{"2025-09-08T00:00:00Z":{"Operating Systems":[{"id":"http://arxiv.org/abs/2509.03855v2","updated":"2025-09-08T10:10:53Z","published":"2025-09-04T03:31:31Z","title":"Towards Deterministic Sub-0.5 us Response on Linux through Interrupt\n  Isolation","summary":"  Real-time responsiveness in Linux is often constrained by interrupt\ncontention and timer handling overhead, making it challenging to achieve\nsub-microsecond latency. This work introduces an interrupt isolation approach\nthat centralizes and minimizes timer interrupt interference across CPU cores.\nBy enabling a dedicated API to selectively invoke timer handling routines and\nsuppress non-critical inter-processor interrupts, our design significantly\nreduces jitter and response latency. Experiments conducted on an ARM-based\nmulticore platform demonstrate that the proposed mechanism consistently\nachieves sub-0.5 us response times, outperforming conventional Linux PREEMPT-RT\nconfigurations. These results highlight the potential of interrupt isolation as\na lightweight and effective strategy for deterministic real-time workloads in\ngeneral-purpose operating systems.\n","authors":["Zhouyi Zhou","Zhili Liu","Shancong Zhang","Jiemin Li","Dengke Du","Mengke Sun","Zhiqiang Wang","Hongyan Liu","Guokai Xu"],"pdf_url":"https://arxiv.org/pdf/2509.03855v2.pdf","comment":"9 pages, 11 figures"}],"Systems and Control":[{"id":"http://arxiv.org/abs/2509.06953v1","updated":"2025-09-08T17:59:35Z","published":"2025-09-08T17:59:35Z","title":"Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for\n  Dynamic Environments","summary":"  Generating collision-free motion in dynamic, partially observable\nenvironments is a fundamental challenge for robotic manipulators. Classical\nmotion planners can compute globally optimal trajectories but require full\nenvironment knowledge and are typically too slow for dynamic scenes. Neural\nmotion policies offer a promising alternative by operating in closed-loop\ndirectly on raw sensory inputs but often struggle to generalize in complex or\ndynamic settings. We propose Deep Reactive Policy (DRP), a visuo-motor neural\nmotion policy designed for reactive motion generation in diverse dynamic\nenvironments, operating directly on point cloud sensory input. At its core is\nIMPACT, a transformer-based neural motion policy pretrained on 10 million\ngenerated expert trajectories across diverse simulation scenarios. We further\nimprove IMPACT's static obstacle avoidance through iterative student-teacher\nfinetuning. We additionally enhance the policy's dynamic obstacle avoidance at\ninference time using DCP-RMP, a locally reactive goal-proposal module. We\nevaluate DRP on challenging tasks featuring cluttered scenes, dynamic moving\nobstacles, and goal obstructions. DRP achieves strong generalization,\noutperforming prior classical and neural methods in success rate across both\nsimulated and real-world settings. Video results and code available at\nhttps://deep-reactive-policy.com\n","authors":["Jiahui Yang","Jason Jingzhou Liu","Yulong Li","Youssef Khaky","Kenneth Shaw","Deepak Pathak"],"pdf_url":"https://arxiv.org/pdf/2509.06953v1.pdf","comment":"Website at \\url{deep-reactive-policy.com}"},{"id":"http://arxiv.org/abs/2509.04199v2","updated":"2025-09-08T16:46:16Z","published":"2025-09-04T13:23:00Z","title":"On the Effect of Sampling-Time Jitter","summary":"  This brief, aimed at practitioners, offers an analysis of the effect of\nsampling-time jitter, i. e., the error produced by execution-time inaccuracies.\nWe propose reinterpreting jitter-afflicted linear time-invariant systems\nthrough equivalent jitter-free analogs. By constructing a perceived system that\nabsorbs the effects of timing perturbations into its dynamics, we find an\naffine scaling of jitter. We examine both measurement and implementation\nscenarios, demonstrating that the presence of jitter effectively scales the\nsystem matrices. Moreover, we observe that, in the Laplace domain, jitter can\nbe interpreted as a frequency scaling.\n","authors":["Dieter Schwarzmann","Simon Käser"],"pdf_url":"https://arxiv.org/pdf/2509.04199v2.pdf","comment":"Updated Version of the one submitted. Submitted for review as letter\n  in IEEE Journal for Transactions on Control Systems Technology"},{"id":"http://arxiv.org/abs/2509.06853v1","updated":"2025-09-08T16:21:11Z","published":"2025-09-08T16:21:11Z","title":"Reinforcement learning meets bioprocess control through behaviour\n  cloning: Real-world deployment in an industrial photobioreactor","summary":"  The inherent complexity of living cells as production units creates major\nchallenges for maintaining stable and optimal bioprocess conditions, especially\nin open Photobioreactors (PBRs) exposed to fluctuating environments. To address\nthis, we propose a Reinforcement Learning (RL) control approach, combined with\nBehavior Cloning (BC), for pH regulation in open PBR systems. This represents,\nto the best of our knowledge, the first application of an RL-based control\nstrategy to such a nonlinear and disturbance-prone bioprocess. Our method\nbegins with an offline training stage in which the RL agent learns from\ntrajectories generated by a nominal Proportional-Integral-Derivative (PID)\ncontroller, without direct interaction with the real system. This is followed\nby a daily online fine-tuning phase, enabling adaptation to evolving process\ndynamics and stronger rejection of fast, transient disturbances. This hybrid\noffline-online strategy allows deployment of an adaptive control policy capable\nof handling the inherent nonlinearities and external perturbations in open\nPBRs. Simulation studies highlight the advantages of our method: the Integral\nof Absolute Error (IAE) was reduced by 8% compared to PID control and by 5%\nrelative to standard off-policy RL. Moreover, control effort decreased\nsubstantially-by 54% compared to PID and 7% compared to standard RL-an\nimportant factor for minimizing operational costs. Finally, an 8-day\nexperimental validation under varying environmental conditions confirmed the\nrobustness and reliability of the proposed approach. Overall, this work\ndemonstrates the potential of RL-based methods for bioprocess control and paves\nthe way for their broader application to other nonlinear, disturbance-prone\nsystems.\n","authors":["Juan D. Gil","Ehecatl Antonio Del Rio Chanona","José L. Guzmán","Manuel Berenguel"],"pdf_url":"https://arxiv.org/pdf/2509.06853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.14222v5","updated":"2025-09-08T15:17:07Z","published":"2025-03-18T12:59:50Z","title":"Vanishing Stacked-Residual PINN for State Reconstruction of Hyperbolic\n  Systems","summary":"  In a more connected world, modeling multi-agent systems with hyperbolic\npartial differential equations (PDEs) offers a compact, physics-consistent\ndescription of collective dynamics. However, classical control tools need\nadaptation for these complex systems. Physics-informed neural networks (PINNs)\nprovide a powerful framework to fix this issue by inferring solutions to PDEs\nby embedding governing equations into the neural network. A major limitation of\noriginal PINNs is their inability to capture steep gradients and\ndiscontinuities in hyperbolic PDEs. To tackle this problem, we propose a\nstacked residual PINN method enhanced with a vanishing viscosity mechanism.\nInitially, a basic PINN with a small viscosity coefficient provides a stable,\nlow-fidelity solution. Residual correction blocks with learnable scaling\nparameters then iteratively refine this solution, progressively decreasing the\nviscosity coefficient to transition from parabolic to hyperbolic PDEs. Applying\nthis method to traffic state reconstruction improved results by an order of\nmagnitude in relative $\\mathcal{L}^2$ error, demonstrating its potential to\naccurately estimate solutions where original PINNs struggle with instability\nand low fidelity.\n","authors":["Katayoun Eshkofti","Matthieu Barreau"],"pdf_url":"https://arxiv.org/pdf/2503.14222v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.06775v1","updated":"2025-09-08T14:58:12Z","published":"2025-09-08T14:58:12Z","title":"Agentic DDQN-Based Scheduling for Licensed and Unlicensed Band\n  Allocation in Sidelink Networks","summary":"  This paper presents an agentic artificial intelligence (AI)-driven double\ndeep Q-network (DDQN) scheduling framework for licensed and unlicensed band\nallocation in New Radio (NR) sidelink (SL) networks. SL must share licensed\nspectrum with cellular communications (CC) and unlicensed bands with Wi-Fi,\nposing significant challenges for coexistence. Unlike prior rule-based or\nthreshold-based methods, the proposed agentic scheduler autonomously perceives\nqueueing dynamics, channel conditions, and coexistence states, and adapts its\npolicy to maintain quality-of-service (QoS). Simulation results show that our\nframework reduces the blocking rate by up to 87.5% compared to threshold-based\nscheduling under limited licensed bandwidth. These findings demonstrate the\npotential of Agentic AI to enable stable, QoS-aware, and adaptive scheduling\nfor future NR SL systems.\n","authors":["Po-Heng Chou","Pin-Qi Fu","Walid Saad","Li-Chun Wang"],"pdf_url":"https://arxiv.org/pdf/2509.06775v1.pdf","comment":"6 pages, 3 figures, accepted by 2025 IEEE Globecom Workshops"},{"id":"http://arxiv.org/abs/2405.15454v2","updated":"2025-09-08T14:48:25Z","published":"2024-05-24T11:30:44Z","title":"Linearly Controlled Language Generation with Performative Guarantees","summary":"  The increasing prevalence of Large Language Models (LMs) in critical\napplications highlights the need for controlled language generation strategies\nthat are not only computationally efficient but that also enjoy performance\nguarantees. To achieve this, we use a common model of concept semantics as\nlinearly represented in an LM's latent space. In particular, we take the view\nthat natural language generation traces a trajectory in this continuous\nsemantic space, realized by the language model's hidden activations. This view\npermits a control-theoretic treatment of text generation in latent space, in\nwhich we propose a lightweight, gradient-free intervention that dynamically\nsteers trajectories away from regions corresponding to undesired meanings. In\nparticular, we propose to directly intervene the activations of the token that\nis being generated in embedding space in an online fashion. Crucially, we do\nnot simply steer activations towards a desirable region. Instead, our method\nrelies on classical techniques from control theory to precisely control\nactivations in a context-dependent way, and guarantees that they are brought\ninto a specific pre-defined region of embedding space that corresponds to\nallowed semantics. Our intervention is computed in closed-form according to an\noptimal controller formulation, minimally impacting generation time. This\ncontrol of the activations in embedding space allows for fine-grained steering\nof attributes of the generated sequence. We demonstrate the effectiveness of\nour approach on different objectives-- toxicity avoidance and sentiment\ncontrol-- while maintaining text quality.\n","authors":["Emily Cheng","Carmen Amo Alonso"],"pdf_url":"https://arxiv.org/pdf/2405.15454v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2509.06758v1","updated":"2025-09-08T14:46:50Z","published":"2025-09-08T14:46:50Z","title":"Steering Opinion through Dynamic Stackelberg Optimization","summary":"  This paper employs the Friedkin-Johnsen (FJ) model to describe the dynamics\nof opinion evolution within a social network. Under the FJ framework, the\nsociety is divided into two subgroups that include stubborn agents and regular\nagents. The opinions of stubborn agents are not influenced by regular agents,\nwhereas the opinions of regular agents evolve based on the opinions of their\nneighboring agents. By defining the origin as the desired collective opinion of\nthe society, the objective of the paper is to minimize deviations from this\ndesired opinion. To achieve this, a Stackelberg game is established between the\nstubborn and regular subgroups, where the opinion adjustments of the stubborn\nagents and the openness variables of regular agents serve as the decision\nvariables. The proposed solution approach integrates quadratic programming and\ndynamic programming to optimize these decision variables at each discrete time\nstep using forward and backward propagation.\n","authors":["Hossein Rastgoftar"],"pdf_url":"https://arxiv.org/pdf/2509.06758v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.04817v2","updated":"2025-09-08T14:38:50Z","published":"2025-09-05T05:37:54Z","title":"Optimal Damping for the 1D Wave Equation Using a Single Damper","summary":"  Vibrational structures are susceptible to catastrophic failures or structural\ndamages when external forces induce resonances or repeated unwanted\noscillations. One common mitigation strategy is to use dampers to suppress\nthese disturbances. This leads to the problem of finding optimal damper\nviscosities and positions for a given vibrational structure. Although extensive\nresearch exists for the case of finite-dimensional systems, optimizing damper\npositions remains challenging due to its discrete nature. To overcome this, we\nintroduce a novel model for the damped wave equation (at the PDE level) with a\ndamper of viscosity $\\mathfrak{g}$ at position $\\mathfrak{p}$ and develop a\nsystem-theoretic input/output-based analysis in the frequency domain. In this\nsystem-theoretic formulation, while we consider average displacement as the\noutput, for input (forcing), we analyze two separate cases, namely, the uniform\nand boundary forcing. For both cases, explicit formulas are derived for the\ncorresponding transfer functions, parametrized by $\\mathfrak{p}$ and\n$\\mathfrak{g}$. This explicit parametrization by $\\mathfrak{p}$ and\n$\\mathfrak{g}$ facilitates analyzing the optimal damping problem (at the PDE\nlevel) using norms such as the $\\mathcal{H}_2$ and $\\mathcal{H}_\\infty$ norms.\nWe also examine limiting cases, such as when the viscosity is very large or\nwhen no external damping is present. To illustrate our approach, we present\nnumerical examples, compare different optimization criteria, and discuss the\nimpact of damping parameters on the damped wave equation.\n","authors":["Petar Mlinarić","Serkan Gugercin","Zoran Tomljanović"],"pdf_url":"https://arxiv.org/pdf/2509.04817v2.pdf","comment":"18 pages, 12 figures"},{"id":"http://arxiv.org/abs/2509.06722v1","updated":"2025-09-08T14:19:40Z","published":"2025-09-08T14:19:40Z","title":"Edge Server Monitoring for Job Assignment","summary":"  In this paper, we study a goal-oriented communication problem for edge server\nmonitoring, where compute jobs arrive intermittently at dispatchers and must be\nimmediately assigned to distributed edge servers. Due to competing workloads\nand the dynamic nature of the edge environment, server availability fluctuates\nover time. To maintain accurate estimates of server availability states, each\ndispatcher updates its belief using two mechanisms: (i) active queries over\nshared communication channels and (ii) feedback from past job executions. We\nformulate a query scheduling problem that maximizes the job success rate under\nlimited communication resources for queries. This problem is modeled as a\nRestless Multi-Armed Bandit (RMAB) with multiple actions and addressed using a\nNet-Gain Maximization (NGM) scheduling algorithm, which selects servers to\nquery based on their expected improvement in execution performance. Simulation\nresults show that the proposed NGM Policy significantly outperforms baseline\nstrategies, achieving up to a 30% gain over the Round-Robin Policy and up to a\n107% gain over the Never-Query Policy.\n","authors":["Samuel Chamoun","Sirin Chakraborty","Eric Graves","Kevin Chan","Yin Sun"],"pdf_url":"https://arxiv.org/pdf/2509.06722v1.pdf","comment":"Accepted to IEEE MILCOM 2025 (Networking Protocols and Performance\n  Track), 6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.17118v2","updated":"2025-09-08T14:13:08Z","published":"2024-10-22T15:49:53Z","title":"Learning Load Balancing with GNN in MPTCP-Enabled Heterogeneous Networks","summary":"  Hybrid light fidelity (LiFi) and wireless fidelity (WiFi) networks are a\npromising paradigm of heterogeneous network (HetNet), attributed to the\ncomplementary physical properties of optical spectra and radio frequency.\nHowever, the current development of such HetNets is mostly bottlenecked by the\nexisting transmission control protocol (TCP), which restricts the user\nequipment (UE) to connecting one access point (AP) at a time. While the ongoing\ninvestigation on multipath TCP (MPTCP) can bring significant benefits, it\ncomplicates the network topology of HetNets, making the existing load balancing\n(LB) learning models less effective. Driven by this, we propose a graph neural\nnetwork (GNN)-based model to tackle the LB problem for MPTCP-enabled HetNets,\nwhich results in a partial mesh topology. Such a topology can be modeled as a\ngraph, with the channel state information and data rate requirement embedded as\nnode features, while the LB solutions are deemed as edge labels. Compared to\nthe conventional deep neural network (DNN), the proposed GNN-based model\nexhibits two key strengths: i) it can better interpret a complex network\ntopology; and ii) it can handle various numbers of APs and UEs with a single\ntrained model. Simulation results show that against the traditional\noptimisation method, the proposed learning model can achieve near-optimal\nthroughput within a gap of 11.5%, while reducing the inference time by 4 orders\nof magnitude. In contrast to the DNN model, the new method can improve the\nnetwork throughput by up to 21.7%, at a similar inference time level.\n","authors":["Han Ji","Xiping Wu","Zhihong Zeng","Chen Chen"],"pdf_url":"https://arxiv.org/pdf/2410.17118v2.pdf","comment":"We would like to withdraw this submission because it contains several\n  errors that need substantial revision. We plan to prepare a corrected and\n  improved version, which will be submitted as a new manuscript at a later\n  stage"},{"id":"http://arxiv.org/abs/2505.10438v3","updated":"2025-09-08T13:56:53Z","published":"2025-05-15T15:55:13Z","title":"Identification and Optimal Nonlinear Control of Turbojet Engine Using\n  Koopman Eigenfunction Model","summary":"  Gas turbine engines are complex and highly nonlinear dynamical systems.\nDeriving their physics-based models can be challenging because it requires\nperformance characteristics that are not always available, often leading to\nmany simplifying assumptions. This paper discusses the limitations of\nconventional experimental methods used to derive component-level and locally\nlinear parameter-varying models, and addresses these issues by employing\nidentification techniques based on data collected from standard engine\noperation under closed-loop control. The rotor dynamics are estimated using the\nsparse identification of nonlinear dynamics. Subsequently, the autonomous part\nof the dynamics is mapped into an optimally constructed Koopman eigenfunction\nspace. This process involves eigenvalue optimization using metaheuristic\nalgorithms and temporal projection, followed by gradient-based eigenfunction\nidentification. The resulting Koopman model is validated against an in-house\nreference component-level model. A globally optimal nonlinear feedback\ncontroller and a Kalman estimator are then designed within the eigenfunction\nspace and compared to traditional and gain-scheduled proportional-integral\ncontrollers, as well as a proposed internal model control approach. The\neigenmode structure enables targeting individual modes during optimization,\nleading to improved performance tuning. Results demonstrate that the\nKoopman-based controller surpasses other benchmark controllers in both\nreference tracking and disturbance rejection under sea-level and varying flight\nconditions, due to its global nature.\n","authors":["David Grasev"],"pdf_url":"https://arxiv.org/pdf/2505.10438v3.pdf","comment":"34 pages, 28 figures Under review at Springer Nonlinear Dynamics"},{"id":"http://arxiv.org/abs/2509.06687v1","updated":"2025-09-08T13:43:09Z","published":"2025-09-08T13:43:09Z","title":"Safe Robust Predictive Control-based Motion Planning of Automated\n  Surface Vessels in Inland Waterways","summary":"  Deploying self-navigating surface vessels in inland waterways offers a\nsustainable alternative to reduce road traffic congestion and emissions.\nHowever, navigating confined waterways presents unique challenges, including\nnarrow channels, higher traffic density, and hydrodynamic disturbances.\nExisting methods for autonomous vessel navigation often lack the robustness or\nprecision required for such environments. This paper presents a new motion\nplanning approach for Automated Surface Vessels (ASVs) using Robust Model\nPredictive Control (RMPC) combined with Control Barrier Functions (CBFs). By\nincorporating channel borders and obstacles as safety constraints within the\ncontrol design framework, the proposed method ensures both collision avoidance\nand robust navigation on complex waterways. Simulation results demonstrate the\nefficacy of the proposed method in safely guiding ASVs under realistic\nconditions, highlighting its improved safety and adaptability compared to the\nstate-of-the-art.\n","authors":["Sajad Ahmadi","Hossein Nejatbakhsh Esfahani","Javad Mohammadpour Velni"],"pdf_url":"https://arxiv.org/pdf/2509.06687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.06682v1","updated":"2025-09-08T13:38:39Z","published":"2025-09-08T13:38:39Z","title":"An Adaptive Coverage Control Approach for Multiple Autonomous Off-road\n  Vehicles in Dynamic Agricultural Fields","summary":"  This paper presents an adaptive coverage control method for a fleet of\noff-road and Unmanned Ground Vehicles (UGVs) operating in dynamic\n(time-varying) agricultural environments. Traditional coverage control\napproaches often assume static conditions, making them unsuitable for\nreal-world farming scenarios where obstacles, such as moving machinery and\nuneven terrains, create continuous challenges. To address this, we propose a\nreal-time path planning framework that integrates Unmanned Aerial Vehicles\n(UAVs) for obstacle detection and terrain assessment, allowing UGVs to\ndynamically adjust their coverage paths. The environment is modeled as a\nweighted directed graph, where the edge weights are continuously updated based\non the UAV observations to reflect obstacle motion and terrain variations. The\nproposed approach incorporates Voronoi-based partitioning, adaptive edge weight\nassignment, and cost-based path optimization to enhance navigation efficiency.\nSimulation results demonstrate the effectiveness of the proposed method in\nimproving path planning, reducing traversal costs, and maintaining robust\ncoverage in the presence of dynamic obstacles and muddy terrains.\n","authors":["Sajad Ahmadi","Mohammadreza Davoodi","Javad Mohammadpour Velni"],"pdf_url":"https://arxiv.org/pdf/2509.06682v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20628v3","updated":"2025-09-08T13:35:34Z","published":"2025-06-25T17:22:18Z","title":"Identifiability and Maximum Likelihood Estimation for System\n  Identification of Networks of Dynamical Systems","summary":"  In this paper we investigate identifiability and maximum likelihood\nestimation for direct system identification of networks of dynamical systems.\nWe provide necessary and sufficient conditions for network identifiability in\nterms of Gr\\\"obner bases. We show that the maximum likelihood approach is both\nconsistent and efficient, which is in contrast to existing prediction error\napproaches. Moreover, our approach has wider applicability, i.e., it is\napplicable whenever network identifiability holds. Finally, we show that we can\nformulate the maximum likelihood problem without the use of a predictor, which\nis the key to numerically being able to solve it efficiently.\n","authors":["Anders Hansson","João Victor Galvão da Mata","Martin S. Andersen"],"pdf_url":"https://arxiv.org/pdf/2506.20628v3.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Submitted to IEEE Transactions on Automatic Control"},{"id":"http://arxiv.org/abs/2509.06657v1","updated":"2025-09-08T13:14:52Z","published":"2025-09-08T13:14:52Z","title":"Human-Hardware-in-the-Loop simulations for systemic resilience\n  assessment in cyber-socio-technical systems","summary":"  Modern industrial systems require updated approaches to safety management, as\nthe tight interplay between cyber-physical, human, and organizational factors\nhas driven their processes toward increasing complexity. In addition to dealing\nwith known risks, managing system resilience acquires great value to address\ncomplex behaviors pragmatically. This manuscript starts from the\nSystem-Theoretic Accident Model and Processes (STAMP) as a modelling initiative\nfor such complexity. The STAMP can be natively integrated with simulation-based\napproaches, which however fail to realistically represent human behaviors and\ntheir influence on the system performance. To overcome this limitation, this\npaper proposes a Human-Hardware-in-the-Loop (HHIL) modeling and simulation\nframework aimed at supporting a more realistic and comprehensive assessments of\nsystemic resilience. The approach is tested on an experimental oil and gas\nplant experiencing cyber-attacks, where two personas of operators (experts and\nnovices) work. This research provides a mean to quantitatively assess how\nvariations in operator behavior impact the overall system performance, offering\ninsights into how resilience should be understood and implemented in complex\nsocio-technical systems at large.\n","authors":["Francesco Simone","Marco Bortolini","Giovanni Mazzuto","Giulio di Gravio","Riccardo Patriarca"],"pdf_url":"https://arxiv.org/pdf/2509.06657v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.09383v2","updated":"2025-09-08T12:59:00Z","published":"2025-06-11T04:23:49Z","title":"Bipedal Balance Control with Whole-body Musculoskeletal Standing and\n  Falling Simulations","summary":"  Balance control is important for human and bipedal robotic systems. While\ndynamic balance during locomotion has received considerable attention,\nquantitative understanding of static balance and falling remains limited. This\nwork presents a hierarchical control pipeline for simulating human balance via\na comprehensive whole-body musculoskeletal system. We identified spatiotemporal\ndynamics of balancing during stable standing, revealed the impact of muscle\ninjury on balancing behavior, and generated fall contact patterns that aligned\nwith clinical data. Furthermore, our simulated hip exoskeleton assistance\ndemonstrated improvement in balance maintenance and reduced muscle effort under\nperturbation. This work offers unique muscle-level insights into human balance\ndynamics that are challenging to capture experimentally. It could provide a\nfoundation for developing targeted interventions for individuals with balance\nimpairments and support the advancement of humanoid robotic systems.\n","authors":["Chengtian Ma","Yunyue Wei","Chenhui Zuo","Chen Zhang","Yanan Sui"],"pdf_url":"https://arxiv.org/pdf/2506.09383v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.06599v1","updated":"2025-09-08T12:08:02Z","published":"2025-09-08T12:08:02Z","title":"Information-Theoretic Bounds and Task-Centric Learning Complexity for\n  Real-World Dynamic Nonlinear Systems","summary":"  Dynamic nonlinear systems exhibit distortions arising from coupled static and\ndynamic effects. Their intertwined nature poses major challenges for\ndata-driven modeling. This paper presents a theoretical framework grounded in\nstructured decomposition, variance analysis, and task-centric complexity\nbounds.\n  The framework employs a directional lower bound on interactions between\nmeasurable system components, extending orthogonality in inner product spaces\nto structurally asymmetric settings. This bound supports variance inequalities\nfor decomposed systems. Key behavioral indicators are introduced along with a\nmemory finiteness index. A rigorous power-based condition establishes a\nmeasurable link between finite memory in realizable systems and the First Law\nof Thermodynamics. This offers a more foundational perspective than classical\nbounds based on the Second Law.\n  Building on this foundation, we formulate a `Behavioral Uncertainty\nPrinciple,' demonstrating that static and dynamic distortions cannot be\nminimized simultaneously. We identify that real-world systems seem to resist\ncomplete deterministic decomposition due to entangled static and dynamic\neffects. We also present two general-purpose theorems linking function variance\nto mean-squared Lipschitz continuity and learning complexity. This yields a\nmodel-agnostic, task-aware complexity metric, showing that lower-variance\ncomponents are inherently easier to learn.\n  These insights explain the empirical benefits of structured residual\nlearning, including improved generalization, reduced parameter count, and lower\ntraining cost, as previously observed in power amplifier linearization\nexperiments. The framework is broadly applicable and offers a scalable,\ntheoretically grounded approach to modeling complex dynamic nonlinear systems.\n","authors":["Sri Satish Krishna Chaitanya Bulusu","Mikko Sillanpää"],"pdf_url":"https://arxiv.org/pdf/2509.06599v1.pdf","comment":"15 pages, 1 figure, 2 photographs"},{"id":"http://arxiv.org/abs/2509.06588v1","updated":"2025-09-08T11:57:44Z","published":"2025-09-08T11:57:44Z","title":"Distributed Automatic Generation Control subject to Ramp-Rate-Limits:\n  Anytime Feasibility and Uniform Network-Connectivity","summary":"  This paper considers automatic generation control over an information-sharing\nnetwork of communicating generators as a multi-agent system. The optimization\nsolution is distributed among the agents based on information consensus\nalgorithms, while addressing the generators' ramp-rate-limits (RRL). This is\ntypically ignored in the existing linear/nonlinear optimization solutions but\nthey exist in real-time power generation scenarios. Without addressing the RRL,\nthe generators cannot follow the assigned rate of generating power by the\noptimization algorithm; therefore, the existing solutions may not necessarily\nconverge to the exact optimal cost or may lose feasibility in practice. The\nproposed solution in this work addresses the ramp-rate-limit constraint along\nwith the box constraint (limits on the generated powers) and the\ncoupling-constraint (generation-demand balance) at all iteration times of the\nalgorithm. The latter is referred to as the anytime feasibility and implies\nthat at every termination point of the algorithm, the balance between the\ndemand and generated power holds. To improve the convergence rate of the\nalgorithm we further consider internal signum-based nonlinearity. We also show\nthat our solution can tolerate communication link removal. This follows from\nthe uniform-connectivity assumption on the communication network.\n","authors":["Mohammadreza Doostmohammadian","Hamid R. Rabiee"],"pdf_url":"https://arxiv.org/pdf/2509.06588v1.pdf","comment":"Digital Signal Processing journal"},{"id":"http://arxiv.org/abs/2501.12279v2","updated":"2025-09-08T11:08:05Z","published":"2025-01-21T16:50:33Z","title":"Spatial exponential decay of perturbations in optimal control of general\n  evolution equations","summary":"  We analyze the robustness of optimally controlled evolution equations with\nrespect to spatially localized perturbations. We prove that if the involved\noperators are domain-uniformly stabilizable and detectable, then these\nlocalized perturbations only have a local effect on the optimal solution. We\ncharacterize this domain-uniform stabilizability and detectability for the\ntransport equation with constant transport velocity, showing that even for\nunitary semigroups, optimality implies exponential damping. We extend this\nresult to the case of a space-dependent transport velocity. Finally we leverage\nthe results for the transport equation to characterize domain-uniform\nstabilizability of the wave equation. Numerical examples in one space dimension\ncomplement the theoretical results.\n","authors":["Simone Göttlich","Benedikt Oppeneiger","Manuel Schaller","Karl Worthmann"],"pdf_url":"https://arxiv.org/pdf/2501.12279v2.pdf","comment":"53 pages, 5 figures"},{"id":"http://arxiv.org/abs/2509.06541v1","updated":"2025-09-08T10:54:43Z","published":"2025-09-08T10:54:43Z","title":"Wireless Low-Latency Synchronization for Body-Worn Multi-Node Systems in\n  Sports","summary":"  Biomechanical data acquisition in sports demands sub-millisecond\nsynchronization across distributed body-worn sensor nodes. This study evaluates\nand characterizes the Enhanced ShockBurst (ESB) protocol from Nordic\nSemiconductor under controlled laboratory conditions for wireless, low-latency\ncommand broadcasting, enabling fast event updates in multi-node systems.\nThrough systematic profiling of protocol parameters, including\ncyclic-redundancy-check modes, bitrate, transmission modes, and payload\nhandling, we achieve a mean Device-to-Device (D2D) latency of 504.99 +- 96.89\nus and a network-to-network core latency of 311.78 +- 96.90 us using a one-byte\npayload with retransmission optimization. This performance significantly\noutperforms Bluetooth Low Energy (BLE), which is constrained by a 7.5 ms\nconnection interval, by providing deterministic, sub-millisecond\nsynchronization suitable for high-frequency (500 Hz to 1000 Hz) biosignals.\nThese results position ESB as a viable solution for time-critical, multi-node\nwearable systems in sports, enabling precise event alignment and reliable\nhigh-speed data fusion for advanced athlete monitoring and feedback\napplications.\n","authors":["Nico Krull","Lukas Schulthess","Michele Magno","Luca Benini","Christoph Leitner"],"pdf_url":"https://arxiv.org/pdf/2509.06541v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.06534v1","updated":"2025-09-08T10:39:38Z","published":"2025-09-08T10:39:38Z","title":"Parameter Robustness in Data-Driven Estimation of Dynamical Systems","summary":"  We study the robustness of system estimation to parametric perturbations in\nsystem dynamics and initial conditions. We define the problem of\nsensitivity-based parametric uncertainty quantification in dynamical system\nestimation. The main contribution of this paper is the development of a novel\nrobustness metric for estimation of parametrized linear dynamical systems with\nand without control actions. For the computation of this metric, we delineate\nthe uncertainty contributions arising from control actions, system dynamics,\nand initial conditions. Furthermore, to validate our theoretical findings, we\nestablish connections between these new results and the existing literature on\nthe robustness of model reduction. This work provides guidance for selecting\nestimation methods based on tolerable levels of parametric uncertainty and\npaves the way for new cost functions in data-driven estimation that reward\nsensitivity to a desired subset of parameters while penalizing others.\n","authors":["Ayush Pandey"],"pdf_url":"https://arxiv.org/pdf/2509.06534v1.pdf","comment":"Submitted for publication in the IEEE Conference on Decision and\n  Control (CDC) 2025"},{"id":"http://arxiv.org/abs/2503.20703v2","updated":"2025-09-08T09:43:06Z","published":"2025-03-26T16:36:52Z","title":"Data-driven Distributionally Robust Control Based on Sinkhorn Ambiguity\n  Sets","summary":"  As the complexity of modern control systems increases, it becomes challenging\nto derive an accurate model of the uncertainty that affects their dynamics.\nWasserstein Distributionally Robust Optimization (DRO) provides a powerful\nframework for decision-making under distributional uncertainty only using noise\nsamples. However, while the resulting policies inherit strong probabilistic\nguarantees when the number of samples is sufficiently high, their performance\nmay significantly degrade when only a few data are available. Inspired by\nrecent results from the machine learning community, we introduce an entropic\nregularization to penalize deviations from a given reference distribution and\nstudy data-driven DR control over Sinkhorn ambiguity sets. We show that for\nfinite-horizon control problems, the optimal DR linear policy can be computed\nvia convex programming. By analyzing the relation between the ambiguity set\ndefined in terms of Wasserstein and Sinkhorn discrepancies, we reveal that, as\nthe regularization parameter increases, this optimal policy interpolates\nbetween the solution of the Wasserstein DR problem and that of the stochastic\nproblem under the reference distribution. We validate our theoretical findings\nand the effectiveness of our approach when only scarce data are available on a\nnumerical example.\n","authors":["Riccardo Cescon","Andrea Martin","Giancarlo Ferrari-Trecate"],"pdf_url":"https://arxiv.org/pdf/2503.20703v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.12664v2","updated":"2025-09-08T09:42:18Z","published":"2025-03-16T21:37:48Z","title":"Exploiting Multistage Optimization Structure in Proximal Solvers","summary":"  This paper presents an efficient structure-exploiting algorithm for\nmultistage optimization problems. The proposed method extends existing\napproaches by supporting full coupling between stages and global decision\nvariables in the cost, as well as equality and inequality constraints. The\nalgorithm is implemented as a new backend in the PIQP solver and leverages a\nspecialized block-tri-diagonal-arrow Cholesky factorization within a proximal\ninterior-point framework to handle the underlying problem structure\nefficiently. The implementation features automatic structure detection and\nseamless integration with existing interfaces. Numerical experiments\ndemonstrate significant performance improvements, achieving up to 13x speed-up\ncompared to a generic sparse backend and matching/exceeding the performance of\nthe state-of-the-art specialized solver HPIPM. The solver is particularly\neffective for applications such as model predictive control, robust scenario\noptimization, and periodic optimization problems.\n","authors":["Roland Schwan","Daniel Kuhn","Colin N. Jones"],"pdf_url":"https://arxiv.org/pdf/2503.12664v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.06447v1","updated":"2025-09-08T08:47:43Z","published":"2025-09-08T08:47:43Z","title":"Unified Graph-Theoretic Modeling of Multi-Energy Flows in Distribution\n  Systems","summary":"  The increasing complexity of energy systems due to sector coupling and\ndecarbonization calls for unified modeling frameworks that capture the physical\nand structural interactions between electricity, gas, and heat networks. This\npaper presents a graph-based modeling approach for multi-energy systems, where\neach domain is represented as a layer in a multi-layer graph, and coupling\ntechnologies are modeled as inter-layer edges via a dedicated coupling layer. A\nsteady-state solver based on a block-structured Newton-Raphson method is\ndeveloped to jointly compute flows and state variables across all carriers. The\nproposed model is tested and validated on a realistic case study based on data\nfrom a German distribution network. The results demonstrate convergence,\nnumerical accuracy, and consistent domain interaction, and demonstrate the\nmethod's applicability for system-wide analysis and its potential as a\nfoundation for future optimizations in integrated energy systems.\n","authors":["Marwan Mostafa","Daniel Wenser","Payam Teimourzadeh Baboli","Christian Becker"],"pdf_url":"https://arxiv.org/pdf/2509.06447v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.15838v2","updated":"2025-09-08T08:28:46Z","published":"2025-04-22T12:31:10Z","title":"Gaussian behaviors: representations and data-driven control","summary":"  We propose a modeling framework for stochastic systems, termed Gaussian\nbehaviors, that describes finite-length trajectories of a system as a Gaussian\nprocess. The proposed model naturally quantifies the uncertainty in the\ntrajectories, yet it is simple enough to allow for tractable formulations. We\nrelate the proposed model to existing descriptions of dynamical systems\nincluding deterministic and stochastic behaviors, and linear time-invariant\n(LTI) state-space models with Gaussian noise. Gaussian behaviors can be\nestimated directly from observed data as the empirical sample covariance. The\ndistribution of future outputs conditioned on inputs and past outputs provides\na predictive model that can be incorporated in predictive control frameworks.\nWe show that subspace predictive control is a certainty-equivalence control\nformulation with the estimated Gaussian behavior. Furthermore, the regularized\ndata-enabled predictive control (DeePC) method is shown to be a\ndistributionally optimistic formulation that optimistically accounts for\nuncertainty in the Gaussian behavior. To mitigate the excessive optimism of\nDeePC, we propose a novel distributionally robust control formulation, and\nprovide a convex reformulation allowing for efficient implementation.\n","authors":["András Sasfi","Ivan Markovsky","Alberto Padoan","Florian Dörfler"],"pdf_url":"https://arxiv.org/pdf/2504.15838v2.pdf","comment":"Extended version of the paper accepted to the 64th IEEE Conference on\n  Decision and Control"},{"id":"http://arxiv.org/abs/2509.06425v1","updated":"2025-09-08T08:21:11Z","published":"2025-09-08T08:21:11Z","title":"First-Principle Modeling Framework of Boost Converter Dynamics for\n  Precise Energy Conversions in Space","summary":"  Boost converters are essential for modern electrification and intelligent\ntechnologies. However, conventional Boost converter models relying on\nsteady-state assumptions fail to accurately predict transient behaviors during\ninput voltage and load fluctuations, which cause significant output voltage\novershoots and instability, resulting in failures of electrical systems,\nthereby restricting their use in space. This study introduces a first-principle\nmodeling framework that derives precise dynamic equations for Boost converters\nby incorporating non-ideal component coupling. As compared to the most accurate\nexisting Boost converter model, the proposed models reduce steady-state and\ndynamic-state errors between experimental and simulated output voltages by\nfactors of 11.0 (from 20.9% to 1.9%) and 15.4 (from 77.1% to 5.0%) under input\nvoltage variations, and by factors of 10.2 (from 15.3% to 1.5%) and 35.1 (from\n42.1% to 1.2%) under load changes, respectively. Consequently, a reliable Boost\nconverter is accordingly designed and on-orbit deployed for precise energy\nconversions.\n","authors":["Yifan Wang","Wenhua Li","Zhenlong Wang","Xinrui Zhang","Jianfeng Sun","Qianfu Xia","Zhongtao Gou","Jiangang Rong","Tao Ye"],"pdf_url":"https://arxiv.org/pdf/2509.06425v1.pdf","comment":"24 pages, 30 pages supplementary material, 5 figures, 14\n  supplementary figures, 6 supplementary tables"},{"id":"http://arxiv.org/abs/2509.06312v1","updated":"2025-09-08T03:34:56Z","published":"2025-09-08T03:34:56Z","title":"Enhancing Low-Altitude Airspace Security: MLLM-Enabled UAV Intent\n  Recognition","summary":"  The rapid development of the low-altitude economy emphasizes the critical\nneed for effective perception and intent recognition of non-cooperative\nunmanned aerial vehicles (UAVs). The advanced generative reasoning capabilities\nof multimodal large language models (MLLMs) present a promising approach in\nsuch tasks. In this paper, we focus on the combination of UAV intent\nrecognition and the MLLMs. Specifically, we first present an MLLM-enabled UAV\nintent recognition architecture, where the multimodal perception system is\nutilized to obtain real-time payload and motion information of UAVs, generating\nstructured input information, and MLLM outputs intent recognition results by\nincorporating environmental information, prior knowledge, and tactical\npreferences. Subsequently, we review the related work and demonstrate their\nprogress within the proposed architecture. Then, a use case for low-altitude\nconfrontation is conducted to demonstrate the feasibility of our architecture\nand offer valuable insights for practical system design. Finally, the future\nchallenges are discussed, followed by corresponding strategic recommendations\nfor further applications.\n","authors":["Guangyu Lei","Tianhao Liang","Yuqi Ping","Xinglin Chen","Longyu Zhou","Junwei Wu","Xiyuan Zhang","Huahao Ding","Xingjian Zhang","Weijie Yuan","Tingting Zhang","Qinyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2509.06312v1.pdf","comment":"The paper has been submitted to IEEE Internet of Things Magazine"},{"id":"http://arxiv.org/abs/2410.00358v2","updated":"2025-09-08T02:44:25Z","published":"2024-10-01T03:07:48Z","title":"AARK: An Open Toolkit for Autonomous Racing Research","summary":"  Autonomous racing demands safe control of vehicles at their physical limits\nfor extended periods of time, providing insights into advanced vehicle safety\nsystems which increasingly rely on intervention provided by vehicle autonomy.\nParticipation in this field carries with it a high barrier to entry. Physical\nplatforms and their associated sensor suites require large capital outlays\nbefore any demonstrable progress can be made. Simulators allow researches to\ndevelop soft autonomous systems without purchasing a platform. However,\ncurrently available simulators lack visual and dynamic fidelity, can still be\nexpensive to buy, lack customisation, and are difficult to use. AARK provides\nthree packages, ACI, ACDG, and ACMPC. These packages enable research into\nautonomous control systems in the demanding environment of racing to bring more\npeople into the field and improve reproducibility: ACI provides researchers\nwith a computer vision-friendly interface to Assetto Corsa for convenient\ncomparison and evaluation of autonomous control solutions; ACDG enables\ngeneration of depth, normal and semantic segmentation data for training\ncomputer vision models to use in perception systems; and ACMPC gives newcomers\nto the field a modular full-stack autonomous control solution, capable of\ncontrolling vehicles to build from. AARK aims to unify and democratise research\ninto a field critical to providing safer roads and trusted autonomous systems.\n","authors":["James Bockman","Matthew Howe","Adrian Orenstein","Feras Dayoub"],"pdf_url":"https://arxiv.org/pdf/2410.00358v2.pdf","comment":"7 pages, 5 figures"},{"id":"http://arxiv.org/abs/2509.06279v1","updated":"2025-09-08T02:01:49Z","published":"2025-09-08T02:01:49Z","title":"DNN-based Digital Twin Framework of a DC-DC Buck Converter using Spider\n  Monkey Optimization Algorithm","summary":"  Component ageing is a critical concern in power electronic converter systems\n(PECSs). It directly impacts the reliability, performance, and operational\nlifespan of converters used across diverse applications, including electric\nvehicles (EVs), renewable energy systems (RESs) and industrial automation.\nTherefore, understanding and monitoring component ageing is crucial for\ndeveloping robust converters and achieving long-term system reliability. This\npaper proposes a data-driven digital twin (DT) framework for DC-DC buck\nconverters, integrating deep neural network (DNN) with the spider monkey\noptimization (SMO) algorithm to monitor and predict component degradation.\nUtilizing a low-power prototype testbed along with empirical and synthetic\ndatasets, the SMO+DNN approach achieves the global optimum in 95% of trials,\nrequires 33% fewer iterations, and results in 80% fewer parameter constraint\nviolations compared to traditional methods. The DNN model achieves $R^2$ scores\nabove 0.998 for all key degradation parameters and accurately forecasts time to\nfailure ($t_{failure}$). In addition, SMO-tuned degradation profile improves\nthe converter's performance by reducing voltage ripple by 20-25% and inductor\ncurrent ripple by 15-20%.\n","authors":["Tahmin Mahmud","Euzeli Cipriano Dos Santos Jr"],"pdf_url":"https://arxiv.org/pdf/2509.06279v1.pdf","comment":"8 pages, 13 figures, 2 tables. Accepted for a lecture presentation at\n  the 2025 IEEE Energy Conversion Conference and Expo (ECCE 2025)"},{"id":"http://arxiv.org/abs/2509.06257v1","updated":"2025-09-08T00:44:59Z","published":"2025-09-08T00:44:59Z","title":"Human Body Weight Estimation Through Music-Induced Bed Vibrations","summary":"  Rapid and accurate body weight estimation is critical in emergency medical\ncare, as it directly influences treatment decisions, such as drug dosing,\ndefibrillation energy selection, and fluid resuscitation. Traditional methods\nsuch as stand-on scales, length-based tapes, or transfer-based weighing scales\nare often impractical for immobilized patients, inaccurate, or labor-intensive\nand time-consuming. This paper introduces MelodyBedScale, a non-intrusive and\nrapid on-bed weight estimation system that leverages bed vibration induced by\nmusic. The core insight is that body weight affects the vibration transfer\nfunction of the bed-body system, which is captured using vibration sensors\nplaced on opposite sides of the bed. First, we identify weight-sensitive\nfrequency bands and compose clinically acceptable soft, natural music with high\nsignal energy in these frequency bands. This music is then played through a\nspeaker mounted on the bed to induce bed vibrations. Additionally, to\nefficiently capture the complex weight-vibration relationship with limited data\nand enhance generalizability to unseen individuals and weights, we\ntheoretically analyze the weight-vibration relationship and integrate the\nresults into the activation functions of the neural network for\nphysics-informed weight regression. We evaluated MelodyBedScale on both wooden\nand steel beds across 11 participants, achieving a mean absolute error of up to\n1.55 kg.\n","authors":["Yuyan Wu","Jiale Zhang","Moon Lee","Cherrelle Smith","Xinyi Li","Ankur Senapati","Pei Zhang","Hae Young Noh"],"pdf_url":"https://arxiv.org/pdf/2509.06257v1.pdf","comment":"Submitted to Mobicom 2026"},{"id":"http://arxiv.org/abs/2507.18077v2","updated":"2025-09-08T00:39:27Z","published":"2025-07-24T04:01:54Z","title":"Carbon Emission Flow Tracing: Fast Algorithm and California Grid Study","summary":"  Power systems decarbonization are at the focal point of the clean energy\ntransition. While system operators and utility companies increasingly publicize\nsystem-level carbon emission information, it remains unclear how emissions from\nindividual generators are transported through the grid and how they impact\nelectricity users at specific locations. This paper presents a novel and\ncomputationally efficient approach for exact quantification of nodal average\nand marginal carbon emission rates, applicable to both AC and DC optimal power\nflow problems. The approach leverages graph-based topological sorting and\ndirected cycle removal techniques, applied to directed graphs formed by\ngeneration dispatch and optimal power flow solutions. Our proposed algorithm\nefficiently identifies each generator's contribution to each node, capturing\nhow emissions are spatially distributed under varying system conditions. To\nvalidate its effectiveness and reveal locational and temporal emission patterns\nin the real world, we simulate the 8,870-bus realistic California grid using\nactual CAISO data and the CATS model. Based on year long hourly data on nodal\nloads and renewable generation, obtained or estimated from CAISO public data,\nour method accurately estimates power flow conditions, generation mixes, and\nsystemwide emissions, and delivers fine grained spatiotemporal emission\nanalysis for every California county. Both our algorithm and the California\nstudy are open-sourced, providing a foundation for future research on grid\nemissions, planning, operations, and energy policy.\n","authors":["Yuqing Shen","Yuanyuan Shi","Daniel Kirschen","Yize Chen"],"pdf_url":"https://arxiv.org/pdf/2507.18077v2.pdf","comment":"In Submission, 16 pages, 12 figures, code available at\n  https://github.com/yuqing5/Carbon-Tracker-California"},{"id":"http://arxiv.org/abs/2507.17325v3","updated":"2025-09-08T00:39:06Z","published":"2025-07-23T08:50:18Z","title":"Grid impedance estimation based Kalman Filter","summary":"  Modern power systems face new operational hurdles due to the increasing\nadoption of inverter-coupled distributed energy resources, which impact system\nstability and control. Central to these challenges is the dynamic nature of\ngrid impedance. To address this, a novel real-time estimation algorithm based\non the Discrete Fourier Transform is proposed. This algorithm is embedded\nwithin an Advanced Angle Estimation Kalman Filter framework that employs a\nLinear Quadratic Regulator for current control (AAEKF-LQR). The impedance data\ndirectly informs and refines the controller's phase angle estimation.\nSimulation analyses demonstrate robust collaboration between the estimator and\ncontroller, sustaining system stability under weak grid conditions. The\ntechnique proves capable of delivering swift and accurate impedance updates\nduring grid variations, which is crucial for maintaining stable inverter\noperation\n","authors":["Phuoc Sang Nguyen","Ghavameddin Nourbakhsh","Gerard Ledwich"],"pdf_url":"https://arxiv.org/pdf/2507.17325v3.pdf","comment":"6 pages, 6 figures"},{"id":"http://arxiv.org/abs/2509.07294v1","updated":"2025-09-08T23:57:27Z","published":"2025-09-08T23:57:27Z","title":"Learning Neural Koopman Operators with Dissipativity Guarantees","summary":"  We address the problem of learning a neural Koopman operator model that\nprovides dissipativity guarantees for an unknown nonlinear dynamical system\nthat is known to be dissipative. We propose a two-stage approach. First, we\nlearn an unconstrained neural Koopman model that closely approximates the\nsystem dynamics. Then, we minimally perturb the parameters to enforce strict\ndissipativity. Crucially, we establish theoretical guarantees that extend the\ndissipativity properties of the learned model back to the original nonlinear\nsystem. We realize this by deriving an exact relationship between the\ndissipativity of the learned model and the true system through careful\ncharacterization of the identification errors from the noisy data, Koopman\noperator truncation, and generalization to unseen data. We demonstrate our\napproach through simulation on a Duffing oscillator model.\n","authors":["Yuezhu Xu","S. Sivaranjani","Vijay Gupta"],"pdf_url":"https://arxiv.org/pdf/2509.07294v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05702v3","updated":"2025-09-08T23:53:38Z","published":"2025-08-07T01:10:28Z","title":"Grid-Agent: An LLM-Powered Multi-Agent System for Power Grid Control","summary":"  Modern power grids face unprecedented complexity from Distributed Energy\nResources (DERs), Electric Vehicles (EVs), and extreme weather, while also\nbeing increasingly exposed to cyberattacks that can trigger grid violations.\nThis paper introduces Grid-Agent, an autonomous AI-driven framework that\nleverages Large Language Models (LLMs) within a multi-agent system to detect\nand remediate violations. Grid-Agent integrates semantic reasoning with\nnumerical precision through modular agents: a planning agent generates\ncoordinated action sequences using power flow solvers, while a validation agent\nensures stability and safety through sandboxed execution with rollback\nmechanisms. To enhance scalability, the framework employs an adaptive\nmulti-scale network representation that dynamically adjusts encoding schemes\nbased on system size and complexity. Violation resolution is achieved through\noptimizing switch configurations, battery deployment, and load curtailment. Our\nexperiments on IEEE and CIGRE benchmark networks, including the IEEE 69-bus,\nCIGRE MV, IEEE 30-bus test systems, demonstrate superior mitigation\nperformance, highlighting Grid-Agent's suitability for modern smart grids\nrequiring rapid, adaptive response.\n","authors":["Yan Zhang","Ahmad Mohammad Saber","Amr Youssef","Deepa Kundur"],"pdf_url":"https://arxiv.org/pdf/2508.05702v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02437v2","updated":"2025-09-08T23:24:11Z","published":"2025-08-04T13:56:22Z","title":"On the Equivalence of Koopman Eigenfunctions and Commuting Symmetries","summary":"  The Koopman operator framework offers a way to represent a nonlinear system\nas a linear one. The key to this simplification lies in the identification of\neigenfunctions. While various data-driven algorithms have been developed for\nthis problem, a theoretical characterization of Koopman eigenfunctions from\ngeometric properties of the flow is still missing. This paper provides such a\ncharacterization by establishing an equivalence between a set of Koopman\neigenfunctions and a set of commuting symmetries -- both assumed to span the\ntangent spaces at every point on a simply connected open set. Based on this\nequivalence, we build an explicit and convergent formula for the principal\nKoopman eigenfunctions defined on the region of attraction of a locally\nasymptotically stable equilibrium point, thereby offering a constructive\nformula to compute Koopman eigenfunctions.\n","authors":["Xinyuan Jiang","Yan Li"],"pdf_url":"https://arxiv.org/pdf/2508.02437v2.pdf","comment":"7 pages, 1 figure"},{"id":"http://arxiv.org/abs/2509.07218v1","updated":"2025-09-08T20:55:54Z","published":"2025-09-08T20:55:54Z","title":"Electricity Demand and Grid Impacts of AI Data Centers: Challenges and\n  Prospects","summary":"  The rapid growth of artificial intelligence (AI) is driving an unprecedented\nincrease in the electricity demand of AI data centers, raising emerging\nchallenges for electric power grids. Understanding the characteristics of AI\ndata center loads and their interactions with the grid is therefore critical\nfor ensuring both reliable power system operation and sustainable AI\ndevelopment. This paper provides a comprehensive review and vision of this\nevolving landscape. Specifically, this paper (i) presents an overview of AI\ndata center infrastructure and its key components, (ii) examines the key\ncharacteristics and patterns of electricity demand across the stages of model\npreparation, training, fine-tuning, and inference, (iii) analyzes the critical\nchallenges that AI data center loads pose to power systems across three\ninterrelated timescales, including long-term planning and interconnection,\nshort-term operation and electricity markets, and real-time dynamics and\nstability, and (iv) discusses potential solutions from the perspectives of the\ngrid, AI data centers, and AI end-users to address these challenges. By\nsynthesizing current knowledge and outlining future directions, this review\naims to guide research and development in support of the joint advancement of\nAI data centers and power systems toward reliable, efficient, and sustainable\noperation.\n","authors":["Xin Chen","Xiaoyang Wang","Ana Colacelli","Matt Lee","Le Xie"],"pdf_url":"https://arxiv.org/pdf/2509.07218v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07203v1","updated":"2025-09-08T20:34:20Z","published":"2025-09-08T20:34:20Z","title":"Extended Version: Market-Driven Equilibria for Distributed Solar Panel\n  Investment","summary":"  This study investigates market-driven long-term investment decisions in\ndistributed solar panels by individual investors. We consider a setting where\ninvestment decisions are driven by expected revenue from participating in\nshort-term electricity markets over the panel's lifespan. These revenues depend\non short-term markets equilibria, i.e., prices and allocations, which are\ninfluenced by aggregate invested panel capacity participating in the markets.\nWe model the interactions among investors by a non-atomic game and develop a\nframework that links short-term markets equilibria to the resulting long-term\ninvestment equilibrium. Then, within this framework, we analyze three market\nmechanisms: (a) a single-product real-time energy market, (b) a\nproduct-differentiated real-time energy market that treats solar energy and\ngrid energy as different products, and (c) a contract-based panel market that\ntrades claims or rights to the production of certain panel capacity ex-ante,\nrather than the realized solar production ex-post. For each, we derive\nexpressions for short-term equilibria and the associated expected revenues, and\nanalytically characterize the corresponding long-term Nash equilibrium\naggregate capacity. We compare the solutions of these characterizing equations\nunder different conditions and theoretically establish that the\nproduct-differentiated market always supports socially optimal investment,\nwhile the single-product market consistently results in under-investment. We\nalso establish that the contract-based market leads to over-investment when the\nextra valuations of users for solar energy are small. Finally, we validate our\ntheoretical findings through numerical experiments.\n","authors":["Mehdi Davoudi","Junjie Qin","Xiaojun Lin"],"pdf_url":"https://arxiv.org/pdf/2509.07203v1.pdf","comment":"Longer version of a paper submitted to IEEE Transactions on Smart\n  Grid"},{"id":"http://arxiv.org/abs/2509.07201v1","updated":"2025-09-08T20:32:22Z","published":"2025-09-08T20:32:22Z","title":"Design of Input-Output Observers for a Population of Systems with\n  Bounded Frequency-Domain Variation using $DK$-iteration","summary":"  This paper proposes a linear input-output observer design methodology for a\npopulation of systems in which each observer uses knowledge of the linear\ntime-invariant dynamics of the particular device. Observers are typically\ncomposed of a known model of the system and a correction mechanism to produce\nan estimate of the state. The proposed design procedure characterizes the\nvariation within the population in the frequency domain and synthesizes a\nsingle robust correction filter. The correction filter is compatible with all\nsystem models that satisfy the variation characterization such that a given\nlevel of estimation performance is guaranteed. This is accomplished by posing a\nrobust performance problem using the observer error dynamics and solving it\nusing $DK$-iteration. The design procedure is experimentally demonstrated on a\nflexible joint robotic manipulator with varied joint stiffnesses. It is shown\nthat the proposed method that uses a single correction filter achieves\ncomparable estimation performance to a method that uses a correction gain\ntailored toward each joint stiffness configuration.\n","authors":["Timothy Everett Adams","James Richard Forbes"],"pdf_url":"https://arxiv.org/pdf/2509.07201v1.pdf","comment":"6 pages, 12 figures"},{"id":"http://arxiv.org/abs/2509.01777v2","updated":"2025-09-08T18:55:54Z","published":"2025-09-01T21:22:49Z","title":"Maximally Resilient Controllers under Temporal Logic Specifications","summary":"  In this paper, we consider the notion of resilience of a dynamical system,\ndefined by the maximum disturbance a controlled dynamical system can withstand\nwhile satisfying given temporal logic specifications. Given a dynamical system\nand a specification, the objective is to synthesize the controller such that\nthe closed-loop system satisfies this specification while maximizing its\nresilience. The problem is formulated as a robust optimization program where\nthe objective is to compute the maximum resilience while simultaneously\nsynthesizing the corresponding controller parameters. For linear systems and\nlinear controllers, exact solutions are provided for the class of time-varying\npolytopic specifications. For the case of nonlinear systems, nonlinear\ncontrollers and more general specifications, we leverage tools from the\nscenario optimization approach, offering a probabilistic guarantee of the\nsolution as well as computational feasibility. Different case studies are\npresented to illustrate the theoretical results.\n","authors":["Youssef Ait Si","Ratnangshu Das","Negar Monir","Sadegh Soudjani","Pushpak Jagtap","Adnane Saoud"],"pdf_url":"https://arxiv.org/pdf/2509.01777v2.pdf","comment":"8 pages, 4 figures, conference"}],"Hardware Architecture":[{"id":"http://arxiv.org/abs/2509.03377v2","updated":"2025-09-08T17:22:17Z","published":"2025-09-03T14:53:45Z","title":"Amplifying Effective CXL Memory Bandwidth for LLM Inference via\n  Transparent Near-Data Processing","summary":"  Large language model (LLM) inference is bottlenecked by the limited bandwidth\nof CXL-based memory used for capacity expansion. We introduce CXL-NDP, a\ntransparent near-data processing architecture that amplifies effective CXL\nbandwidth without requiring changes to the CXL.mem interface or AI models.\nCXL-NDP integrates a precision-scalable bit-plane layout for dynamic\nquantization with transparent lossless compression of weights and KV caches\ndirectly within the CXL device. In end-to-end serving, CXL-NDP improves\nthroughput by 43%, extends the maximum context length by 87%, and reduces the\nKV cache footprint by 46.9% without accuracy loss. Hardware synthesis confirms\nits practicality with a modest silicon footprint, lowering the barrier for\nadopting efficient, scalable CXL-based memory in generative AI infrastructure.\n","authors":["Rui Xie","Asad Ul Haq","Linsen Ma","Yunhua Fang","Zirak Burzin Engineer","Liu Liu","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2509.03377v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.06794v1","updated":"2025-09-08T15:22:51Z","published":"2025-09-08T15:22:51Z","title":"Dato: A Task-Based Programming Model for Dataflow Accelerators","summary":"  Recent deep learning workloads increasingly push computational demand beyond\nwhat current memory systems can sustain, with many kernels stalling on data\nmovement rather than computation. While modern dataflow accelerators\nincorporate on-chip streaming to mitigate off-chip bandwidth limitations,\nexisting programming models struggle to harness these capabilities effectively.\nLow-level interfaces provide fine-grained control but impose significant\ndevelopment overhead, whereas high-level tile-based languages abstract away\ncommunication details, restricting optimization and forcing compilers to\nreconstruct the intended dataflow. We present Dato, a Python-embedded,\ntask-based programming model for dataflow accelerators that elevates data\ncommunication and sharding to first-class type constructs. Developers write\nprograms as a graph of tasks connected via explicit stream types, with sharded\ninputs specified using layout types. These tasks are first mapped virtually\nonto the accelerator's spatial fabric, and the compiler then generates a\nphysical mapping that respects hardware constraints. Experimental results on\nboth AMD Ryzen AI NPU and Alveo FPGA devices demonstrate that Dato achieves\nhigh performance while significantly reducing the burden of writing optimized\ncode. On the NPU, Dato attains up to 84% hardware utilization for GEMM and\ndelivers a 2.81x speedup on attention kernels compared to a state-of-the-art\ncommercial framework. On the FPGA, Dato surpasses leading frameworks in\nperformance when generating custom systolic arrays, achieving 98% of the\ntheoretical peak performance.\n","authors":["Shihan Fang","Hongzheng Chen","Niansong Zhang","Jiajie Li","Han Meng","Adrian Liu","Zhiru Zhang"],"pdf_url":"https://arxiv.org/pdf/2509.06794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.11506v2","updated":"2025-09-08T14:03:34Z","published":"2025-07-15T17:21:31Z","title":"ELK: Exploring the Efficiency of Inter-core Connected AI Chips with Deep\n  Learning Compiler Techniques","summary":"  To meet the increasing demand of deep learning (DL) models, AI chips are\nemploying both off-chip memory (e.g., HBM) and high-bandwidth low-latency\ninterconnect for direct inter-core data exchange. However, it is not easy to\nexplore the efficiency of these inter-core connected AI (ICCA) chips, due to a\nfundamental tussle among compute (per-core execution), communication\n(inter-core data exchange), and I/O (off-chip data access).\n  In this paper, we develop Elk, a DL compiler framework to maximize the\nefficiency of ICCA chips by jointly trading off all the three performance\nfactors discussed above. Elk structures these performance factors into\nconfigurable parameters and forms a global trade-off space in the DL compiler.\nTo systematically explore this space and maximize overall efficiency, Elk\nemploys a new inductive operator scheduling policy and a cost-aware on-chip\nmemory allocation algorithm. It generates globally optimized execution plans\nthat best overlap off-chip data loading and on-chip execution. To examine the\nefficiency of Elk, we build a full-fledged emulator based on a real ICCA chip\nIPU-POD4, and an ICCA chip simulator for sensitivity analysis with different\ninterconnect network topologies. Elk achieves 94% of the ideal roofline\nperformance of ICCA chips on average, showing the benefits of supporting large\nDL models on ICCA chips. We also show Elk's capability of enabling architecture\ndesign space exploration for new ICCA chip development.\n","authors":["Yiqi Liu","Yuqi Xue","Noelle Crawford","Jilong Xue","Jian Huang"],"pdf_url":"https://arxiv.org/pdf/2507.11506v2.pdf","comment":"This paper is accepted at the 58th IEEE/ACM International Symposium\n  on Microarchitecture (MICRO'25)"},{"id":"http://arxiv.org/abs/2509.06698v1","updated":"2025-09-08T13:52:33Z","published":"2025-09-08T13:52:33Z","title":"VCO-CARE: VCO-based Calibration-free Analog Readout for Electrodermal\n  activity sensing","summary":"  Continuous monitoring of electrodermal activity (EDA) through wearable\ndevices has attracted much attention in recent times. However, the persistent\nchallenge demands analog front-end (AFE) systems with high sensitivity, low\npower consumption, and minimal calibration requirements to ensure practical\nusability in wearable technologies. In response to this challenge, this\nresearch introduces VCO-CARE, a Voltage-Controlled Oscillator-based Analog\nReadout tailored for continuous EDA sensing. The results show that our system\nachieves an exceptional average sensitivity of up to 40 pS within a 0-20 uS\nrange and a negligible relative error of less than 0.0025% for\nfixed-resistance. Furthermore, the proposed system consumes only an average of\n2.3 uW based on post-layout validations and introduces a low noise\ncontribution, measuring only 0.8 uVrms across the 0-1.5 Hz EDA signal band.\nThis research aims to drive the evolution of wearable sensors characterized by\nseamless adaptability to diverse users, minimal power consumption, and\noutstanding noise resilience.\n","authors":["Leidy Mabel Alvero-Gonzalez","Matias Miguez","Eric Gutierrez","Juan Sapriza","Susana Patón","David Atienza","José Miranda"],"pdf_url":"https://arxiv.org/pdf/2509.06698v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.06690v1","updated":"2025-09-08T13:44:55Z","published":"2025-09-08T13:44:55Z","title":"BioLite U-Net: Edge-Deployable Semantic Segmentation for In Situ\n  Bioprinting Monitoring","summary":"  Bioprinting is a rapidly advancing field that offers a transformative\napproach to fabricating tissue and organ models through the precise deposition\nof cell-laden bioinks. Ensuring the fidelity and consistency of printed\nstructures in real-time remains a core challenge, particularly under\nconstraints imposed by limited imaging data and resource-constrained embedded\nhardware. Semantic segmentation of the extrusion process, differentiating\nbetween nozzle, extruded bioink, and surrounding background, enables in situ\nmonitoring critical to maintaining print quality and biological viability. In\nthis work, we introduce a lightweight semantic segmentation framework tailored\nfor real-time bioprinting applications. We present a novel, manually annotated\ndataset comprising 787 RGB images captured during the bioprinting process,\nlabeled across three classes: nozzle, bioink, and background. To achieve fast\nand efficient inference suitable for integration with bioprinting systems, we\npropose a BioLite U-Net architecture that leverages depthwise separable\nconvolutions to drastically reduce computational load without compromising\naccuracy. Our model is benchmarked against MobileNetV2 and MobileNetV3-based\nsegmentation baselines using mean Intersection over Union (mIoU), Dice score,\nand pixel accuracy. All models were evaluated on a Raspberry Pi 4B to assess\nreal-world feasibility. The proposed BioLite U-Net achieves an mIoU of 92.85%\nand a Dice score of 96.17%, while being over 1300x smaller than\nMobileNetV2-DeepLabV3+. On-device inference takes 335 ms per frame,\ndemonstrating near real-time capability. Compared to MobileNet baselines,\nBioLite U-Net offers a superior tradeoff between segmentation accuracy,\nefficiency, and deployability, making it highly suitable for intelligent,\nclosed-loop bioprinting systems.\n","authors":["Usman Haider","Lukasz Szemet","Daniel Kelly","Vasileios Sergis","Andrew C. Daly","Karl Mason"],"pdf_url":"https://arxiv.org/pdf/2509.06690v1.pdf","comment":"8 pages, 5 figures, conference-style submission (ICRA 2026). Includes\n  dataset description, BioLite U-Net architecture, benchmark results on edge\n  device (Raspberry Pi 4B)"},{"id":"http://arxiv.org/abs/2509.06365v1","updated":"2025-09-08T06:39:23Z","published":"2025-09-08T06:39:23Z","title":"Hardware Acceleration in Portable MRIs: State of the Art and Future\n  Prospects","summary":"  There is a growing interest in portable MRI (pMRI) systems for point-of-care\nimaging, particularly in remote or resource-constrained environments. However,\nthe computational complexity of pMRI, especially in image reconstruction and\nmachine learning (ML) algorithms for enhanced imaging, presents significant\nchallenges. Such challenges can be potentially addressed by harnessing hardware\napplication solutions, though there is little focus in the current pMRI\nliterature on hardware acceleration. This paper bridges that gap by reviewing\nrecent developments in pMRI, emphasizing the role and impact of hardware\nacceleration to speed up image acquisition and reconstruction. Key technologies\nsuch as Graphics Processing Units (GPUs), Field-Programmable Gate Arrays\n(FPGAs), and Application-Specific Integrated Circuits (ASICs) offer excellent\nperformance in terms of reconstruction speed and power consumption. This review\nalso highlights the promise of AI-powered reconstruction, open low-field pMRI\ndatasets, and innovative edge-based hardware solutions for the future of pMRI\ntechnology. Overall, hardware acceleration can enhance image quality, reduce\npower consumption, and increase portability for next-generation pMRI\ntechnology. To accelerate reproducible AI for portable MRI, we propose forming\na Low-Field MRI Consortium and an evidence ladder (analytic/phantom validation,\nretrospective multi-center testing, prospective reader and non-inferiority\ntrials) to provide standardized datasets, benchmarks, and regulator-ready\ntestbeds.\n","authors":["Omar Al Habsi","Safa Mohammed Sali","Anis Meribout","Mahmoud Meribout","Saif Almazrouei","Mohamed Seghier"],"pdf_url":"https://arxiv.org/pdf/2509.06365v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.06289v1","updated":"2025-09-08T02:23:51Z","published":"2025-09-08T02:23:51Z","title":"A Spatio-Temporal Graph Neural Networks Approach for Predicting Silent\n  Data Corruption inducing Circuit-Level Faults","summary":"  Silent Data Errors (SDEs) from time-zero defects and aging degrade\nsafety-critical systems. Functional testing detects SDE-related faults but is\nexpensive to simulate. We present a unified spatio-temporal graph convolutional\nnetwork (ST-GCN) for fast, accurate prediction of long-cycle fault impact\nprobabilities (FIPs) in large sequential circuits, supporting quantitative risk\nassessment. Gate-level netlists are modeled as spatio-temporal graphs to\ncapture topology and signal timing; dedicated spatial and temporal encoders\npredict multi-cycle FIPs efficiently. On ISCAS-89 benchmarks, the method\nreduces simulation time by more than 10x while maintaining high accuracy (mean\nabsolute error 0.024 for 5-cycle predictions). The framework accepts features\nfrom testability metrics or fault simulation, allowing efficiency-accuracy\ntrade-offs. A test-point selection study shows that choosing observation points\nby predicted FIPs improves detection of long-cycle, hard-to-detect faults. The\napproach scales to SoC-level test strategy optimization and fits downstream\nelectronic design automation flows.\n","authors":["Shaoqi Wei","Senling Wang","Hiroshi Kai","Yoshinobu Higami","Ruijun Ma","Tianming Ni","Xiaoqing Wen","Hiroshi Takahashi"],"pdf_url":"https://arxiv.org/pdf/2509.06289v1.pdf","comment":"21 pages, 9 figures, plan to submit to ACM TODAES"},{"id":"http://arxiv.org/abs/2506.13905v2","updated":"2025-09-08T18:17:46Z","published":"2025-06-16T18:33:25Z","title":"Spec2RTL-Agent: Automated Hardware Code Generation from Complex\n  Specifications Using LLM Agent Systems","summary":"  Despite recent progress in generating hardware RTL code with LLMs, existing\nsolutions still suffer from a substantial gap between practical application\nscenarios and the requirements of real-world RTL code development. Prior\napproaches either focus on overly simplified hardware descriptions or depend on\nextensive human guidance to process complex specifications, limiting their\nscalability and automation potential. In this paper, we address this gap by\nproposing an LLM agent system, termed Spec2RTL-Agent, designed to directly\nprocess complex specification documentation and generate corresponding RTL code\nimplementations, advancing LLM-based RTL code generation toward more realistic\napplication settings. To achieve this goal, Spec2RTL-Agent introduces a novel\nmulti-agent collaboration framework that integrates three key enablers: (1) a\nreasoning and understanding module that translates specifications into\nstructured, step-by-step implementation plans; (2) a progressive coding and\nprompt optimization module that iteratively refines the code across multiple\nrepresentations to enhance correctness and synthesisability for RTL conversion;\nand (3) an adaptive reflection module that identifies and traces the source of\nerrors during generation, ensuring a more robust code generation flow. Instead\nof directly generating RTL from natural language, our system strategically\ngenerates synthesizable C++ code, which is then optimized for HLS. This\nagent-driven refinement ensures greater correctness and compatibility compared\nto naive direct RTL generation approaches. We evaluate Spec2RTL-Agent on three\nspecification documents, showing it generates accurate RTL code with up to 75%\nfewer human interventions than existing methods. This highlights its role as\nthe first fully automated multi-agent system for RTL generation from\nunstructured specs, reducing reliance on human effort in hardware design.\n","authors":["Zhongzhi Yu","Mingjie Liu","Michael Zimmer","Yingyan Celine Lin","Yong Liu","Haoxing Ren"],"pdf_url":"https://arxiv.org/pdf/2506.13905v2.pdf","comment":null}],"Programming Languages":[{"id":"http://arxiv.org/abs/2509.06872v1","updated":"2025-09-08T16:42:02Z","published":"2025-09-08T16:42:02Z","title":"Mechanized Metatheory of Forward Reasoning for End-to-End\n  Linearizability Proofs","summary":"  In the past decade, many techniques have been developed to prove\nlinearizability, the gold standard of correctness for concurrent data\nstructures. Intuitively, linearizability requires that every operation on a\nconcurrent data structure appears to take place instantaneously, even when\ninterleaved with other operations. Most recently, Jayanti et al. presented the\nfirst sound and complete \"forward reasoning\" technique for proving\nlinearizability that relates the behavior of a concurrent data structure to a\nreference atomic data structure as time moves forward. This technique can be\nused to produce machine-checked proofs of linearizability in TLA+. However,\nwhile Jayanti et al.'s approach is shown to be sound and complete, a\nmechanization of this important metatheoretic result is still outstanding. As a\nresult, it is not possible to produce verified end-to-end proofs of\nlinearizability. To reduce the size of this trusted computing base, we\nformalize this forward reasoning technique and mechanize proofs of its\nsoundness and completeness in Rocq. As a case study, we use the approach to\nproduce a verified end-to-end proof of linearizability for a simple concurrent\nregister.\n","authors":["Zachary Kent","Ugur Y. Yavuz","Siddhartha Jayanti","Stephanie Balzer","Guy Blelloch"],"pdf_url":"https://arxiv.org/pdf/2509.06872v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.06845v1","updated":"2025-09-08T16:15:18Z","published":"2025-09-08T16:15:18Z","title":"MIO: Multiverse Debugging in the Face of Input/Output -- Extended\n  Version with Additional Appendices","summary":"  Debugging non-deterministic programs on microcontrollers is notoriously\nchallenging, especially when bugs manifest in unpredictable, input-dependent\nexecution paths. A recent approach, called multiverse debugging, makes it\neasier to debug non-deterministic programs by allowing programmers to explore\nall potential execution paths. Current multiverse debuggers enable both forward\nand backward traversal of program paths, and some facilitate jumping to any\npreviously visited states, potentially branching into alternative execution\npaths within the state space.\n  Unfortunately, debugging programs that involve input/output operations using\nexisting multiverse debuggers can reveal inaccessible program states, i.e.\nstates which are not encountered during regular execution. This can\nsignificantly hinder the debugging process, as the programmer may spend\nsubstantial time exploring and examining inaccessible program states, or worse,\nmay mistakenly assume a bug is present in the code, when in fact, the issue is\ncaused by the debugger.\n  This paper presents a novel approach to multiverse debugging, which can\naccommodate a broad spectrum of input/output operations. We provide the\nsemantics of our approach and prove the correctness of our debugger, ensuring\nthat despite having support for a wide range of input/output operations the\ndebugger will only explore those program states which can be reached during\nregular execution.\n  We have developed a prototype, called MIO, leveraging the WARDuino\nWebAssembly virtual machine to demonstrate the feasibility and efficiency of\nour techniques. As a demonstration of the approach we highlight a color dial\nbuilt with a Lego Mindstorms motor, and color sensor, providing a tangible\nexample of how our approach enables multiverse debugging for programs running\non an STM32 microcontroller.\n","authors":["Tom Lauwaerts","Maarten Steevens","Christophe Scholliers"],"pdf_url":"https://arxiv.org/pdf/2509.06845v1.pdf","comment":"This extended version provides auxiliary material to the article of\n  the same title that will appear in the ACM Digital Library as part of the\n  PACMPL issue for OOPSLA 2025"},{"id":"http://arxiv.org/abs/2509.06794v1","updated":"2025-09-08T15:22:51Z","published":"2025-09-08T15:22:51Z","title":"Dato: A Task-Based Programming Model for Dataflow Accelerators","summary":"  Recent deep learning workloads increasingly push computational demand beyond\nwhat current memory systems can sustain, with many kernels stalling on data\nmovement rather than computation. While modern dataflow accelerators\nincorporate on-chip streaming to mitigate off-chip bandwidth limitations,\nexisting programming models struggle to harness these capabilities effectively.\nLow-level interfaces provide fine-grained control but impose significant\ndevelopment overhead, whereas high-level tile-based languages abstract away\ncommunication details, restricting optimization and forcing compilers to\nreconstruct the intended dataflow. We present Dato, a Python-embedded,\ntask-based programming model for dataflow accelerators that elevates data\ncommunication and sharding to first-class type constructs. Developers write\nprograms as a graph of tasks connected via explicit stream types, with sharded\ninputs specified using layout types. These tasks are first mapped virtually\nonto the accelerator's spatial fabric, and the compiler then generates a\nphysical mapping that respects hardware constraints. Experimental results on\nboth AMD Ryzen AI NPU and Alveo FPGA devices demonstrate that Dato achieves\nhigh performance while significantly reducing the burden of writing optimized\ncode. On the NPU, Dato attains up to 84% hardware utilization for GEMM and\ndelivers a 2.81x speedup on attention kernels compared to a state-of-the-art\ncommercial framework. On the FPGA, Dato surpasses leading frameworks in\nperformance when generating custom systolic arrays, achieving 98% of the\ntheoretical peak performance.\n","authors":["Shihan Fang","Hongzheng Chen","Niansong Zhang","Jiajie Li","Han Meng","Adrian Liu","Zhiru Zhang"],"pdf_url":"https://arxiv.org/pdf/2509.06794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.06752v1","updated":"2025-09-08T14:40:34Z","published":"2025-09-08T14:40:34Z","title":"Termination Analysis of Linear-Constraint Programs","summary":"  This Survey provides an overview of techniques in termination analysis for\nprograms with numerical variables and transitions defined by linear\nconstraints. This subarea of program analysis is challenging due to the\nexistence of undecidable problems, and this Survey systematically explores\napproaches that mitigate this inherent difficulty. These include foundational\ndecidability results, the use of ranking functions, and disjunctive\nwell-founded transition invariants. The Survey also discusses non-termination\nwitnesses, used to prove that a program will not halt. We examine the\nalgorithmic and complexity aspects of these methods, showing how different\napproaches offer a trade-off between expressive power and computational\ncomplexity. The Survey does not discuss how termination analysis is performed\non real-world programming languages, nor does it consider more expressive\nabstract models that include non-linear arithmetic, probabilistic choice, or\nterm rewriting systems.\n","authors":["Amir M. Ben-Amram","Samir Genaim","Joël Ouaknine","James Worrell"],"pdf_url":"https://arxiv.org/pdf/2509.06752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.06724v1","updated":"2025-09-08T14:22:00Z","published":"2025-09-08T14:22:00Z","title":"Pacing Types: Safe Monitoring of Asynchronous Streams","summary":"  Stream-based monitoring is a real-time safety assurance mechanism for complex\ncyber-physical systems such as unmanned aerial vehicles. In this context, a\nmonitor aggregates streams of input data from sensors and other sources to give\nreal-time statistics and assessments of the system's health. Since monitors are\nsafety-critical components, it is crucial to ensure that they are free of\npotential runtime errors. One of the central challenges in designing reliable\nstream-based monitors is to deal with the asynchronous nature of data streams:\nin concrete applications, the different sensors being monitored produce values\nat different speeds, and it is the monitor's responsibility to correctly react\nto the asynchronous arrival of different streams of values. To ease this\nprocess, modern frameworks for stream-based monitoring such as RTLola feature\nan expressive specification language that allows to finely specify data\nsynchronization policies. While this feature dramatically simplifies the design\nof monitors, it can also lead to subtle runtime errors. To mitigate this issue,\nthis paper presents pacing types, a novel type system implemented in RTLola to\nensure that monitors for asynchronous streams are well-behaved at runtime. We\nformalize the essence of pacing types for a core fragment of RTLola, and\npresent a soundness proof of the pacing type system using a new logical\nrelation.\n","authors":["Florian Kohn","Arthur Correnson","Jan Baumeister","Bernd Finkbeiner"],"pdf_url":"https://arxiv.org/pdf/2509.06724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.15137v3","updated":"2025-09-08T23:15:20Z","published":"2025-08-21T00:19:43Z","title":"Software Model Checking via Summary-Guided Search (Extended Version)","summary":"  In this work, we describe a new software model-checking algorithm called GPS.\nGPS treats the task of model checking a program as a directed search of the\nprogram states, guided by a compositional, summary-based static analysis. The\nsummaries produced by static analysis are used both to prune away infeasible\npaths and to drive test generation to reach new, unexplored program states. GPS\ncan find both proofs of safety and counter-examples to safety (i.e., inputs\nthat trigger bugs), and features a novel two-layered search strategy that\nrenders it particularly efficient at finding bugs in programs featuring long,\ninput-dependent error paths. To make GPS refutationally complete (in the sense\nthat it will find an error if one exists, if it is allotted enough time), we\nintroduce an instrumentation technique and show that it helps GPS achieve\nrefutation-completeness without sacrificing overall performance. We benchmarked\nGPS on a diverse suite of benchmarks including programs from the Software\nVerification Competition (SV-COMP), from prior literature, as well as synthetic\nprograms based on examples in this paper. We found that our implementation of\nGPS outperforms state-of-the-art software model checkers (including the top\nperformers in SV-COMP ReachSafety-Loops category), both in terms of the number\nof benchmarks solved and in terms of running time.\n","authors":["Ruijie Fang","Zachary Kincaid","Thomas Reps"],"pdf_url":"https://arxiv.org/pdf/2508.15137v3.pdf","comment":"Extended version of paper in OOPSLA 2025 (with typo and stylistic\n  fixes compared to v2 manuscript). 37 pages"},{"id":"http://arxiv.org/abs/2507.03659v3","updated":"2025-09-08T19:11:06Z","published":"2025-07-04T15:36:12Z","title":"Specification-Guided Repair of Arithmetic Errors in Dafny Programs using\n  LLMs","summary":"  Debugging and repairing faults when programs fail to formally verify can be\ncomplex and time-consuming. Automated Program Repair (APR) can ease this burden\nby automatically identifying and fixing faults. However, traditional APR\ntechniques often rely on test suites for validation, but these may not capture\nall possible scenarios. In contrast, formal specifications provide strong\ncorrectness criteria, enabling more effective automated repair.\n  In this paper, we present an APR tool for Dafny, a verification-aware\nprogramming language that uses formal specifications - including\npre-conditions, post-conditions, and invariants - as oracles for fault\nlocalization and repair. Assuming the correctness of the specifications and\nfocusing on arithmetic bugs, we localize faults through a series of steps,\nwhich include using Hoare logic to determine the state of each statement within\nthe program, and applying Large Language Models (LLMs) to synthesize candidate\nfixes. The models considered are GPT-4o mini, Llama 3, Mistral 7B, and Llemma\n7B.\n  We evaluate our approach using DafnyBench, a benchmark of real-world Dafny\nprograms. Our tool achieves 89.6% fault localization coverage and GPT-4o mini\nyields the highest repair success rate of 74.18%. These results highlight the\npotential of combining formal reasoning with LLM-based program synthesis for\nautomated program repair.\n","authors":["Valentina Wu","Alexandra Mendes","Alexandre Abreu"],"pdf_url":"https://arxiv.org/pdf/2507.03659v3.pdf","comment":null}],"Data Structures and Algorithms":[{"id":"http://arxiv.org/abs/2509.06900v1","updated":"2025-09-08T17:18:37Z","published":"2025-09-08T17:18:37Z","title":"Engineering Select Support for Hybrid Bitvectors","summary":"  One of the central problems in the design of compressed data structures is\nthe efficient support for rank and select queries on bitvectors. These two\noperations form the backbone of more complex data structures (such as wavelet\ntrees) used for the compact representation of texts, trees, graphs, or grids.\nTheir efficient implementation is one of the most frequently studied problems\nin compressed data structures.\n  One effective solution is the so-called hybrid bitvector implementation,\nwhich partitions the input bitvector into blocks and adaptively selects an\nencoding method, such as run-length, plain, or minority encoding, based on\nlocal redundancy. Experiments have shown that hybrid bitvectors achieve\nexcellent all-around performance on repetitive and non-repetitive inputs.\n  However, current implementations support only rank queries (i.e., counting\nthe number of ones up to a given position) and lack support for select queries.\nThis limitation significantly restricts their applicability. In this paper, we\npropose a method to add support for select queries to hybrid bitvectors, and we\nconduct an extensive set of experiments. Our results show that hybrid\nbitvectors offer excellent performance, matching the speed of the fastest and\nthe space efficiency of the most compact existing bitvectors.\n","authors":["Eric Chiu","Dominik Kempa"],"pdf_url":"https://arxiv.org/pdf/2509.06900v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.06789v1","updated":"2025-09-08T15:18:02Z","published":"2025-09-08T15:18:02Z","title":"The Steiner Shortest Path Tree Problem","summary":"  We introduce and study a novel problem of computing a shortest path tree with\na minimum number of non-terminals. It can be viewed as an (unweighted) Steiner\nShortest Path Tree (SSPT) that spans a given set of terminal vertices by\nshortest paths from a given source while minimizing the number of nonterminal\nvertices included in the tree. This problem is motivated by applications where\nshortest-path connections from a source are essential, and where reducing the\nnumber of intermediate vertices helps limit cost, complexity, or overhead. We\nshow that the SSPT problem is NP-hard. To approximate it, we introduce and\nstudy the shortest path subgraph of a graph. Using it, we show an\napproximation-preserving reduction of SSPT to the uniform vertex-weighted\nvariant of the Directed Steiner Tree (DST) problem, termed UVDST. Consequently,\nthe algorithm of [Grandoni et al., 2023] approximating DST implies a\nquasi-polynomial polylog-approximation algorithm for SSPT. We present a\npolynomial polylog-approximation algorithm for UVDST, and thus for SSPT, for a\nrestricted class of graphs.\n","authors":["Omer Asher","Yefim Dinitz","Shlomi Dolev","Li-on Raviv","Baruch Schieber"],"pdf_url":"https://arxiv.org/pdf/2509.06789v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.06623v1","updated":"2025-09-08T12:41:14Z","published":"2025-09-08T12:41:14Z","title":"Zero-Freeness is All You Need: A Weitz-Type FPTAS for the Entire\n  Lee-Yang Zero-Free Region","summary":"  We present a Weitz-type FPTAS for the ferromagnetic Ising model across the\nentire Lee-Yang zero-free region, without relying on the strong spatial mixing\n(SSM) property. Our algorithm is Weitz-type for two reasons. First, it\nexpresses the partition function as a telescoping product of ratios, with the\nkey being to approximate each ratio. Second, it uses Weitz's self-avoiding walk\ntree, and truncates it at logarithmic depth to give a good and efficient\napproximation. The key difference from the standard Weitz algorithm is that we\napproximate a carefully designed edge-deletion ratio instead of the marginal\nprobability of a vertex's spin, ensuring our algorithm does not require SSM.\n  Furthermore, by establishing local dependence of coefficients (LDC), we\nindeed prove a novel form of SSM for these edge-deletion ratios, which, in\nturn, implies the standard SSM for the random cluster model. This is the first\nSSM result for the random cluster model on general graphs, beyond lattices. We\nprove LDC using a new division relation, and remarkably, such relations hold\nquite universally. As a result, we establish LDC for a variety of models.\nCombined with existing zero-freeness results for these models, we derive new\nSSM results for them. Our work suggests that both Weitz-type FPTASes and SSM\ncan be derived from zero-freeness, while zero-freeness alone suffices for\nWeitz-type FPTASes, SSM additionally requires LDC, a combinatorial property\nindependent of zero-freeness.\n","authors":["Shuai Shao","Ke Shi"],"pdf_url":"https://arxiv.org/pdf/2509.06623v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11561v2","updated":"2025-09-08T08:04:46Z","published":"2025-02-17T08:48:29Z","title":"Resident fitness computation in linear time and other algorithmic\n  aspects of interacting trajectories","summary":"  The notion of a system of interacting trajectories was recently introduced by\nHermann, Gonz\\'alez Casanova, Soares dos Santos, T\\'obi\\'as and Wakolbinger.\nSuch a system of $[0,1]$-valued piecewise linear trajectories arises as a\nscaling limit of the system of logarithmic subpopulation sizes in a\npopulation-genetic model (more precisely, a Moran model) with mutation and\nselection. By definition, the resident fitness is initially 0 and afterwards it\nincreases by the ultimate slope of each trajectory that reaches height 1.\n  We show that although the interaction of $n$ trajectories may yield\n$\\Omega(n^2)$ slope changes in total, the resident fitness function can be\ncomputed algorithmically in $O(n)$ time. Our algorithm uses the so-called\ncontinued lines representation of the system of interacting trajectories. In\nthe special case of Poissonian interacting trajectories where the birth times\nof the trajectories form a Poisson process and the initial slopes are random\nand i.i.d., we provide a linear bound on the expected total number of slope\nchanges.\n","authors":["Katalin Friedl","Viktória Nemkin","András Tóbiás"],"pdf_url":"https://arxiv.org/pdf/2502.11561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.11236v3","updated":"2025-09-08T07:00:19Z","published":"2025-07-15T12:06:11Z","title":"Improved sampling algorithms and Poincaré inequalities for\n  non-log-concave distributions","summary":"  We study the problem of sampling from a distribution $\\mu$ with density\n$\\propto e^{-V}$ for some potential function $V:\\mathbb R^d\\to \\mathbb R$ with\nquery access to $V$ and $\\nabla V$. We start with the following standard\nassumptions:\n  (1) The potential function $V$ is $L$-smooth.\n  (2) The second moment $\\mathbf{E}_{X\\sim \\mu}[\\|X\\|^2]\\leq M$.\n  Recently, He and Zhang (COLT'25) showed that the query complexity of sampling\nfrom such distributions is at least\n$\\left(\\frac{LM}{d\\epsilon}\\right)^{\\Omega(d)}$ where $\\epsilon$ is the desired\naccuracy in total variation distance, and the Poincar\\'e constant can be\narbitrarily large.\n  Meanwhile, another common assumption in the study of diffusion based samplers\n(see e.g., the work of Chen, Chewi, Li, Li, Salim and Zhang (ICLR'23))\nstrengthens the smoothness condition (1) to the following:\n  (1*) The potential function of *every* distribution along the\nOrnstein-Uhlenbeck process starting from $\\mu$ is $L$-smooth.\n  We show that under the assumptions (1*) and (2), the query complexity of\nsampling from $\\mu$ can be $\\mathrm{poly}(L,d)\\cdot\n\\left(\\frac{Ld+M}{\\epsilon^2}\\right)^{\\mathcal{O}(L+1)}$, which is polynomial\nin $d$ and $\\frac{1}{\\epsilon}$ when $L=\\mathcal{O}(1)$ and\n$M=\\mathrm{poly}(d)$. This improves the algorithm with quasi-polynomial query\ncomplexity developed by Huang et al. (COLT'24). Our results imply that the\nseemly moderate strengthening of the smoothness condition (1) to (1*) can lead\nto an exponential gap in the query complexity of sampling algorithms.\n  Moreover, we show that together with the assumption (1*) and the stronger\nmoment assumption that $\\|X\\|$ is $\\lambda$-sub-Gaussian for $X\\sim\\mu$, the\nPoincar\\'e constant of $\\mu$ is at most $\\mathcal{O}(\\lambda)^{2(L+1)}$. As an\napplication of our technique, we obtain improved estimate of the Poincar\\'e\nconstant for mixture of Gaussians with the same covariance.\n","authors":["Yuchen He","Zhehan Lei","Jianan Shao","Chihao Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.11236v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.04949v2","updated":"2025-09-08T06:55:46Z","published":"2025-05-08T05:08:23Z","title":"With a Little Help From My Friends: Exploiting Probability Distribution\n  Advice in Algorithm Design","summary":"  We study online algorithms with predictions using distributional advice, a\ntype of prediction that arises when leveraging expert knowledge or historical\ndata. To demonstrate the usefulness and versatility of this framework, we focus\non the fundamental problem of online metric matching, considering both the\nfractional and integral variants. Our main positive result is, for the former,\nan algorithm achieving the optimal cost under perfect advice, while smoothly\ndefaulting to competitive ratios comparable to advice-free algorithms as the\nprediction's quality degrades. For the integral matching, we are able to\nprovide an algorithm with essentially the same guarantees, up to an additive\nsublinear term. We conclude by discussing how our algorithmic framework can be\nextended to other online optimization problems.\n","authors":["Clément L. Canonne","Kenny Chen","Julián Mestre"],"pdf_url":"https://arxiv.org/pdf/2505.04949v2.pdf","comment":"Extending the results on online matching, and removing the warmup\n  section on prophet inequalities after being made aware of a gap in one of the\n  earlier proofs"},{"id":"http://arxiv.org/abs/2508.21423v2","updated":"2025-09-08T05:59:52Z","published":"2025-08-29T08:49:41Z","title":"Constructive l2-Discrepancy Minimization with Additive Deviations","summary":"  The \\emph{signed series} problem in the $\\ell_2$ norm asks, given set of\nvectors $v_1,\\ldots,v_n\\in \\mathbf{R}^d$ having at most unit $\\ell_2$ norm,\ndoes there always exist a series $(\\varepsilon_i)_{i\\in [n]}$ of $\\pm 1$ signs\nsuch that for all $i\\in [n]$, $\\max_{i\\in [n]} \\|\\sum_{j=1}^i \\varepsilon_i\nv_i\\|_2 = O(\\sqrt{d})$. A result of Banaszczyk [2012, \\emph{Rand. Struct.\nAlg.}] states that there exist signs $\\varepsilon_i\\in \\{-1,1\\},\\; i\\in [n]$\nsuch that $\\max_{i\\in [n]} \\|\\sum_{j=1}^i \\varepsilon_i v_i\\|_2 =\nO(\\sqrt{d+\\log n})$. The best constructive bound known so far is of\n$O(\\sqrt{d\\log n})$, by Bansal and Garg [2017, \\emph{STOC.}, 2019, \\emph{SIAM\nJ. Comput.}]. We give a polynomial-time randomized algorithm to find signs\n$x(i) \\in \\{-1,1\\},\\; i\\in [n]$ such that \\[ \\max_{i\\in [n]} \\|\\sum_{j=1}^i\nx(i)v_i\\|_2 = O(\\sqrt{d + \\log^2 n}) = O(\\sqrt{d}+\\log n).\\] By the\nconstructive reduction of Harvey and Samadi [\\emph{COLT}, 2014], this also\nyields a constructive bound of $O(\\sqrt{d}+\\log n)$ for the Steinitz problem in\nthe $\\ell_2$-norm. Thus, we algorithmically achieve Banaszczyk's bounds for\nboth problems when $d \\geq \\log^2n$, which also matches the conjectured bounds.\nOur algorithm is based on the framework on Bansal and Garg, together with a new\nanalysis involving $(i)$ additional linear and spectral orthogonality\nconstraints during the construction of the covariance matrix of the random walk\nsteps, which allow us to control the quadratic variation in the linear as well\nas the quadratic components of the discrepancy increment vector, alongwith\n$(ii)$ a ``Freedman-like\" version of the Hanson-Wright concentration\ninequality, for filtration-dependent sums of subgaussian chaoses.\n","authors":["Kunal Dutta"],"pdf_url":"https://arxiv.org/pdf/2508.21423v2.pdf","comment":"A preliminary version was submitted to a conference"},{"id":"http://arxiv.org/abs/2407.10401v2","updated":"2025-09-08T05:52:58Z","published":"2024-07-15T02:41:51Z","title":"The Average-Value Allocation Problem","summary":"  We initiate the study of centralized algorithms for welfare-maximizing\nallocation of goods to buyers subject to average-value constraints. We show\nthat this problem is NP-hard to approximate beyond a factor of $\\frac{e}{e-1}$,\nand provide a $\\frac{4e}{e-1}$-approximate offline algorithm. For the online\nsetting, we show that no non-trivial approximations are achievable under\nadversarial arrivals. Under i.i.d. arrivals, we present a polytime online\nalgorithm that provides a constant approximation of the optimal\n(computationally-unbounded) online algorithm. In contrast, we show that no\nconstant approximation of the ex-post optimum is achievable by an online\nalgorithm.\n","authors":["Kshipra Bhawalkar","Zhe Feng","Anupam Gupta","Aranyak Mehta","David Wajc","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2407.10401v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07286v1","updated":"2025-09-08T23:39:56Z","published":"2025-09-08T23:39:56Z","title":"Optimal streaming algorithm for detecting $\\ell_2$ heavy hitters in\n  random order streams","summary":"  Given a stream $x_1,x_2,\\dots,x_n$ of items from a Universe $U$ of size\n$\\mathsf{poly}(n)$, and a parameter $\\epsilon>0$, an item $i\\in U$ is said to\nbe an $\\ell_2$ heavy hitter if its frequency $f_i$ in the stream is at least\n$\\sqrt{\\epsilon F_2}$, where $F_2=\\sqrt{\\sum_{i\\in U} f_i^2}$. The classical\n$\\mathsf{CountSketch}$ algorithm due to Charikar, Chen, and Farach-Colton\n[2004], was the first algorithm to detect $\\ell_2$ heavy hitters using\n$O\\left(\\frac{\\log^2 n}{\\epsilon}\\right)$ bits of space, and their algorithm is\noptimal for streams with deletions. For insertion-only streams, Braverman,\nChestnut, Ivkin, Nelson, Wang, and Woodruff [2017] gave the $\\mathsf{BPTree}$\nalgorithm which requires only $O\\left(\\frac{\\log(1/\\epsilon)}{\\epsilon}\\log n\n\\right)$ space. Note that any algorithm requires at least\n$O\\left(\\frac{1}{\\epsilon} \\log n\\right)$ space to output $O(1/\\epsilon)$ heavy\nhitters in the worst case. So for constant $\\epsilon$, the space usage of the\n$\\mathsf{BPTree}$ algorithm is optimal but their bound could be sub-optimal for\n$\\epsilon=o(1)$. In this work, we show that for random order streams, where the\nstream elements can be adversarial but their order of arrival is uniformly\nrandom, it is possible to achieve the optimal space bound of\n$O\\left(\\frac{1}{\\epsilon} \\log n\\right)$ for every $\\epsilon =\n\\Omega\\left(\\frac{1}{2^{\\sqrt{\\log n}}}\\right)$. We also show that for\npartially random order streams where only the heavy hitters are required to be\nuniformly distributed in the stream, it is possible to achieve the same space\nbound, but with an additional assumption that the algorithm is given a constant\napproximation to $F_2$ in advance.\n","authors":["Santhoshini Velusamy","Huacheng Yu"],"pdf_url":"https://arxiv.org/pdf/2509.07286v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07155v1","updated":"2025-09-08T19:09:05Z","published":"2025-09-08T19:09:05Z","title":"Quantum algorithms for general nonlinear dynamics based on the Carleman\n  embedding","summary":"  Important nonlinear dynamics, such as those found in plasma and fluid\nsystems, are typically hard to simulate on classical computers. Thus, if\nfault-tolerant quantum computers could efficiently solve such nonlinear\nproblems, it would be a transformative change for many industries. In a recent\nbreakthrough [Liu et al., PNAS 2021], the first efficient quantum algorithm for\nsolving nonlinear differential equations was constructed, based on a single\ncondition $R<1$, where $R$ characterizes the ratio of nonlinearity to\ndissipation. This result, however, is limited to the class of purely\ndissipative systems with negative log-norm, which excludes application to many\nimportant problems. In this work, we correct technical issues with this and\nother prior analysis, and substantially extend the scope of nonlinear dynamical\nsystems that can be efficiently simulated on a quantum computer in a number of\nways. Firstly, we extend the existing results from purely dissipative systems\nto a much broader class of stable systems, and show that every quadratic\nLyapunov function for the linearized system corresponds to an independent\n$R$-number criterion for the convergence of the Carlemen scheme. Secondly, we\nextend our stable system results to physically relevant settings where\nconserved polynomial quantities exist. Finally, we provide extensive results\nfor the class of non-resonant systems. With this, we are able to show that\nefficient quantum algorithms exist for a much wider class of nonlinear systems\nthan previously known, and prove the BQP-completeness of nonlinear oscillator\nproblems of exponential size. In our analysis, we also obtain several results\nrelated to the Poincar\\'{e}-Dulac theorem and diagonalization of the Carleman\nmatrix, which could be of independent interest.\n","authors":["David Jennings","Kamil Korzekwa","Matteo Lostaglio","Andrew T Sornborger","Yigit Subasi","Guoming Wang"],"pdf_url":"https://arxiv.org/pdf/2509.07155v1.pdf","comment":"70+78 pages, 4 figures. Comments welcome!"},{"id":"http://arxiv.org/abs/2211.08373v5","updated":"2025-09-08T17:50:37Z","published":"2022-11-15T18:23:29Z","title":"SDPs and Robust Satisfiability of Promise CSP","summary":"  For a constraint satisfaction problem (CSP), a robust satisfaction algorithm\nis one that outputs an assignment satisfying most of the constraints on\ninstances that are near-satisfiable. It is known that the CSPs that admit\nefficient robust satisfaction algorithms are precisely those of bounded width,\ni.e., CSPs whose satisfiability can be checked by a simple local consistency\nalgorithm (eg., 2-SAT or Horn-SAT in the Boolean case). While the exact\nsatisfiability of a bounded width CSP can be checked by combinatorial\nalgorithms, the robust algorithm is based on rounding a canonical Semidefinite\nProgramming (SDP) relaxation.\n  In this work, we initiate the study of robust satisfaction algorithms for\npromise CSPs, which are a vast generalization of CSPs that have received much\nattention recently. The motivation is to extend the theory beyond CSPs, as well\nas to better understand the power of SDPs. We present robust SDP rounding\nalgorithms under some general conditions, namely the existence of particular\nhigh-dimensional Boolean symmetries known as majority or alternating threshold\npolymorphisms. On the hardness front, we prove that the lack of such\npolymorphisms makes the PCSP hard for all pairs of symmetric Boolean\npredicates. Our approach relies on SDP integrality gaps argued via the absence\nof certain colorings of the sphere, with connections to sphere Ramsey theory.\n  We conjecture that PCSPs with robust satisfaction algorithms are precisely\nthose for which the feasibility of the canonical SDP implies (exact)\nsatisfiability. We also give a precise algebraic condition, known as a minion\ncharacterization, of which PCSPs have the latter property.\n","authors":["Joshua Brakensiek","Venkatesan Guruswami","Sai Sandeep"],"pdf_url":"https://arxiv.org/pdf/2211.08373v5.pdf","comment":"Discrete Analysis"}],"Graphics":[{"id":"http://arxiv.org/abs/2509.06950v1","updated":"2025-09-08T17:58:06Z","published":"2025-09-08T17:58:06Z","title":"Scaling Transformer-Based Novel View Synthesis Models with Token\n  Disentanglement and Synthetic Data","summary":"  Large transformer-based models have made significant progress in\ngeneralizable novel view synthesis (NVS) from sparse input views, generating\nnovel viewpoints without the need for test-time optimization. However, these\nmodels are constrained by the limited diversity of publicly available scene\ndatasets, making most real-world (in-the-wild) scenes out-of-distribution. To\novercome this, we incorporate synthetic training data generated from diffusion\nmodels, which improves generalization across unseen domains. While synthetic\ndata offers scalability, we identify artifacts introduced during data\ngeneration as a key bottleneck affecting reconstruction quality. To address\nthis, we propose a token disentanglement process within the transformer\narchitecture, enhancing feature separation and ensuring more effective\nlearning. This refinement not only improves reconstruction quality over\nstandard transformers but also enables scalable training with synthetic data.\nAs a result, our method outperforms existing models on both in-dataset and\ncross-dataset evaluations, achieving state-of-the-art results across multiple\nbenchmarks while significantly reducing computational costs. Project page:\nhttps://scaling3dnvs.github.io/\n","authors":["Nithin Gopalakrishnan Nair","Srinivas Kaza","Xuan Luo","Vishal M. Patel","Stephen Lombardi","Jungyeon Park"],"pdf_url":"https://arxiv.org/pdf/2509.06950v1.pdf","comment":"Accepted at ICCV 2025"},{"id":"http://arxiv.org/abs/2403.18767v3","updated":"2025-09-08T15:54:54Z","published":"2024-03-27T17:05:06Z","title":"The best approximation pair problem relative to two subsets in a normed\n  space","summary":"  In the classical best approximation pair (BAP) problem, one is given two\nnonempty, closed, convex and disjoint subsets in a finite- or an\ninfinite-dimensional Hilbert space, and the goal is to find a pair of points,\neach from each subset, which realizes the distance between the subsets. We\ndiscuss the problem in more general normed spaces and with possibly non-convex\nsubsets, and focus our attention on the issues of uniqueness and existence of\nthe solution to the problem. As far as we know, these fundamental issues have\nnot received much attention. We present several sufficient geometric conditions\nfor the (at most) uniqueness of a BAP. These conditions are related to the\nstructure and the relative orientation of the boundaries of the subsets and to\nthe norm. We also present many sufficient conditions for the existence of a\nBAP. Our results significantly extend the horizon of a recent algorithm for\nsolving the BAP problem [Censor, Mansour, Reem, J. Approx. Theory (2024)]. The\npaper also shows, perhaps for the first time, how wide is the scope of the BAP\nproblem in terms of the scientific communities which are involved in it\n(frequently independently) and in terms of its applications.\n","authors":["Daniel Reem","Yair Censor"],"pdf_url":"https://arxiv.org/pdf/2403.18767v3.pdf","comment":"Correction of a misprint in the Acknowledgments"},{"id":"http://arxiv.org/abs/2509.06607v1","updated":"2025-09-08T12:24:27Z","published":"2025-09-08T12:24:27Z","title":"From Skin to Skeleton: Towards Biomechanically Accurate 3D Digital\n  Humans","summary":"  Great progress has been made in estimating 3D human pose and shape from\nimages and video by training neural networks to directly regress the parameters\nof parametric human models like SMPL. However, existing body models have\nsimplified kinematic structures that do not correspond to the true joint\nlocations and articulations in the human skeletal system, limiting their\npotential use in biomechanics. On the other hand, methods for estimating\nbiomechanically accurate skeletal motion typically rely on complex motion\ncapture systems and expensive optimization methods. What is needed is a\nparametric 3D human model with a biomechanically accurate skeletal structure\nthat can be easily posed. To that end, we develop SKEL, which re-rigs the SMPL\nbody model with a biomechanics skeleton. To enable this, we need training data\nof skeletons inside SMPL meshes in diverse poses.\n  We build such a dataset by optimizing biomechanically accurate skeletons\ninside SMPL meshes from AMASS sequences. We then learn a regressor from SMPL\nmesh vertices to the optimized joint locations and bone rotations. Finally, we\nre-parametrize the SMPL mesh with the new kinematic parameters. The resulting\nSKEL model is animatable like SMPL but with fewer, and\nbiomechanically-realistic, degrees of freedom. We show that SKEL has more\nbiomechanically accurate joint locations than SMPL, and the bones fit inside\nthe body surface better than previous methods. By fitting SKEL to SMPL meshes\nwe are able to \"upgrade\" existing human pose and shape datasets to include\nbiomechanical parameters. SKEL provides a new tool to enable biomechanics in\nthe wild, while also providing vision and graphics researchers with a better\nconstrained and more realistic model of human articulation. The model, code,\nand data are available for research at https://skel.is.tue.mpg.de..\n","authors":["Marilyn Keller","Keenon Werling","Soyong Shin","Scott Delp","Sergi Pujades","C. Karen Liu","Michael J. Black"],"pdf_url":"https://arxiv.org/pdf/2509.06607v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.06573v1","updated":"2025-09-08T11:35:40Z","published":"2025-09-08T11:35:40Z","title":"From Rigging to Waving: 3D-Guided Diffusion for Natural Animation of\n  Hand-Drawn Characters","summary":"  Hand-drawn character animation is a vibrant field in computer graphics,\npresenting challenges in achieving geometric consistency while conveying\nexpressive motion. Traditional skeletal animation methods maintain geometric\nconsistency but struggle with complex non-rigid elements like flowing hair and\nskirts, leading to unnatural deformation. Conversely, video diffusion models\nsynthesize realistic dynamics but often create geometric distortions in\nstylized drawings due to domain gaps. This work proposes a hybrid animation\nsystem that combines skeletal animation and video diffusion. Initially, coarse\nimages are generated from characters retargeted with skeletal animations for\ngeometric guidance. These images are then enhanced in texture and secondary\ndynamics using video diffusion priors, framing this enhancement as an\ninpainting task. A domain-adapted diffusion model refines user-masked regions\nneeding improvement, especially for secondary dynamics. To enhance motion\nrealism further, we introduce a Secondary Dynamics Injection (SDI) strategy in\nthe denoising process, incorporating features from a pre-trained diffusion\nmodel enriched with human motion priors. Additionally, to tackle unnatural\ndeformations from low-poly single-mesh character modeling, we present a Hair\nLayering Modeling (HLM) technique that uses segmentation maps to separate hair\nfrom the body, allowing for more natural animation of long-haired characters.\nExtensive experiments show that our system outperforms state-of-the-art methods\nin both quantitative and qualitative evaluations.\n","authors":["Jie Zhou","Linzi Qu","Miu-Ling Lam","Hongbo Fu"],"pdf_url":"https://arxiv.org/pdf/2509.06573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.04145v2","updated":"2025-09-08T08:40:58Z","published":"2025-09-04T12:15:55Z","title":"Hyper Diffusion Avatars: Dynamic Human Avatar Generation using Network\n  Weight Space Diffusion","summary":"  Creating human avatars is a highly desirable yet challenging task. Recent\nadvancements in radiance field rendering have achieved unprecedented\nphotorealism and real-time performance for personalized dynamic human avatars.\nHowever, these approaches are typically limited to person-specific rendering\nmodels trained on multi-view video data for a single individual, limiting their\nability to generalize across different identities. On the other hand,\ngenerative approaches leveraging prior knowledge from pre-trained 2D diffusion\nmodels can produce cartoonish, static human avatars, which are animated through\nsimple skeleton-based articulation. Therefore, the avatars generated by these\nmethods suffer from lower rendering quality compared to person-specific\nrendering methods and fail to capture pose-dependent deformations such as cloth\nwrinkles. In this paper, we propose a novel approach that unites the strengths\nof person-specific rendering and diffusion-based generative modeling to enable\ndynamic human avatar generation with both high photorealism and realistic\npose-dependent deformations. Our method follows a two-stage pipeline: first, we\noptimize a set of person-specific UNets, with each network representing a\ndynamic human avatar that captures intricate pose-dependent deformations. In\nthe second stage, we train a hyper diffusion model over the optimized network\nweights. During inference, our method generates network weights for real-time,\ncontrollable rendering of dynamic human avatars. Using a large-scale,\ncross-identity, multi-view video dataset, we demonstrate that our approach\noutperforms state-of-the-art human avatar generation methods.\n","authors":["Dongliang Cao","Guoxing Sun","Marc Habermann","Florian Bernard"],"pdf_url":"https://arxiv.org/pdf/2509.04145v2.pdf","comment":"Project webpage: https://vcai.mpi-inf.mpg.de/projects/HDA/"},{"id":"http://arxiv.org/abs/2405.15425v3","updated":"2025-09-08T22:26:42Z","published":"2024-05-24T10:42:05Z","title":"Don't Splat your Gaussians: Volumetric Ray-Traced Primitives for\n  Modeling and Rendering Scattering and Emissive Media","summary":"  Efficient scene representations are essential for many computer graphics\napplications. A general unified representation that can handle both surfaces\nand volumes simultaneously, remains a research challenge. Inspired by recent\nmethods for scene reconstruction that leverage mixtures of 3D Gaussians to\nmodel radiance fields, we formalize and generalize the modeling of scattering\nand emissive media using mixtures of simple kernel-based volumetric primitives.\nWe introduce closed-form solutions for transmittance and free-flight distance\nsampling for different kernels, and propose several optimizations to use our\nmethod efficiently within any off-the-shelf volumetric path tracer. We\ndemonstrate our method as a compact and efficient alternative to other forms of\nvolume modeling for forward and inverse rendering of scattering media.\nFurthermore, we adapt and showcase our method in radiance field optimization\nand rendering, providing additional flexibility compared to current state of\nthe art given its ray-tracing formulation. We also introduce the Epanechnikov\nkernel and demonstrate its potential as an efficient alternative to the\ntraditionally-used Gaussian kernel in scene reconstruction tasks. The\nversatility and physically-based nature of our approach allows us to go beyond\nradiance fields and bring to kernel-based modeling and rendering any\npath-tracing enabled functionality such as scattering, relighting and complex\ncamera models.\n","authors":["Jorge Condor","Sebastien Speierer","Lukas Bode","Aljaz Bozic","Simon Green","Piotr Didyk","Adrian Jarabo"],"pdf_url":"https://arxiv.org/pdf/2405.15425v3.pdf","comment":"17 pages, 17 figures"},{"id":"http://arxiv.org/abs/2509.07175v1","updated":"2025-09-08T19:48:28Z","published":"2025-09-08T19:48:28Z","title":"Efficient Computation of Voronoi Diagrams Using Point-in-Cell Tests","summary":"  Since the Voronoi diagram appears in many applications, the topic of\nimproving its computational efficiency remains attractive. We propose a novel\nyet efficient method to compute Voronoi diagrams bounded by a given domain,\ni.e., the clipped or restricted Voronoi diagrams. The intersection of the\ndomain and a Voronoi cell (domain-cell intersection) is generated by removing\nthe part outside the cell from the domain, which can be accomplished by several\nclippings. Different from the existing methods, we present an edge-based search\nscheme to find clipping planes (bisectors). A test called point-in-cell is\nfirst set up to tell whether a space point is in a target Voronoi cell or not.\nThen, for each edge of the intermediate domain-cell intersection, we will\nlaunch a clipping only if its two endpoints are respectively inside and outside\nthe corresponding Voronoi cell, where the bisector for the clipping can be\nfound by using a few times of point-in-cell tests. Therefore, our method only\ninvolves the clippings that contribute to the final results, which is a great\nadvantage over the state-of-the-art methods. Additionally, because each\ndomain-cell intersection can be generated independently, we extend the proposed\nmethod to the GPUs for computing Voronoi diagrams in parallel. The experimental\nresults show the best performance of our method compared to state-of-the-art\nones, regardless of site distribution. This paper was first submitted to\nSIGGRAPH Asia 2025.\n","authors":["Yanyang Xiao","Yao Li","Juan Cao","Zhonggui Chen"],"pdf_url":"https://arxiv.org/pdf/2509.07175v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07127v1","updated":"2025-09-08T18:28:31Z","published":"2025-09-08T18:28:31Z","title":"SVGauge: Towards Human-Aligned Evaluation for SVG Generation","summary":"  Generated Scalable Vector Graphics (SVG) images demand evaluation criteria\ntuned to their symbolic and vectorial nature: criteria that existing metrics\nsuch as FID, LPIPS, or CLIPScore fail to satisfy. In this paper, we introduce\nSVGauge, the first human-aligned, reference based metric for text-to-SVG\ngeneration. SVGauge jointly measures (i) visual fidelity, obtained by\nextracting SigLIP image embeddings and refining them with PCA and whitening for\ndomain alignment, and (ii) semantic consistency, captured by comparing\nBLIP-2-generated captions of the SVGs against the original prompts in the\ncombined space of SBERT and TF-IDF. Evaluation on the proposed SHE benchmark\nshows that SVGauge attains the highest correlation with human judgments and\nreproduces system-level rankings of eight zero-shot LLM-based generators more\nfaithfully than existing metrics. Our results highlight the necessity of\nvector-specific evaluation and provide a practical tool for benchmarking future\ntext-to-SVG generation models.\n","authors":["Leonardo Zini","Elia Frigieri","Sebastiano Aloscari","Marcello Generali","Lorenzo Dodi","Robert Dosen","Lorenzo Baraldi"],"pdf_url":"https://arxiv.org/pdf/2509.07127v1.pdf","comment":"Accepted at 23rd edition of International Conference on Image\n  Analysis and Processing 2025"},{"id":"http://arxiv.org/abs/2509.07044v1","updated":"2025-09-08T11:31:47Z","published":"2025-09-08T11:31:47Z","title":"On design, analysis, and hybrid manufacturing of microstructured\n  blade-like geometries","summary":"  With the evolution of new manufacturing technologies such as multi-material\n3D printing, one can think of new type of objects that consist of considerably\nless, yet heterogeneous, material, consequently being porous, lighter and\ncheaper, while having the very same functionality as the original object when\nmanufactured from one single solid material. We aim at questioning five decades\nof traditional paradigms in geometric CAD and focus at new generation of CAD\nobjects that are not solid, but contain heterogeneous free-form internal\nmicrostructures. We propose a unified manufacturing pipeline that involves all\nstages, namely design, optimization, manufacturing, and inspection of\nmicrostructured free-form geometries. We demonstrate our pipeline on an\nindustrial test case of a blisk blade that sustains the desired pressure\nlimits, yet requires significantly less material when compared to the solid\ncounterpart.\n","authors":["Pablo Antolin","Michael Barton","Georges-Pierre Bonneau","Annalisa Buffa","Amaia Calleja-Ochoa","Gershon Elber","Stefanie Elgeti","Gaizka Gómez Escudero","Alicia Gonzalez","Haizea González Barrio","Stefanie Hahmann","Thibaut Hirschler","Q Youn Honga","Konstantin Key","Myung-Soo Kim","Michael Kofler","Norberto Lopez de Lacalle","Silvia de la Maza","Kanika Rajain","Jacques Zwar"],"pdf_url":"https://arxiv.org/pdf/2509.07044v1.pdf","comment":"14 pages, 23 figures"}]},"2025-09-05T00:00:00Z":{"Operating Systems":[{"id":"http://arxiv.org/abs/2509.05488v1","updated":"2025-09-05T20:34:06Z","published":"2025-09-05T20:34:06Z","title":"MambaLite-Micro: Memory-Optimized Mamba Inference on MCUs","summary":"  Deploying Mamba models on microcontrollers (MCUs) remains challenging due to\nlimited memory, the lack of native operator support, and the absence of\nembedded-friendly toolchains. We present, to our knowledge, the first\ndeployment of a Mamba-based neural architecture on a resource-constrained MCU,\na fully C-based runtime-free inference engine: MambaLite-Micro. Our pipeline\nmaps a trained PyTorch Mamba model to on-device execution by (1) exporting\nmodel weights into a lightweight format, and (2) implementing a handcrafted\nMamba layer and supporting operators in C with operator fusion and memory\nlayout optimization. MambaLite-Micro eliminates large intermediate tensors,\nreducing 83.0% peak memory, while maintaining an average numerical error of\nonly 1.7x10-5 relative to the PyTorch Mamba implementation. When evaluated on\nkeyword spotting(KWS) and human activity recognition (HAR) tasks,\nMambaLite-Micro achieved 100% consistency with the PyTorch baselines, fully\npreserving classification accuracy. We further validated portability by\ndeploying on both ESP32S3 and STM32H7 microcontrollers, demonstrating\nconsistent operation across heterogeneous embedded platforms and paving the way\nfor bringing advanced sequence models like Mamba to real-world\nresource-constrained applications.\n","authors":["Hongjun Xu","Junxi Xia","Weisi Yang","Yueyuan Sui","Stephen Xia"],"pdf_url":"https://arxiv.org/pdf/2509.05488v1.pdf","comment":"4 pages, 1 figures"},{"id":"http://arxiv.org/abs/2506.09758v2","updated":"2025-09-05T10:39:03Z","published":"2025-06-11T14:03:13Z","title":"Mainframe-Style Channel Controllers for Modern Disaggregated Memory\n  Systems","summary":"  Despite the promise of alleviating the main memory bottleneck, and the\nexistence of commercial hardware implementations, techniques for Near-Data\nProcessing have seen relatively little real-world deployment. The idea has\nreceived renewed interest with the appearance of disaggregated or \"far\" memory,\nfor example in the use of CXL memory pools.\n  However, we argue that the lack of a clear OS-centric abstraction of\nNear-Data Processing is a major barrier to adoption of the technology. Inspired\nby the channel controllers which interface the CPU to disk drives in mainframe\nsystems, we propose memory channel controllers as a convenient, portable, and\nvirtualizable abstraction of Near-Data Processing for modern disaggregated\nmemory systems.\n  In addition to providing a clean abstraction that enables OS integration\nwhile requiring no changes to CPU architecture, memory channel controllers\nincorporate another key innovation: they exploit the cache coherence provided\nby emerging interconnects to provide a much richer programming model, with more\nfine-grained interaction, than has been possible with existing designs.\n","authors":["Zikai Liu","Jasmin Schult","Pengcheng Xu","Timothy Roscoe"],"pdf_url":"https://arxiv.org/pdf/2506.09758v2.pdf","comment":"Camera-ready authors' version for APSys'25"}],"Systems and Control":[{"id":"http://arxiv.org/abs/2509.05482v1","updated":"2025-09-05T20:13:48Z","published":"2025-09-05T20:13:48Z","title":"State Estimation for Linear Systems with Non-Gaussian Measurement Noise\n  via Dynamic Programming","summary":"  We propose a new recursive estimator for linear dynamical systems under\nGaussian process noise and non-Gaussian measurement noise. Specifically, we\ndevelop an approximate maximum a posteriori (MAP) estimator using dynamic\nprogramming and tools from convex analysis. Our approach does not rely on\nrestrictive noise assumptions and employs a Bellman-like update instead of a\nBayesian update. Our proposed estimator is computationally efficient, with only\nmodest overhead compared to a standard Kalman filter. Simulations demonstrate\nthat our estimator achieves lower root mean squared error (RMSE) than the\nKalman filter and has comparable performance to state-of-the-art estimators,\nwhile requiring significantly less computational power.\n","authors":["Mohammad Hussein Yoosefian Nooshabadi","Laurent Lessard"],"pdf_url":"https://arxiv.org/pdf/2509.05482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.14790v2","updated":"2025-09-05T20:04:44Z","published":"2025-03-18T23:42:29Z","title":"Modeling, Observability, and Inertial Parameter Estimation of a Planar\n  Multi-Link System with Thrusters","summary":"  This research provides a theoretical foundation for modeling and real-time\nestimation of both the pose and inertial parameters of a free-floating\nmulti-link system with link thrusters, which are essential for safe and\neffective controller design and performance. First, we adapt a planar nonlinear\nmulti-link snake robot model to represent a planar chain of bioinspired salp\nrobots by removing joint actuators, introducing link thrusters, and allowing\nfor non-uniform link lengths, masses, and moments of inertia. Second, we\nconduct a nonlinear observability analysis of the multi-link system with link\nthrusters, proving that the link angles, angular velocities, masses, and\nmoments of inertia are locally observable when equipped with inertial\nmeasurement units and operating under specific thruster conditions. The\nanalytical results are demonstrated in simulation with a three-link system.\n","authors":["Nicholas B. Andrews","Kristi A. Morgansen"],"pdf_url":"https://arxiv.org/pdf/2503.14790v2.pdf","comment":"8 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2509.05463v1","updated":"2025-09-05T19:35:30Z","published":"2025-09-05T19:35:30Z","title":"A Fully Analog Implementation of Model Predictive Control with\n  Application to Buck Converters","summary":"  This paper proposes a novel approach to design analog electronic circuits\nthat implement Model Predictive Control (MPC) policies for plants described by\naffine models. The combination of state-of-the-art approaches to define\nreduced-complexity Explicit MPC (EMPC) is employed to realize an analog circuit\ncharacterized by a limited amount of low-latency and commercially available\ncomponents. The practical feasibility and effectiveness of the proposed\napproach are demonstrated through its application in the design of an advanced\ncontroller for DC-DC Buck converters. We formally analyze the stability of the\nobtained system and conduct extensive numerical simulations to demonstrate that\nit is capable of achieving outstanding load disturbance rejection performance,\noutclassing standard approaches.\n","authors":["Simone Pirrera","Lorenzo Calogero","Francesco Gabriele","Diego Regruto","Alessandro Rizzo","Gianluca Setti"],"pdf_url":"https://arxiv.org/pdf/2509.05463v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.08060v2","updated":"2025-09-05T18:35:43Z","published":"2025-04-10T18:24:54Z","title":"Community-Centric Multi-Criteria Assessment Framework for Energy\n  Transition","summary":"  The transition to low-carbon energy systems demands comprehensive technical,\neconomic, environmental, and social evaluation tools. While numerous studies\naddress specific aspects of energy transition, few provide an integrated\nframework to capture the full spectrum of impacts. This work developed a\ncommunity-collaborative assessment framework that integrates intelligent energy\ndevices with optimization-based coordination of energy assets. The proposed\nframework uses techno-economic, environmental, and social criteria to evaluate\ntransition pathways. A detailed case study is performed for a remote community\nin Alaska to assess its applicability, where the feasibility of renewable\nenergy transitions remains underexplored. Three distinct pathways, including\nheat pump and battery integration, resource coordination, and expanded\ncommunity solar PV, are analyzed using a year-long dataset of demand, renewable\nenergy, and transformer data. The analysis revealed that using heat pumps\nlowers the overall energy costs by 30% and carbon emissions by 28%. In\naddition, the share of the population spending more than 10% of their income on\nenergy falls from 74% in the existing scenario to 40% with heat pump adoption,\nindicating significant affordability improvements. By combining a general,\ncommunity-centric assessment framework with a data-driven case study, this work\noffers a practical tool for utilities, community stakeholders, and policymakers\nto work toward equitable and sustainable energy transitions.\n","authors":["Jayashree Yadav","Ingemar Mathiasson","Bindu Panikkar","Mads Almassalkhi"],"pdf_url":"https://arxiv.org/pdf/2504.08060v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.04548v2","updated":"2025-09-05T17:22:16Z","published":"2025-04-06T16:56:22Z","title":"NISE-PE Constraint: Data-Driven Predictive Control with Persistence of\n  Excitation","summary":"  Persistence of excitation (PE) is an important requirement for the successful\noperation of data-driven predictive control, as it ensures that the\ninput-output data contains sufficient information about the underlying system\ndynamics. Nonetheless, this property is usually assumed rather than guaranteed.\nThis paper introduces a novel data-driven predictive control formulation that\nmaintains PE. The technical development that allows this is the\ncharacterisation of the nonexciting input set (NIS), i.e., the set of inputs\nthat lead to loss of PE, and the consequent derivation of a pair of disjoint,\nlinear inequality constraints on the input, termed NIS exclusion PE (NIS-PE)\nconstraint, that, if satisfied, maintain PE. When used in a predictive control\nformulation, these constraints lead to a mixed-integer optimal control problem\nwith a single binary variable or, equivalently, a pair of disjoint quadratic\nprogramming problems that can be efficiently and reliably solved. Numerical\nexamples show how these constraints are able to maintain PE during the\ncontroller's operation, resulting in improved performance over conventional\napproaches for both time-invariant and time-varying systems.\n","authors":["Lucca Heinze Faro","Yuanbo Nie","Paul Trodden"],"pdf_url":"https://arxiv.org/pdf/2504.04548v2.pdf","comment":"7 pages, 5 figures. Accepted for presentation at, and publication in\n  the proceedings of, the 2025 64th IEEE Conference on Decision and Control\n  (CDC)"},{"id":"http://arxiv.org/abs/2509.05259v1","updated":"2025-09-05T17:18:17Z","published":"2025-09-05T17:18:17Z","title":"A Kolmogorov-Arnold Network for Interpretable Cyberattack Detection in\n  AGC Systems","summary":"  Automatic Generation Control (AGC) is essential for power grid stability but\nremains vulnerable to stealthy cyberattacks, such as False Data Injection\nAttacks (FDIAs), which can disturb the system's stability while evading\ntraditional detection methods. Unlike previous works that relied on blackbox\napproaches, this work proposes Kolmogorov-Arnold Networks (KAN) as an\ninterpretable and accurate method for FDIA detection in AGC systems,\nconsidering the system nonlinearities. KAN models include a method for\nextracting symbolic equations, and are thus able to provide more\ninterpretability than the majority of machine learning models. The proposed KAN\nis trained offline to learn the complex nonlinear relationships between the AGC\nmeasurements under different operating scenarios. After training, symbolic\nformulas that describe the trained model's behavior can be extracted and\nleveraged, greatly enhancing interpretability. Our findings confirm that the\nproposed KAN model achieves FDIA detection rates of up to 95.97% and 95.9% for\nthe initial model and the symbolic formula, respectively, with a low false\nalarm rate, offering a reliable approach to enhancing AGC cybersecurity.\n","authors":["Jehad Jilan","Niranjana Naveen Nambiar","Ahmad Mohammad Saber","Alok Paranjape","Amr Youssef","Deepa Kundur"],"pdf_url":"https://arxiv.org/pdf/2509.05259v1.pdf","comment":"Peer-reviewed"},{"id":"http://arxiv.org/abs/2509.05201v1","updated":"2025-09-05T16:03:57Z","published":"2025-09-05T16:03:57Z","title":"Robust Model Predictive Control Design for Autonomous Vehicles with\n  Perception-based Observers","summary":"  This paper presents a robust model predictive control (MPC) framework that\nexplicitly addresses the non-Gaussian noise inherent in deep learning-based\nperception modules used for state estimation. Recognizing that accurate\nuncertainty quantification of the perception module is essential for safe\nfeedback control, our approach departs from the conventional assumption of\nzero-mean noise quantification of the perception error. Instead, it employs\nset-based state estimation with constrained zonotopes to capture biased,\nheavy-tailed uncertainties while maintaining bounded estimation errors. To\nimprove computational efficiency, the robust MPC is reformulated as a linear\nprogram (LP), using a Minkowski-Lyapunov-based cost function with an added\nslack variable to prevent degenerate solutions. Closed-loop stability is\nensured through Minkowski-Lyapunov inequalities and contractive zonotopic\ninvariant sets. The largest stabilizing terminal set and its corresponding\nfeedback gain are then derived via an ellipsoidal approximation of the\nzonotopes. The proposed framework is validated through both simulations and\nhardware experiments on an omnidirectional mobile robot along with a camera and\na convolutional neural network-based perception module implemented within a\nROS2 framework. The results demonstrate that the perception-aware MPC provides\nstable and accurate control performance under heavy-tailed noise conditions,\nsignificantly outperforming traditional Gaussian-noise-based designs in terms\nof both state estimation error bounding and overall control performance.\n","authors":["Nariman Niknejad","Gokul S. Sankar","Bahare Kiumarsi","Hamidreza Modares"],"pdf_url":"https://arxiv.org/pdf/2509.05201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.05191v1","updated":"2025-09-05T15:44:35Z","published":"2025-09-05T15:44:35Z","title":"Feedback Linearisation with State Constraints","summary":"  Feedback Linearisation (FBL) is a widely used technique that applies feedback\nlaws to transform input-affine nonlinear dynamical systems into linear\ndynamical systems, allowing for the use of linear controller design methods\nsuch as pole placement. However, for problems with state constraints,\ncontrolling the linear system induced by FBL can be more challenging than\ncontrolling the original system. This is because simple state constraints in\nthe original nonlinear system become complex nonlinear constraints in the FBL\ninduced linearised system, thereby diminishing the advantages of linearisation.\nTo avoid increasing the complexity of state constraints under FBL, this paper\nintroduces a method to first augment system dynamics to capture state\nconstraints before applying FBL. We show that our proposed augmentation method\nleads to ill-defined relative degrees at state constraint boundaries. However,\nwe show that ill-defined relative degrees can be overcome by using a switching\nFBL controller. Numerical experiments illustrate the capabilities of this\nmethod for handling state constraints within the FBL framework.\n","authors":["Songlin Jin","Yuanbo Nie","Morgan Jones"],"pdf_url":"https://arxiv.org/pdf/2509.05191v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.01630v2","updated":"2025-09-05T15:36:28Z","published":"2025-09-01T17:17:05Z","title":"Learning to Coordinate: Distributed Meta-Trajectory Optimization Via\n  Differentiable ADMM-DDP","summary":"  Distributed trajectory optimization via ADMM-DDP is a powerful approach for\ncoordinating multi-agent systems, but it requires extensive tuning of tightly\ncoupled hyperparameters that jointly govern local task performance and global\ncoordination. In this paper, we propose Learning to Coordinate (L2C), a general\nframework that meta-learns these hyperparameters, modeled by lightweight\nagent-wise neural networks, to adapt across diverse tasks and agent\nconfigurations. L2C differentiates end-to-end through the ADMM-DDP pipeline in\na distributed manner. It also enables efficient meta-gradient computation by\nreusing DDP components such as Riccati recursions and feedback gains. These\ngradients correspond to the optimal solutions of distributed matrix-valued LQR\nproblems, coordinated across agents via an auxiliary ADMM framework that\nbecomes convex under mild assumptions. Training is further accelerated by\ntruncating iterations and meta-learning ADMM penalty parameters optimized for\nrapid residual reduction, with provable Lipschitz-bounded gradient errors. On a\nchallenging cooperative aerial transport task, L2C generates dynamically\nfeasible trajectories in high-fidelity simulation using IsaacSIM, reconfigures\nquadrotor formations for safe 6-DoF load manipulation in tight spaces, and\nadapts robustly to varying team sizes and task conditions, while achieving up\nto $88\\%$ faster gradient computation than state-of-the-art methods.\n","authors":["Bingheng Wang","Yichao Gao","Tianchen Sun","Lin Zhao"],"pdf_url":"https://arxiv.org/pdf/2509.01630v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.05182v1","updated":"2025-09-05T15:30:36Z","published":"2025-09-05T15:30:36Z","title":"Collective decision-making dynamics in hypernetworks","summary":"  This work describes a collective decision-making dynamical process in a\nmultiagent system under the assumption of cooperative higher-order interactions\nwithin the community, modeled as a hypernetwork. The nonlinear interconnected\nsystem is characterized by saturated nonlinearities that describe how agents\ntransmit their opinion state to their neighbors in the hypernetwork, and by a\nbifurcation parameter representing the community's social effort. We show that\nthe presence of higher-order interactions leads to the unfolding of a pitchfork\nbifurcation, introducing an interval for the social effort parameter in which\nthe system exhibits bistability. With equilibrium points representing\ncollective decisions, this implies that, depending on the initial conditions,\nthe community will either remain in a deadlock state (with the origin as the\nequilibrium point) or reach a nontrivial decision. A numerical example is given\nto illustrate the results.\n","authors":["Angela Fontan","Silun Zhang"],"pdf_url":"https://arxiv.org/pdf/2509.05182v1.pdf","comment":"8 pages, 2 figures"},{"id":"http://arxiv.org/abs/2509.05167v1","updated":"2025-09-05T15:06:02Z","published":"2025-09-05T15:06:02Z","title":"Model predictive quantum control: A modular approach for efficient and\n  robust quantum optimal control","summary":"  Model predictive control (MPC) is one of the most successful modern control\nmethods. It relies on repeatedly solving a finite-horizon optimal control\nproblem and applying the beginning piece of the optimal input. In this paper,\nwe develop a modular framework for improving efficiency and robustness of\nquantum optimal control (QOC) via MPC. We first provide a tutorial introduction\nto basic concepts of MPC from a QOC perspective. We then present multiple MPC\nschemes, ranging from simple approaches to more sophisticated schemes which\nadmit stability guarantees. This yields a modular framework which can be used\n1) to improve efficiency of open-loop QOC and 2) to improve robustness of\nclosed-loop quantum control by incorporating feedback. We demonstrate these\nbenefits with numerical results, where we benchmark the proposed methods\nagainst competing approaches.\n","authors":["Eya Guizani","Julian Berberich"],"pdf_url":"https://arxiv.org/pdf/2509.05167v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.15077v2","updated":"2025-09-05T14:32:43Z","published":"2022-06-30T07:20:07Z","title":"Attitude Control of Rigid Bodies: A Survey of Representations,\n  Topological Obstructions, and Stabilization Techniques","summary":"  This paper reviews the attitude control problems for rigid-body systems,\nstarting from the attitude representation for rigid body kinematics. Highly\nredundant rotation matrix defines the attitude orientation globally and\nuniquely by 9 parameters, which is the most fundamental one, without any\nsingularities; minimum 3-parameter Euler angles or (modified) Rodrigues\nparameters define the attitude orientation neither globally nor uniquely, but\nthe former exhibits kinematical singularity and Gimbal lock, while the latter\ntwo exhibit geometrical singularity; once-redundant axis-angle or unit\nquaternion globally define the attitude rotation but not uniquely using 4\nparameters, but the former is not appropriate to define very small or very\nlarge rotations, while the latter shows unwinding phenomenon despite of the\nreduced computation burden. In addition, we explore the relationships among\nthose attitude representations, including the connections among Gimbal lock,\nunwinding phenomenon and a nowhere dense set of zero Lebesgue measure. Based on\nattitude representations, we analyze different attitude control laws, almost\nglobal control and global attitude control, nominal and general robustness, as\nwell as the technique tools.\n","authors":["Hongye Su","Dandan Zhang"],"pdf_url":"https://arxiv.org/pdf/2206.15077v2.pdf","comment":"13 pages, 6 figures, 2 tables"},{"id":"http://arxiv.org/abs/2401.13062v3","updated":"2025-09-05T13:57:29Z","published":"2024-01-23T19:38:11Z","title":"Sensing environmental physical interaction to traverse cluttered\n  obstacles","summary":"  The long-standing, dominant approach to robotic obstacle negotiation relies\non mapping environmental geometry to avoid obstacles. However, this approach\ndoes not allow for traversal of cluttered obstacles, hindering applications\nsuch as search and rescue operations through earthquake rubble and exploration\nacross lunar and Martian rocks. To overcome this challenge, robots must further\nsense and utilize environmental physical interactions to control themselves to\ntraverse obstacles. Recently, a physics-based approach has been established\ntowards this vision. Self-propelled robots interacting with obstacles results\nin a potential energy landscape. On this landscape, to traverse obstacles, a\nrobot must escape from certain landscape basins that attract it into failure\nmodes, to reach other basins that lead to successful modes. Thus, sensing the\npotential energy landscape is crucial. Here, we developed new methods and\nperformed systematic experiments to demonstrate that the potential energy\nlandscape can be estimated by sensing environmental physical interaction. We\ndeveloped a minimalistic robot capable of sensing obstacle contact forces and\ntorques for systematic experiments over a wide range of parameter space.\nSurprisingly, although these forces and torques are not fully conservative,\nthey match the potential energy landscape gradients that are conservative\nforces and torques, enabling an accurate estimation of the potential energy\nlandscape. Additionally, a bio-inspired strategy further enhanced estimation\naccuracy. Our results provided a foundation for further refining these methods\nfor use in free-locomoting robots. Our study is a key step in establishing a\nnew physics-based approach for robots to traverse clustered obstacles to\nadvance their mobility in complex, real-world environments.\n","authors":["Yaqing Wang","Ling Xu","Chen Li"],"pdf_url":"https://arxiv.org/pdf/2401.13062v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.01807v2","updated":"2025-09-05T11:51:58Z","published":"2025-04-02T15:12:34Z","title":"Barrier Certificates for Unknown Systems with Latent States and\n  Polynomial Dynamics using Bayesian Inference","summary":"  Certifying safety in dynamical systems is crucial, but barrier certificates -\nwidely used to verify that system trajectories remain within a safe region -\ntypically require explicit system models. When dynamics are unknown,\ndata-driven methods can be used instead, yet obtaining a valid certificate\nrequires rigorous uncertainty quantification. For this purpose, existing\nmethods usually rely on full-state measurements, limiting their applicability.\nThis paper proposes a novel approach for synthesizing barrier certificates for\nunknown systems with latent states and polynomial dynamics. A Bayesian\nframework is employed, where a prior in state-space representation is updated\nusing output data via a targeted marginal Metropolis-Hastings sampler. The\nresulting samples are used to construct a barrier certificate through a\nsum-of-squares program. Probabilistic guarantees for its validity with respect\nto the true, unknown system are obtained by testing on an additional set of\nposterior samples. The approach and its probabilistic guarantees are\nillustrated through a numerical simulation.\n","authors":["Robert Lefringhausen","Sami Leon Noel Aziz Hanna","Elias August","Sandra Hirche"],"pdf_url":"https://arxiv.org/pdf/2504.01807v2.pdf","comment":"Accepted for publication in the Proceedings of the 64th IEEE\n  Conference on Decision and Control"},{"id":"http://arxiv.org/abs/2509.05020v1","updated":"2025-09-05T11:29:22Z","published":"2025-09-05T11:29:22Z","title":"StimulHeat: a Low-Energy Wearable Thermal Feedback Device Using Peltier\n  Elements with Heat Flow Controlled Loop for Hand Interactions in Virtual\n  Reality","summary":"  Nowadays, the majority of wearable thermal feedback systems designed for use\nin virtual reality applications are not compatible or not integrated to\nstandard controllers and are based on temperature control. The objectives of\nthe present work is to enable integration with existing controllers, in this\ncase Valve Index controllers, and to propose an alternative approach to\nmanaging thermal stimulation with Peltier modules by controlling heat flow\ninstead of temperature. We introduce StimulHeat as a wireless, low power\nthermal feedback system, based on the continuous relationship between heat and\ncurrent injection in thermoelectric device (TED). First, we designed an\noptimized TED driver capable of injecting a continuous, bidirectional current\ninto the TED, thereby driving it as a heater or cooler. Subsequently, this\ndriver was implemented in an electronic board to include temperature and heat\nflow control loops, as well as Bluetooth Low Energy interface for remote\ncontrol. A mechanical integration was conducted, in the form of a controller\nextension which is non-intrusive and can be clipped to Valve Index controllers\nto enclose the TED, temperature sensors and electronics. Finally, we present a\nuser study validating StimulHeat for use in Virtual Reality, utilizing a\nUnity-built virtual environment with our open-source package.\n","authors":["Matthieu Mesnage","Sophie Villenave","Bertrand Massot","Matthieu Blanchard","Pierre Raimbaud","Guillaume Lavoué","Claudine Gehin"],"pdf_url":"https://arxiv.org/pdf/2509.05020v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.05003v1","updated":"2025-09-05T10:53:59Z","published":"2025-09-05T10:53:59Z","title":"Estimating Cellular Network Delays in Finnish Railways: A Machine\n  Learning Enhanced Approach","summary":"  There is growing interest in using public cellular networks for specialized\ncommunication applications, replacing standalone sector-specific networks. One\nsuch application is transitioning from the aging GSM-R railway network to\npublic 4G and 5G networks. Finland is modernizing its railway communication\nsystem through the Digirail project, leveraging public cellular networks. To\nevaluate network performance, a nationwide measurement campaign was conducted\nin two modes: Best Quality and Packet Replication. However, Best Quality mode\nintroduces artificial delays, making it unsuitable for real-world assessments.\nIn this paper, railway network delays are modeled using machine learning based\non measurements from the Packet Replication mode. The best-performing model is\nthen employed to generate a dataset estimating network delays across Finland's\nrailway network. This dataset provides a more accurate representation of\nnetwork performance. Machine learning based network performance prediction is\nshown to be feasible, and the results indicate that Finland's public cellular\nnetwork can meet the stringent performance requirements of railway network\ncontrol.\n","authors":["Saeideh Mansouri","Mohamed Shamekh","Simon Indola","Petri Mahonen"],"pdf_url":"https://arxiv.org/pdf/2509.05003v1.pdf","comment":"Accepted for presentation at IEEE PIMRC 2025. 6 pages, 7 figures"},{"id":"http://arxiv.org/abs/2206.14360v5","updated":"2025-09-05T10:10:51Z","published":"2022-06-29T02:01:26Z","title":"Stability Analysis for Stochastic Hybrid Inclusions","summary":"  Stochastic hybrid inclusions (SHIs) address situations with the stochastic\ncontinuous evolution in a stochastic differential inclusions and random jumps\nin the difference inclusions due to the forced (the state reaching a boundary\nin the state space) and/or spontaneous (the state vector may occur\nspontaneously) transitions. An obvious characteristic of SHIs is the\nnon-uniqueness of random solutions, which can be ensured by the mild regularity\nconditions, as well as nominal robustness. Basic sufficient conditions for\nstability/recurrence in probability are usually expressed based on different\ntypes of Lyapunov functions, including Lagrange/Lyapunov/Lyapunov-Forster\nfunctions respectively for Lagrange/Lyapunov/asymptotical stability in\nprobability and Foster/Lagrange-Forster functions for recurrence, (weaker)\nrelaxed Lyapunov-based sufficient conditions including Matrosov-Foster\nfunctions and the stochastic invariance principle, as well as Lyapunov-based\nnecessary and sufficient conditions for asymptotical stability in probability\nor recurrence (i.e.,converse theorems), etc. The converse theorems involving\nsmooth Lyapunov functions are guaranteed by the sequential compactness and thus\nrobustness. In addition, the uniformity property and causality are analyzed for\nthe stabilities in probability. Hence, serving as a partial roadmap for the\ntheoretical development of SHIs, also serving as inspiration, we anticipate\nthat many of the open questions, including the prediction problem, the\nfiltering problem and the control problem, will be resolved based on the\ntechniques of SHIs.\n","authors":["Hongye Su","Dandan Zhang"],"pdf_url":"https://arxiv.org/pdf/2206.14360v5.pdf","comment":"15 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2509.04885v1","updated":"2025-09-05T08:03:54Z","published":"2025-09-05T08:03:54Z","title":"Performance Analysis of Pinching-Antenna-Enabled Internet of Things\n  Systems","summary":"  The pinching-antenna systems (PASS), which activate small dielectric\nparticles along a dielectric waveguide, has recently emerged as a promising\nparadigm for flexible antenna deployment in next-generation wireless\ncommunication networks. While most existing studies assume rectangular indoor\nlayouts with full coverage waveguide, practical deployments may involve\ngeometric constraints, partial coverage, and non-negligible waveguide\nattenuation. This paper presents the first analytical investigation of PASS in\na circular indoor environment, encompassing both full coverage and partial\ncoverage waveguide configurations with/without propagation loss. A unified\ngeometric-propagation framework is developed that jointly captures\npinching-antenna placement, Internet of Things (IoT) device location\ndistribution, and waveguide attenuation. Closed-form expressions for the outage\nprobability and average achievable rate are derived for four scenarios, with\naccuracy validated via extensive Monte-Carlo simulations. The analysis reveals\nthat, under the partial coverage waveguide scenario with propagation loss, the\nsystem performance demonstrates a non-monotonic trend with respect to the\nwaveguide length, and the optimal length decreases as the attenuation\ncoefficient increases. Numerical results further quantify the interplay between\ndeployment strategy, waveguide propagation loss, and coverage geometry,\noffering practical guidelines for performance-oriented PASS design.\n","authors":["Han Zhang","Bingxin Zhang","Yizhe Zhao","Kun Yang","Guopeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2509.04885v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.00801v2","updated":"2025-09-05T08:00:49Z","published":"2025-08-31T11:23:57Z","title":"Adaptation of Parameters in Heterogeneous Multi-agent Systems","summary":"  This paper proposes an adaptation mechanism for heterogeneous multi-agent\nsystems to align the agents' internal parameters, based on enforced consensus\nthrough strong couplings. Unlike homogeneous systems, where exact consensus is\nattainable, the heterogeneity in node dynamics precludes perfect\nsynchronization. Nonetheless, previous work has demonstrated that strong\ncoupling can induce approximate consensus, whereby the agents exhibit emergent\ncollective behavior governed by the so-called blended dynamics. Building on\nthis observation, we introduce an adaptation law that gradually aligns the\ninternal parameters of agents without requiring direct parameter communication.\nThe proposed method reuses the same coupling signal employed for state\nsynchronization, which may result in a biologically or sociologically plausible\nadaptation process. Under a persistent excitation condition, we prove that the\nlinearly parametrized vector fields of the agents converge to each other,\nthereby making the dynamics asymptotically homogeneous, and leading to exact\nconsensus of the state variables.\n","authors":["Hyungbo Shim","Jin Gyu Lee","B. D. O. Anderson"],"pdf_url":"https://arxiv.org/pdf/2509.00801v2.pdf","comment":"10 pages, 2 figures, IEEE Conf. on Decision and Control 2025"},{"id":"http://arxiv.org/abs/2504.09057v2","updated":"2025-09-05T03:29:15Z","published":"2025-04-12T03:23:42Z","title":"Error-In-Variables Methods for Efficient System Identification with\n  Finite-Sample Guarantees","summary":"  This paper addresses the problem of learning linear dynamical systems from\nnoisy observations. In this setting, existing algorithms either yield biased\nparameter estimates or have large sample complexities. We resolve these issues\nby adapting the instrumental variable method and the bias compensation method,\noriginally proposed for error-in-variables models, to our setting. We provide\nrefined non-asymptotic analysis for both methods. Under mild conditions, our\nalgorithms achieve superior sample complexities that match the best-known\nsample complexity for learning a fully observable system without observation\nnoise.\n","authors":["Yuyang Zhang","Xinhe Zhang","Jia Liu","Na Li"],"pdf_url":"https://arxiv.org/pdf/2504.09057v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.05946v3","updated":"2025-09-05T00:55:55Z","published":"2025-04-08T11:59:00Z","title":"InstructMPC: A Human-LLM-in-the-Loop Framework for Context-Aware Control","summary":"  Model Predictive Control (MPC) is a powerful control strategy widely utilized\nin domains like energy management, building control, and autonomous systems.\nHowever, its effectiveness in real-world settings is challenged by the need to\nincorporate context-specific predictions and expert instructions, which\ntraditional MPC often neglects. We propose InstructMPC, a novel framework that\naddresses this gap by integrating real-time human instructions through a Large\nLanguage Model (LLM) to produce context-aware predictions for MPC. Our method\nemploys a Language-to-Distribution (L2D) module to translate contextual\ninformation into predictive disturbance trajectories, which are then\nincorporated into the MPC optimization. Unlike existing context-aware and\nlanguage-based MPC models, InstructMPC enables dynamic human-LLM interaction\nand fine-tunes the L2D module in a closed loop with theoretical performance\nguarantees, achieving a regret bound of $O(\\sqrt{T\\log T})$ for linear dynamics\nwhen optimized via advanced fine-tuning methods such as Direct Preference\nOptimization (DPO) using a tailored loss function.\n","authors":["Ruixiang Wu","Jiahao Ai","Tongxin Li"],"pdf_url":"https://arxiv.org/pdf/2504.05946v3.pdf","comment":null}],"Hardware Architecture":[{"id":"http://arxiv.org/abs/2509.05504v1","updated":"2025-09-05T21:28:26Z","published":"2025-09-05T21:28:26Z","title":"Comparing Methods for the Cross-Level Verification of SystemC\n  Peripherals with Symbolic Execution","summary":"  Virtual Prototypes (VPs) are important tools in modern hardware development.\nAt high abstractions, they are often implemented in SystemC and offer early\nanalysis of increasingly complex designs. These complex designs often combine\none or more processors, interconnects, and peripherals to perform tasks in\nhardware or interact with the environment. Verifying these subsystems is a\nwell-suited task for VPs, as they allow reasoning across different abstraction\nlevels. While modern verification techniques like symbolic execution can be\nseamlessly integrated into VP-based workflows, they require modifications in\nthe SystemC kernel. Hence, existing approaches therefore modify and replace the\nSystemC kernel, or ignore the opportunity of cross-level scenarios completely,\nand would not allow focusing on special challenges of particular subsystems\nlike peripherals. We propose CrosSym and SEFOS, two opposing approaches for a\nversatile symbolic execution of peripherals. CrosSym modifies the SystemC\nkernel, while SEFOS instead modifies a modern symbolic execution engine. Our\nextensive evaluation applies our tools to various peripherals on different\nlevels of abstractions. Both tools extensive sets of features are demonstrated\nfor (1) different verification scenarios, and (2) identifying 300+ mutants. In\ncomparison with each other, SEFOS convinces with the unmodified SystemC kernel\nand peripheral, while CrosSym offers slightly better runtime and memory usage.\nIn comparison to the state-of-the-art, that is limited to Transaction Level\nModelling (TLM), our tools offered comparable runtime, while enabling\ncross-level verification with symbolic execution.\n","authors":["Karl Aaron Rudkowski","Sallar Ahmadi-Pour","Rolf Drechsler"],"pdf_url":"https://arxiv.org/pdf/2509.05504v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.15006v3","updated":"2025-09-05T20:34:04Z","published":"2025-06-17T22:29:37Z","title":"Scaling Intelligence: Designing Data Centers for Next-Gen Language\n  Models","summary":"  The explosive growth of Large Language Models (LLMs), such as GPT-4 with 1.8\ntrillion parameters, demands a fundamental rethinking of data center\narchitecture to ensure scalability, efficiency, and cost-effectiveness. Our\nwork provides a comprehensive co-design framework that jointly explores FLOPS,\nHBM bandwidth and capacity, multiple network topologies (two-tier vs. FullFlat\noptical), the size of the scale-out domain, and popular\nparallelism/optimization strategies used in LLMs. We introduce and evaluate\nFullFlat network architectures, which provide uniform high-bandwidth,\nlow-latency connectivity between all nodes, and demonstrate their\ntransformative impact on performance and scalability. Through detailed\nsensitivity analyses, we quantify the benefits of overlapping compute and\ncommunication, leveraging hardware-accelerated collectives, widening the\nscale-out domain, and increasing memory capacity. Our study spans both sparse\n(mixture of experts) and dense transformer-based LLMs, revealing how system\ndesign choices affect Model FLOPS Utilization (MFU = Model FLOPS per token *\nObserved tokens per second / Peak FLOPS of the hardware) and overall\nthroughput. For the co-design study, we utilized an analytical performance\nmodeling tool capable of predicting LLM runtime within 10% of real-world\nmeasurements. Our findings offer actionable insights and a practical roadmap\nfor designing AI data centers that can efficiently support trillion-parameter\nmodels, reduce optimization complexity, and sustain the rapid evolution of AI\ncapabilities.\n","authors":["Jesmin Jahan Tithi","Hanjiang Wu","Avishaii Abuhatzera","Fabrizio Petrini"],"pdf_url":"https://arxiv.org/pdf/2506.15006v3.pdf","comment":"14 pages, submitted to SC25 for review"},{"id":"http://arxiv.org/abs/2509.05451v1","updated":"2025-09-05T19:09:26Z","published":"2025-09-05T19:09:26Z","title":"Characterizing and Optimizing Realistic Workloads on a Commercial\n  Compute-in-SRAM Device","summary":"  Compute-in-SRAM architectures offer a promising approach to achieving higher\nperformance and energy efficiency across a range of data-intensive\napplications. However, prior evaluations have largely relied on simulators or\nsmall prototypes, limiting the understanding of their real-world potential. In\nthis work, we present a comprehensive performance and energy characterization\nof a commercial compute-in-SRAM device, the GSI APU, under realistic workloads.\nWe compare the GSI APU against established architectures, including CPUs and\nGPUs, to quantify its energy efficiency and performance potential. We introduce\nan analytical framework for general-purpose compute-in-SRAM devices that\nreveals fundamental optimization principles by modeling performance trade-offs,\nthereby guiding program optimizations.\n  Exploiting the fine-grained parallelism of tightly integrated memory-compute\narchitectures requires careful data management. We address this by proposing\nthree optimizations: communication-aware reduction mapping, coalesced DMA, and\nbroadcast-friendly data layouts. When applied to retrieval-augmented generation\n(RAG) over large corpora (10GB--200GB), these optimizations enable our\ncompute-in-SRAM system to accelerate retrieval by 4.8$\\times$--6.6$\\times$ over\nan optimized CPU baseline, improving end-to-end RAG latency by\n1.1$\\times$--1.8$\\times$. The shared off-chip memory bandwidth is modeled using\na simulated HBM, while all other components are measured on the real\ncompute-in-SRAM device. Critically, this system matches the performance of an\nNVIDIA A6000 GPU for RAG while being significantly more energy-efficient\n(54.4$\\times$-117.9$\\times$ reduction). These findings validate the viability\nof compute-in-SRAM for complex, real-world applications and provide guidance\nfor advancing the technology.\n","authors":["Niansong Zhang","Wenbo Zhu","Courtney Golden","Dan Ilan","Hongzheng Chen","Christopher Batten","Zhiru Zhang"],"pdf_url":"https://arxiv.org/pdf/2509.05451v1.pdf","comment":"MICRO 2025"},{"id":"http://arxiv.org/abs/2506.09758v2","updated":"2025-09-05T10:39:03Z","published":"2025-06-11T14:03:13Z","title":"Mainframe-Style Channel Controllers for Modern Disaggregated Memory\n  Systems","summary":"  Despite the promise of alleviating the main memory bottleneck, and the\nexistence of commercial hardware implementations, techniques for Near-Data\nProcessing have seen relatively little real-world deployment. The idea has\nreceived renewed interest with the appearance of disaggregated or \"far\" memory,\nfor example in the use of CXL memory pools.\n  However, we argue that the lack of a clear OS-centric abstraction of\nNear-Data Processing is a major barrier to adoption of the technology. Inspired\nby the channel controllers which interface the CPU to disk drives in mainframe\nsystems, we propose memory channel controllers as a convenient, portable, and\nvirtualizable abstraction of Near-Data Processing for modern disaggregated\nmemory systems.\n  In addition to providing a clean abstraction that enables OS integration\nwhile requiring no changes to CPU architecture, memory channel controllers\nincorporate another key innovation: they exploit the cache coherence provided\nby emerging interconnects to provide a much richer programming model, with more\nfine-grained interaction, than has been possible with existing designs.\n","authors":["Zikai Liu","Jasmin Schult","Pengcheng Xu","Timothy Roscoe"],"pdf_url":"https://arxiv.org/pdf/2506.09758v2.pdf","comment":"Camera-ready authors' version for APSys'25"},{"id":"http://arxiv.org/abs/2509.04798v1","updated":"2025-09-05T04:29:50Z","published":"2025-09-05T04:29:50Z","title":"Distributed-HISQ: A Distributed Quantum Control Architecture","summary":"  The design of a scalable Quantum Control Architecture (QCA) faces two primary\nchallenges. First, the continuous growth in qubit counts has rendered\ndistributed QCA inevitable, yet the nondeterministic latencies inherent in\nfeedback loops demand cycleaccurate synchronization across multiple\ncontrollers. Existing synchronization strategies -- whether lock-step or\ndemand-driven -- introduce significant performance penalties. Second, existing\nquantum instruction set architectures are polarized, being either too abstract\nor too granular. This lack of a unifying design necessitates recurrent hardware\ncustomization for each new control requirement, which limits the system's\nreconfigurability and impedes the path toward a scalable and unified digital\nmicroarchitecture.\n  Addressing these challenges, we propose Distributed-HISQ, featuring: (i)\nHISQ, A universal instruction set that redefines quantum control with a\nhardware-agnostic design. By decoupling from quantum operation semantics, HISQ\nprovides a unified language for control sequences, enabling a single\nmicroarchitecture to support various control methods and enhancing system\nreconfigurability. (ii) BISP, a booking-based synchronization protocol that can\npotentially achieve zero-cycle synchronization overhead. The feasibility and\nadaptability of Distributed-HISQ are validated through its implementation on a\ncommercial quantum control system targeting superconducting qubits. We\nperformed a comprehensive evaluation using a customized quantum software stack.\nOur results show that BISP effectively synchronizes multiple control boards,\nleading to a 22.8% reduction in average program execution time and a\n$\\sim$5$\\times$ reduction in infidelity when compared to an existing lock-step\nsynchronization scheme.\n","authors":["Yilun Zhao","Kangding Zhao","Peng Zhou","Dingdong Liu","Tingyu Luo","Yuzhen Zheng","Peng Luo","Shun Hu","Jin Lin","Cheng Guo","Yinhe Han","Ying Wang","Mingtang Deng","Junjie Wu","X. Fu"],"pdf_url":"https://arxiv.org/pdf/2509.04798v1.pdf","comment":null}],"Programming Languages":[{"id":"http://arxiv.org/abs/2509.05504v1","updated":"2025-09-05T21:28:26Z","published":"2025-09-05T21:28:26Z","title":"Comparing Methods for the Cross-Level Verification of SystemC\n  Peripherals with Symbolic Execution","summary":"  Virtual Prototypes (VPs) are important tools in modern hardware development.\nAt high abstractions, they are often implemented in SystemC and offer early\nanalysis of increasingly complex designs. These complex designs often combine\none or more processors, interconnects, and peripherals to perform tasks in\nhardware or interact with the environment. Verifying these subsystems is a\nwell-suited task for VPs, as they allow reasoning across different abstraction\nlevels. While modern verification techniques like symbolic execution can be\nseamlessly integrated into VP-based workflows, they require modifications in\nthe SystemC kernel. Hence, existing approaches therefore modify and replace the\nSystemC kernel, or ignore the opportunity of cross-level scenarios completely,\nand would not allow focusing on special challenges of particular subsystems\nlike peripherals. We propose CrosSym and SEFOS, two opposing approaches for a\nversatile symbolic execution of peripherals. CrosSym modifies the SystemC\nkernel, while SEFOS instead modifies a modern symbolic execution engine. Our\nextensive evaluation applies our tools to various peripherals on different\nlevels of abstractions. Both tools extensive sets of features are demonstrated\nfor (1) different verification scenarios, and (2) identifying 300+ mutants. In\ncomparison with each other, SEFOS convinces with the unmodified SystemC kernel\nand peripheral, while CrosSym offers slightly better runtime and memory usage.\nIn comparison to the state-of-the-art, that is limited to Transaction Level\nModelling (TLM), our tools offered comparable runtime, while enabling\ncross-level verification with symbolic execution.\n","authors":["Karl Aaron Rudkowski","Sallar Ahmadi-Pour","Rolf Drechsler"],"pdf_url":"https://arxiv.org/pdf/2509.05504v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.05462v1","updated":"2025-09-05T19:35:08Z","published":"2025-09-05T19:35:08Z","title":"The compact double category $\\mathbf{Int}(\\mathbf{Poly}_*)$ models\n  control flow and data transformations","summary":"  Hasegawa showed that control flow in programming languages -- while loops and\nif-then-else statements -- can be modeled using traced cocartesian categories,\nsuch as the category $\\mathbf{Set}_*$ of pointed sets. In this paper we define\nan operad $\\mathscr{W}$ of wiring diagrams that provides syntax for categories\nwhose control flow moreover includes data transformations, including deleting,\nduplicating, permuting, and applying pre-specified functions to variables. In\nthe most basic version, the operad underlies $\\mathbf{Int}(\\mathbf{Poly}_*)$,\nwhere $\\mathbf{Int}(\\mathscr{T})$ denotes the free compact category on a traced\ncategory $\\mathscr{T}$, as defined by Joyal, Street, and Verity; to do so, we\nshow that $\\mathbf{Poly}_*$, as well as any multivariate version of it, is\ntraced. We show moreover that whenever $\\mathscr{T}$ is uniform -- a condition\nalso defined by Hasegawa and satisfied by $\\mathbf{Int}(\\mathscr{T})$ -- the\nresulting $\\mathbf{Int}$-construction extends to a double category\n$\\mathbb{I}\\mathbf{nt}(\\mathscr{T})$, which is compact in the sense of\nPatterson. Finally, we define a universal property of the double category\n$\\mathbb{I}\\mathbf{nt}(\\mathbf{Poly}_*)$ and\n$\\mathbb{I}\\mathbf{nt}(\\mathbf{Set}_*)$ by which one can track trajectories as\nthey move through the control flow associated to a wiring diagram.\n","authors":["Grigory Kondyrev","David I. Spivak"],"pdf_url":"https://arxiv.org/pdf/2509.05462v1.pdf","comment":"28 pages including many diagrams"},{"id":"http://arxiv.org/abs/2509.05293v1","updated":"2025-09-05T17:58:45Z","published":"2025-09-05T17:58:45Z","title":"Non-Termination Proving: 100 Million LoC and Beyond","summary":"  We report on our tool, Pulse Infinite, that uses proof techniques to show\nnon-termination (divergence) in large programs. Pulse Infinite works\ncompositionally and under-approximately: the former supports scale, and the\nlatter ensures soundness for proving divergence. Prior work focused on small\nbenchmarks in the tens or hundreds of lines of code (LoC), and scale limits\ntheir practicality: a single company may have tens of millions, or even\nhundreds of millions of LoC or more. We report on applying Pulse Infinite to\nover a hundred million lines of open-source and proprietary software written in\nC, C++, and Hack, identifying over 30 previously unknown issues, establishing a\nnew state of the art for detecting divergence in real-world codebases.\n","authors":["Julien Vanegue","Jules Villard","Peter O'Hearn","Azalea Raad"],"pdf_url":"https://arxiv.org/pdf/2509.05293v1.pdf","comment":"14 pages, 4 figures"},{"id":"http://arxiv.org/abs/2509.05160v1","updated":"2025-09-05T14:56:18Z","published":"2025-09-05T14:56:18Z","title":"AI-Assisted Modeling: DSL-Driven AI Interactions","summary":"  AI-assisted programming greatly increases software development performance.\nWe enhance this potential by integrating transparency through domain-specific\nmodeling techniques and providing instantaneous, graphical visualizations that\naccurately represent the semantics of AI-generated code. This approach\nfacilitates visual inspection and formal verification, such as model checking.\n  Formal models can be developed using programming, natural language prompts,\nvoice commands, and stage-wise refinement, with immediate feedback after each\ntransformation step. This support can be tailored to specific domains or\nintended purposes, improving both code generation and subsequent validation\nprocesses.\n  To demonstrate the effectiveness of this approach, we have developed a\nprototype as a Visual Studio Code extension for the Lingua Franca language.\nThis prototype showcases the potential for novel domain-specific modeling\npractices, offering an advancement in how models are created, visualized, and\nverified.\n","authors":["Steven Smyth","Daniel Busch","Moez Ben Haj Hmida","Edward A. Lee","Bernhard Steffen"],"pdf_url":"https://arxiv.org/pdf/2509.05160v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2306.12935v3","updated":"2025-09-05T13:42:08Z","published":"2023-06-22T14:48:48Z","title":"Special Delivery: Programming with Mailbox Types (Extended Version)","summary":"  The asynchronous and unidirectional communication model supported by\nmailboxes is a key reason for the success of actor languages like Erlang and\nElixir for implementing reliable and scalable distributed systems. While many\nactors may send messages to some actor, only the actor may receive from its\nmailbox. Although actors eliminate many of the issues stemming from shared\nmemory concurrency, they remain vulnerable to communication errors such as\nprotocol violations and deadlocks.\n  Mailbox types are a novel behavioural type system for mailboxes first\nintroduced for a process calculus by de'Liguoro and Padovani in 2018, which\ncapture the contents of a mailbox as a commutative regular expression. Due to\naliasing and nested evaluation contexts, moving from a process calculus to a\nprogramming language is challenging. This paper presents Pat, the first\nprogramming language design incorporating mailbox types, and describes an\nalgorithmic type system. We make essential use of quasi-linear typing to tame\nsome of the complexity introduced by aliasing. Our algorithmic type system is\nnecessarily co-contextual, achieved through a novel use of backwards\nbidirectional typing, and we prove it sound and complete with respect to our\ndeclarative type system. We extend Pat with sums, products and higher-order\nfunctions, and also interfaces that allow finer-grained reasoning about mailbox\ncontents. We implement a prototype type checker, and use it to demonstrate the\nexpressiveness of Pat on a factory automation case study and a series of\nexamples from the Savina actor benchmark suite.\n","authors":["Simon Fowler","Duncan Paul Attard","Danielle Marshall","Simon J. Gay","Phil Trinder"],"pdf_url":"https://arxiv.org/pdf/2306.12935v3.pdf","comment":"Revised and extended version of paper accepted to ICFP'23"},{"id":"http://arxiv.org/abs/2504.04365v3","updated":"2025-09-05T11:08:45Z","published":"2025-04-06T05:30:10Z","title":"AutoPDL: Automatic Prompt Optimization for LLM Agents","summary":"  The performance of large language models (LLMs) depends on how they are\nprompted, with choices spanning both the high-level prompting pattern (e.g.,\nZero-Shot, CoT, ReAct, ReWOO) and the specific prompt content (instructions and\nfew-shot demonstrations). Manually tuning this combination is tedious,\nerror-prone, and specific to a given LLM and task. Therefore, this paper\nproposes AutoPDL, an automated approach to discovering good LLM agent\nconfigurations. Our approach frames this as a structured AutoML problem over a\ncombinatorial space of agentic and non-agentic prompting patterns and\ndemonstrations, using successive halving to efficiently navigate this space. We\nintroduce a library implementing common prompting patterns using the PDL prompt\nprogramming language. AutoPDL solutions are human-readable, editable, and\nexecutable PDL programs that use this library. This approach also enables\nsource-to-source optimization, allowing human-in-the-loop refinement and reuse.\nEvaluations across three tasks and seven LLMs (ranging from 3B to 70B\nparameters) show consistent accuracy gains ($9.21\\pm15.46$ percentage points),\nup to 67.5pp, and reveal that selected prompting strategies vary across models\nand tasks.\n","authors":["Claudio Spiess","Mandana Vaziri","Louis Mandel","Martin Hirzel"],"pdf_url":"https://arxiv.org/pdf/2504.04365v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.04936v1","updated":"2025-09-05T08:58:43Z","published":"2025-09-05T08:58:43Z","title":"A Large-Scale Study of Floating-Point Usage in Statically Typed\n  Languages","summary":"  Reasoning about floating-point arithmetic is notoriously hard. While static\nand dynamic analysis techniques or program repair have made significant\nprogress, more work is still needed to make them relevant to real-world code.\nOn the critical path to that goal is understanding what real-world\nfloating-point code looks like. To close that knowledge gap, this paper\npresents the first large-scale empirical study of floating-point arithmetic\nusage in statically typed languages across public GitHub repositories. We\nfollow state-of the art mining practices including random sampling and\nfiltering based on only intrinsic properties to avoid bias, and identify\nfloating-point usage by searching for keywords in the source code, and\nprogramming language constructs (e.g., loops) by parsing the code. Our\nevaluation supports the claim often made in papers that floating-point\narithmetic is widely used. Comparing statistics such as size and usage of\ncertain constructs and functions, we find that benchmarks used in literature to\nevaluate automated reasoning techniques for floating-point arithmetic are in\ncertain aspects representative of 'real-world' code, but not in all. We aim for\nour study and dataset to help future techniques for floating-point arithmetic\nto be designed and evaluated to match actual users' expectations.\n","authors":["Andrea Gilot","Tobias Wrigstad","Eva Darulova"],"pdf_url":"https://arxiv.org/pdf/2509.04936v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.04777v1","updated":"2025-09-05T03:15:27Z","published":"2025-09-05T03:15:27Z","title":"Forall-Exists Relational Verification by Filtering to Forall-Forall","summary":"  Relational verification encompasses research directions such as reasoning\nabout data abstraction, reasoning about security and privacy, secure\ncompilation, and functional specificaton of tensor programs, among others.\nSeveral relational Hoare logics exist, with accompanying tool support for\ncompositional reasoning of $\\forall\\forall$ (2-safety) properties and,\ngenerally, k-safety properties of product programs. In contrast, few logics and\ntools exist for reasoning about $\\forall\\exists$ properties which are critical\nin the context of nondeterminism.\n  This paper's primary contribution is a methodology for verifying a\n$\\forall\\exists$ judgment by way of a novel filter-adequacy transformation.\nThis transformation adds assertions to a product program in such a way that the\ndesired $\\forall\\exists$ property (of a pair of underlying unary programs) is\nimplied by a $\\forall\\forall$ property of the transformed product. The paper\ndevelops a program logic for the basic $\\forall\\exists$ judgement extended with\nassertion failures; develops bicoms, a form of product programs that represents\npairs of executions and that caters for direct translation of $\\forall\\forall$\nproperties to unary correctness; proves (using the logic) a soundness theorem\nthat says successful $\\forall\\forall$ verification of a transformed bicom\nimplies the $\\forall\\exists$ spec for its underlying unary commands; and\nimplements a proof of principle prototype for auto-active relational\nverification which has been used to verify all examples in the paper. The\nmethodology thereby enables a user to work with ordinary assertions and\nassumptions, and a standard assertion language, so that existing tools\nincluding auto-active verifiers can be used.\n","authors":["Ramana Nagasamudram","Anindya Banerjee","David A. Naumann"],"pdf_url":"https://arxiv.org/pdf/2509.04777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.09061v4","updated":"2025-09-05T01:04:00Z","published":"2025-02-13T08:23:42Z","title":"CRANE: Reasoning with constrained LLM generation","summary":"  Code generation, symbolic math reasoning, and other tasks require LLMs to\nproduce outputs that are both syntactically and semantically correct.\nConstrained LLM generation is a promising direction to enforce adherence to\nformal grammar, but prior works have empirically observed that strict\nenforcement of formal constraints often diminishes the reasoning capabilities\nof LLMs. In this work, we first provide a theoretical explanation for why\nconstraining LLM outputs to very restrictive grammars that only allow\nsyntactically valid final answers reduces the reasoning capabilities of the\nmodel. Second, we demonstrate that by augmenting the output grammar with\ncarefully designed additional rules, it is always possible to preserve the\nreasoning capabilities of the LLM while ensuring syntactic and semantic\ncorrectness in its outputs. Building on these theoretical insights, we propose\na reasoning-augmented constrained decoding algorithm, CRANE, which effectively\nbalances the correctness of constrained generation with the flexibility of\nunconstrained generation. Experiments on multiple open-source LLMs and\nbenchmarks show that CRANE significantly outperforms both state-of-the-art\nconstrained decoding strategies and standard unconstrained decoding, showing up\nto 10% points accuracy improvement over baselines on challenging symbolic\nreasoning benchmarks GSM-symbolic and FOLIO.\n","authors":["Debangshu Banerjee","Tarun Suresh","Shubham Ugare","Sasa Misailovic","Gagandeep Singh"],"pdf_url":"https://arxiv.org/pdf/2502.09061v4.pdf","comment":"Accepted at ICML 2025, Code at:\n  https://github.com/uiuc-focal-lab/CRANE"},{"id":"http://arxiv.org/abs/2509.07003v1","updated":"2025-09-05T19:29:00Z","published":"2025-09-05T19:29:00Z","title":"veScale: Consistent and Efficient Tensor Programming with Eager-Mode\n  SPMD","summary":"  Large Language Models (LLMs) have scaled rapidly in size and complexity,\nrequiring increasingly intricate parallelism for distributed training, such as\n3D parallelism. This sophistication motivates a shift toward simpler, more\ndebuggable programming paradigm like Single Program Multiple Data (SPMD).\nHowever, SPMD in eager execution introduces two key challenges: ensuring\nconsistency with single-device execution and achieving high performance at\nscale. In this paper, we introduce veScale, an eager-mode training system that\nfully embraces SPMD paradigm to democratize distributed tensor programming.\nveScale addresses the prevalent issue of inconsistent results in systems like\nPyTorch by introducing a novel algorithm of distributed Random Number\nGeneration (RNG) compatible with arbitrary sharded operators. veScale also\nsignificantly boosts training performance by reducing PyTorch primitive's\noverhead and improving communication efficiency. Evaluations show that veScale\ndelivers up to 2.2x speedup over the state-of-the-art training systems, like\nTorchTitan, and cuts code complexity by 78.4%, while preserving\nsingle-device-equivalent results.\n","authors":["Youjie Li","Cheng Wan","Zhiqi Lin","Hongyu Zhu","Jiacheng Yang","Ziang Song","Xinyi Di","Jiawei Wu","Huiyao Shu","Wenlei Bao","Yanghua Peng","Haibin Lin","Li-Wen Chang"],"pdf_url":"https://arxiv.org/pdf/2509.07003v1.pdf","comment":"21 pages, 16 figures, 5 tables"}],"Data Structures and Algorithms":[{"id":"http://arxiv.org/abs/2508.16531v2","updated":"2025-09-05T17:58:45Z","published":"2025-08-22T16:54:18Z","title":"Quality control in sublinear time: a case study via random graphs","summary":"  Many algorithms are designed to work well on average over inputs. When\nrunning such an algorithm on an arbitrary input, we must ask: Can we trust the\nalgorithm on this input? We identify a new class of algorithmic problems\naddressing this, which we call \"Quality Control Problems.\" These problems are\nspecified by a (positive, real-valued) \"quality function\" $\\rho$ and a\ndistribution $D$ such that, with high probability, a sample drawn from $D$ is\n\"high quality,\" meaning its $\\rho$-value is near $1$. The goal is to accept\ninputs $x \\sim D$ and reject potentially adversarially generated inputs $x$\nwith $\\rho(x)$ far from $1$. The objective of quality control is thus weaker\nthan either component problem: testing for \"$\\rho(x) \\approx 1$\" or testing if\n$x \\sim D$, and offers the possibility of more efficient algorithms.\n  In this work, we consider the sublinear version of the quality control\nproblem, where $D \\in \\Delta(\\{0,1\\}^N)$ and the goal is to solve the $(D\n,\\rho)$-quality problem with $o(N)$ queries and time. As a case study, we\nconsider random graphs, i.e., $D = G_{n,p}$ (and $N = \\binom{n}2$), and the\n$k$-clique count function $\\rho_k := C_k(G)/\\mathbb{E}_{G' \\sim\nG_{n,p}}[C_k(G')]$, where $C_k(G)$ is the number of $k$-cliques in $G$. Testing\nif $G \\sim G_{n,p}$ with one sample, let alone with sublinear query access to\nthe sample, is of course impossible. Testing if $\\rho_k(G)\\approx 1$ requires\n$p^{-\\Omega(k^2)}$ samples. In contrast, we show that the quality control\nproblem for $G_{n,p}$ (with $n \\geq p^{-ck}$ for some constant $c$) with\nrespect to $\\rho_k$ can be tested with $p^{-O(k)}$ queries and time, showing\nquality control is provably superpolynomially more efficient in this setting.\nMore generally, for a motif $H$ of maximum degree $\\Delta(H)$, the respective\nquality control problem can be solved with $p^{-O(\\Delta(H))}$ queries and\nrunning time.\n","authors":["Cassandra Marcussen","Ronitt Rubinfeld","Madhu Sudan"],"pdf_url":"https://arxiv.org/pdf/2508.16531v2.pdf","comment":"70 pages"},{"id":"http://arxiv.org/abs/2509.05245v1","updated":"2025-09-05T16:59:32Z","published":"2025-09-05T16:59:32Z","title":"Vertex-ordering and arc-partitioning problems","summary":"  We study vertex-ordering problems in loop-free digraphs subject to\nconstraints on the left-going arcs, focusing on existence conditions and\ncomputational complexity. As an intriguing special case, we explore\nvertex-specific lower and upper bounds on the left-outdegrees and\nright-indegrees. We show, for example, that deciding whether the left-going\narcs can form an in-branching is solvable in polynomial time and provide a\nnecessary and sufficient condition, while the analogous problem for an\nin-arborescence turns out to be NP-complete. We also consider a weighted\nvariant that enforces vertex-specific lower and upper bounds on the weighted\nleft-outdegrees, which is particularly relevant in applications. Furthermore,\nwe investigate the connection between ordering problems and their\narc-partitioning counterparts, where one seeks to partition the arcs into a\nsubgraph from a specific digraph family and an acyclic subgraph --\nequivalently, one seeks to cover all directed cycles with a subgraph belonging\nto a specific family. For the family of in-branchings, unions of disjoint\ndipaths, and matchings, the two formulations coincide, whereas for\nin-arborescences, dipaths, Hamiltonian dipaths, and perfect matchings the\nformulations diverge. Our results yield a comprehensive complexity landscape,\nunify diverse special cases and variants, clarify the algorithmic boundaries of\nordered digraphs, and relate them to broader topics including graph degeneracy,\nacyclic orientations, influence propagation, and rank aggregation.\n","authors":["Nóra A. Borsik","Péter Madarasi"],"pdf_url":"https://arxiv.org/pdf/2509.05245v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.02670v3","updated":"2025-09-05T16:24:28Z","published":"2024-12-03T18:44:19Z","title":"The Broader Landscape of Robustness in Algorithmic Statistics","summary":"  The last decade has seen a number of advances in computationally efficient\nalgorithms for statistical methods subject to robustness constraints. An\nestimator may be robust in a number of different ways: to contamination of the\ndataset, to heavy-tailed data, or in the sense that it preserves privacy of the\ndataset. We survey recent results in these areas with a focus on the problem of\nmean estimation, drawing technical and conceptual connections between the\nvarious forms of robustness, showing that the same underlying algorithmic ideas\nlead to computationally efficient estimators in all these settings.\n","authors":["Gautam Kamath"],"pdf_url":"https://arxiv.org/pdf/2412.02670v3.pdf","comment":"To appear in IEEE BITS the Information Theory Magazine"},{"id":"http://arxiv.org/abs/2509.05203v1","updated":"2025-09-05T16:07:15Z","published":"2025-09-05T16:07:15Z","title":"List Decoding Expander-Based Codes via Fast Approximation of Expanding\n  CSPs: I","summary":"  We present near-linear time list decoding algorithms (in the block-length\n$n$) for expander-based code constructions. More precisely, we show that\n  (i) For every $\\delta \\in (0,1)$ and $\\epsilon > 0$, there is an explicit\nfamily of good Tanner LDPC codes of (design) distance $\\delta$ that is $(\\delta\n- \\epsilon, O_\\varepsilon(1))$ list decodable in time\n$\\widetilde{\\mathcal{O}}_{\\varepsilon}(n)$ with alphabet size $O_\\delta(1)$,\n  (ii) For every $R \\in (0,1)$ and $\\epsilon > 0$, there is an explicit family\nof AEL codes of rate $R$, distance $1-R -\\varepsilon$ that is $(1-R-\\epsilon,\nO_\\varepsilon(1))$ list decodable in time\n$\\widetilde{\\mathcal{O}}_{\\varepsilon}(n)$ with alphabet size\n$\\text{exp}(\\text{poly}(1/\\epsilon))$, and\n  (iii) For every $R \\in (0,1)$ and $\\epsilon > 0$, there is an explicit family\nof AEL codes of rate $R$, distance $1-R-\\varepsilon$ that is $(1-R-\\epsilon,\nO(1/\\epsilon))$ list decodable in time\n$\\widetilde{\\mathcal{O}}_{\\varepsilon}(n)$ with alphabet size\n$\\text{exp}(\\text{exp}(\\text{poly}(1/\\epsilon)))$ using recent near-optimal\nlist size bounds from [JMST25].\n  Our results are obtained by phrasing the decoding task as an agreement CSP\n[RWZ20,DHKNT19] on expander graphs and using the fast approximation algorithm\nfor $q$-ary expanding CSPs from [Jer23], which is based on weak regularity\ndecomposition [JST21,FK96]. Similarly to list decoding $q$-ary Ta-Shma's codes\nin [Jer23], we show that it suffices to enumerate over assignments that are\nconstant in each part (of the constantly many) of the decomposition in order to\nrecover all codewords in the list.\n","authors":["Fernando Granha Jeronimo","Aman Singh"],"pdf_url":"https://arxiv.org/pdf/2509.05203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.05157v1","updated":"2025-09-05T14:49:16Z","published":"2025-09-05T14:49:16Z","title":"Efficient Contractions of Dynamic Graphs -- with Applications","summary":"  A non-trivial minimum cut (NMC) sparsifier is a multigraph $\\hat{G}$ that\npreserves all non-trivial minimum cuts of a given undirected graph $G$. We\nintroduce a flexible data structure for fully dynamic graphs that can\nefficiently provide an NMC sparsifier upon request at any point during the\nsequence of updates. We employ simple dynamic forest data structures to achieve\na fast from-scratch construction of the sparsifier at query time. Based on the\nstrength of the adversary and desired type of time bounds, the data structure\ncomes with different guarantees. Specifically, let $G$ be a fully dynamic\nsimple graph with $n$ vertices and minimum degree $\\delta$. Then our data\nstructure supports an insertion/deletion of an edge to/from $G$ in $n^{o(1)}$\nworst-case time. Furthermore, upon request, it can return w.h.p. an NMC\nsparsifier of $G$ that has $O(n/\\delta)$ vertices and $O(n)$ edges, in\n$\\hat{O}(n)$ time. The probabilistic guarantees hold against an adaptive\nadversary. Alternatively, the update and query times can be improved to\n$\\tilde{O}(1)$ and $\\tilde{O}(n)$ respectively, if amortized-time guarantees\nare sufficient, or if the adversary is oblivious.\n  We discuss two applications of our data structure. First, it can be used to\nefficiently report a cactus representation of all minimum cuts of a fully\ndynamic simple graph. Using the NMC sparsifier we can w.h.p. build this cactus\nin worst-case time $\\hat{O}(n)$ against an adaptive adversary. Second, our data\nstructure allows us to efficiently compute the maximal $k$-edge-connected\nsubgraphs of undirected simple graphs, by repeatedly applying a minimum cut\nalgorithm on the NMC sparsifier. Specifically, we can compute w.h.p. the\nmaximal $k$-edge-connected subgraphs of a simple graph with $n$ vertices and\n$m$ edges in $\\tilde{O}(m+n^2/k)$ time which is an improvement for $k =\n\\Omega(n^{1/8})$ and works for fully dynamic graphs.\n","authors":["Monika Henzinger","Evangelos Kosinas","Robin Münk","Harald Räcke"],"pdf_url":"https://arxiv.org/pdf/2509.05157v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.05132v1","updated":"2025-09-05T14:19:21Z","published":"2025-09-05T14:19:21Z","title":"Testing Depth First Search Numbering","summary":"  Property Testing is a formal framework to study the computational power and\ncomplexity of sampling from combinatorial objects. A central goal in standard\ngraph property testing is to understand which graph properties are testable\nwith sublinear query complexity. Here, a graph property P is testable with a\nsublinear query complexity if there is an algorithm that makes a sublinear\nnumber of queries to the input graph and accepts with probability at least 2/3,\nif the graph has property P, and rejects with probability at least 2/3 if it is\n$\\varepsilon$-far from every graph that has property P.\n  In this paper, we introduce a new variant of the bounded degree graph model.\nIn this variant, in addition to the standard representation of a bounded degree\ngraph, we assume that every vertex $v$ has a unique label num$(v)$ from $\\{1,\n\\dots, |V|\\}$, and in addition to the standard queries in the bounded degree\ngraph model, we also allow a property testing algorithm to query for the label\nof a vertex (but not for a vertex with a given label).\n  Our new model is motivated by certain graph processes such as a DFS\ntraversal, which assign consecutive numbers (labels) to the vertices of the\ngraph. We want to study which of these numberings can be tested in sublinear\ntime. As a first step in understanding such a model, we develop a\n\\emph{property testing algorithm for discovery times of a DFS traversal} with\nquery complexity $O(n^{1/3}/\\varepsilon)$ and for constant $\\varepsilon>0$ we\ngive a matching lower bound.\n","authors":["Artur Czumaj","Christian Sohler","Stefan Walzer"],"pdf_url":"https://arxiv.org/pdf/2509.05132v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.05129v1","updated":"2025-09-05T14:14:36Z","published":"2025-09-05T14:14:36Z","title":"Efficient Exact Resistance Distance Computation on Small-Treewidth\n  Graphs: a Labelling Approach","summary":"  Resistance distance computation is a fundamental problem in graph analysis,\nyet existing random walk-based methods are limited to approximate solutions and\nsuffer from poor efficiency on small-treewidth graphs (e.g., road networks). In\ncontrast, shortest-path distance computation achieves remarkable efficiency on\nsuch graphs by leveraging cut properties and tree decompositions. Motivated by\nthis disparity, we first analyze the cut property of resistance distance. While\na direct generalization proves impractical due to costly matrix operations, we\novercome this limitation by integrating tree decompositions, revealing that the\nresistance distance $r(s,t)$ depends only on labels along the paths from $s$\nand $t$ to the root of the decomposition. This insight enables compact\nlabelling structures. Based on this, we propose \\treeindex, a novel index\nmethod that constructs a resistance distance labelling of size $O(n \\cdot\nh_{\\mathcal{G}})$ in $O(n \\cdot h_{\\mathcal{G}}^2 \\cdot d_{\\max})$ time, where\n$h_{\\mathcal{G}}$ (tree height) and $d_{\\max}$ (maximum degree) behave as small\nconstants in many real-world small-treewidth graphs (e.g., road networks). Our\nlabelling supports exact single-pair queries in $O(h_{\\mathcal{G}})$ time and\nsingle-source queries in $O(n \\cdot h_{\\mathcal{G}})$ time. Extensive\nexperiments show that TreeIndex substantially outperforms state-of-the-art\napproaches. For instance, on the full USA road network, it constructs a $405$\nGB labelling in $7$ hours (single-threaded) and answers exact single-pair\nqueries in $10^{-3}$ seconds and single-source queries in $190$ seconds--the\nfirst exact method scalable to such large graphs.\n","authors":["Meihao Liao","Yueyang Pan","Rong-Hua Li","Guoren Wang"],"pdf_url":"https://arxiv.org/pdf/2509.05129v1.pdf","comment":"Accepted by SIGMOD 2026"},{"id":"http://arxiv.org/abs/2509.05122v1","updated":"2025-09-05T14:08:21Z","published":"2025-09-05T14:08:21Z","title":"Improved Bounds for Twin-Width Parameter Variants with Algorithmic\n  Applications to Counting Graph Colorings","summary":"  The $H$-Coloring problem is a well-known generalization of the classical\nNP-complete problem $k$-Coloring where the task is to determine whether an\ninput graph admits a homomorphism to the template graph $H$. This problem has\nbeen the subject of intense theoretical research and in this article we study\nthe complexity of $H$-Coloring with respect to the parameters clique-width and\nthe more recent component twin-width, which describe desirable computational\nproperties of graphs. We give two surprising linear bounds between these\nparameters, thus improving the previously known exponential and double\nexponential bounds. Our constructive proof naturally extends to related\nparameters and as a showcase we prove that total twin-width and linear\nclique-width can be related via a tight quadratic bound. These bounds naturally\nlead to algorithmic applications. The linear bounds between component\ntwin-width and clique-width entail natural approximations of component\ntwin-width, by making use of the results known for clique-width. As for\ncomputational aspects of graph coloring, we target the richer problem of\ncounting the number of homomorphisms to $H$ (#$H$-Coloring). The first\nalgorithm that we propose uses a contraction sequence of the input graph $G$\nparameterized by the component twin-width of $G$. This leads to a positive FPT\nresult for the counting version. The second uses a contraction sequence of the\ntemplate graph $H$ and here we instead measure the complexity with respect to\nthe number of vertices in the input graph. Using our linear bounds we show that\nour algorithms are always at least as fast as the previously best #$H$-Coloring\nalgorithms (based on clique-width) and for several interesting classes of\ngraphs (e.g., cographs, cycles of length $\\ge 7$, or distance-hereditary\ngraphs) are in fact strictly faster.\n","authors":["Ambroise Baril","Miguel Couceiro","Victor Lagerkvist"],"pdf_url":"https://arxiv.org/pdf/2509.05122v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.10471v2","updated":"2025-09-05T13:23:27Z","published":"2022-11-18T19:19:24Z","title":"Prophet Inequalities over Time","summary":"  In this paper, we introduce an over-time variant of the well-known prophet\ninequality with i.i.d. random variables. Instead of stopping with one realized\nvalue at some point in the process, we decide for each step how long we select\nthe value. Then we cannot select another value until this period is over. The\ngoal is to maximize the expectation of the sum of selected values. We describe\nthe structure of the optimal stopping rule and give upper and lower bounds on\nthe prophet inequality. In online algorithms terminology, this corresponds to\nbounds on the competitive ratio of an online algorithm.\n  We give a surprisingly simple algorithm with a single threshold that results\nin a prophet inequality of $\\approx 0.396$ for all input lengths $n$.\nAdditionally, as our main result, we present a more advanced algorithm\nresulting in a prophet inequality of $\\approx 0.598$ when the number of steps\ntends to infinity. We complement our results by an upper bound that shows that\nthe best possible prophet inequality is at most $1/\\varphi \\approx 0.618$,\nwhere $\\varphi$ denotes the golden ratio.\n","authors":["Andreas Abels","Elias Pitschmann","Daniel Schmand"],"pdf_url":"https://arxiv.org/pdf/2211.10471v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.05024v1","updated":"2025-09-05T11:35:31Z","published":"2025-09-05T11:35:31Z","title":"Capturing an Invisible Robber using Separators","summary":"  We study the zero-visibility cops and robbers game, where the robber is\ninvisible to the cops until they are caught. This differs from the classic game\nwhere full information about the robber's location is known at any time. A\npreviously known solution for capturing a robber in the zero-visibility case is\nbased on the pathwidth decomposition. We provide an alternative solution based\non a separation hierarchy, improving capture time and space complexity without\nasymptotically increasing the zero-visibility cop number in most cases. In\naddition, we provide a better bound on the approximate zero-visibility cop\nnumber for various classes of graphs, where approximate refers to the\nrestriction to polynomial time computable strategies.\n","authors":["Igor Potapov","Tymofii Prokopenko","John Sylvester"],"pdf_url":"https://arxiv.org/pdf/2509.05024v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.05016v1","updated":"2025-09-05T11:25:22Z","published":"2025-09-05T11:25:22Z","title":"On approximating the $f$-divergence between two Ising models","summary":"  The $f$-divergence is a fundamental notion that measures the difference\nbetween two distributions. In this paper, we study the problem of approximating\nthe $f$-divergence between two Ising models, which is a generalization of\nrecent work on approximating the TV-distance. Given two Ising models $\\nu$ and\n$\\mu$, which are specified by their interaction matrices and external fields,\nthe problem is to approximate the $f$-divergence $D_f(\\nu\\,\\|\\,\\mu)$ within an\narbitrary relative error $\\mathrm{e}^{\\pm \\varepsilon}$. For\n$\\chi^\\alpha$-divergence with a constant integer $\\alpha$, we establish both\nalgorithmic and hardness results. The algorithm works in a parameter regime\nthat matches the hardness result. Our algorithm can be extended to other\n$f$-divergences such as $\\alpha$-divergence, Kullback-Leibler divergence,\nR\\'enyi divergence, Jensen-Shannon divergence, and squared Hellinger distance.\n","authors":["Weiming Feng","Yucheng Fu"],"pdf_url":"https://arxiv.org/pdf/2509.05016v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.05002v1","updated":"2025-09-05T10:51:18Z","published":"2025-09-05T10:51:18Z","title":"Graph Reconstruction with a Connected Components Oracle","summary":"  In the Graph Reconstruction (GR) problem, the goal is to recover a hidden\ngraph by utilizing some oracle that provides limited access to the structure of\nthe graph. The interest is in characterizing how strong different oracles are\nwhen the complexity of an algorithm is measured in the number of performed\nqueries. We study a novel oracle that returns the set of connected components\n(CC) on the subgraph induced by the queried subset of vertices. Our main\ncontributions are as follows:\n  1. For a hidden graph with $n$ vertices, $m$ edges, maximum degree $\\Delta$,\nand treewidth $k$, GR can be solved in $O(\\min\\{m, \\Delta^2, k^2\\} \\cdot \\log\nn)$ CC queries by an adaptive randomized algorithm.\n  2. For a hidden graph with $n$ vertices, $m$ edges, maximum degree $\\Delta$,\nand treewidth $k$, no algorithm can solve GR in $o(\\min\\{m, \\Delta^2, k^2\\})$\nCC queries.\n","authors":["Juha Harviainen","Pekka Parviainen"],"pdf_url":"https://arxiv.org/pdf/2509.05002v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.04976v1","updated":"2025-09-05T09:59:18Z","published":"2025-09-05T09:59:18Z","title":"Parameterized Approximability for Modular Linear Equations","summary":"  We consider the Min-$r$-Lin$(Z_m)$ problem: given a system $S$ of length-$r$\nlinear equations modulo $m$, find $Z \\subseteq S$ of minimum cardinality such\nthat $S-Z$ is satisfiable. The problem is NP-hard and UGC-hard to approximate\nin polynomial time within any constant factor even when $r = m = 2$. We focus\non parameterized approximation with solution size as the parameter. Dabrowski\net al. showed that Min-$2$-Lin$(Z_m)$ is in FPT if $m$ is prime (i.e. $Z_m$ is\na field), and it is W[1]-hard if $m$ is not a prime power. We show that\nMin-$2$-Lin$(Z_{p^n})$ is FPT-approximable within a factor of $2$ for every\nprime $p$ and integer $n \\geq 2$. This implies that Min-$2$-Lin$(Z_m)$, $m \\in\nZ^+$, is FPT-approximable within a factor of $2\\omega(m)$ where $\\omega(m)$\ncounts the number of distinct prime divisors of $m$. The idea behind the\nalgorithm is to solve ever tighter relaxations of the problem, decreasing the\nset of possible values for the variables at each step. Working over $Z_{p^n}$\nand viewing the values in base-$p$, one can roughly think of a relaxation as\nfixing the number of trailing zeros and the least significant nonzero digits of\nthe values assigned to the variables. To solve the relaxed problem, we\nconstruct a certain graph where solutions can be identified with a particular\ncollection of cuts. The relaxation may hide obstructions that will only become\nvisible in the next iteration of the algorithm, which makes it difficult to\nfind optimal solutions. To deal with this, we use a strategy based on shadow\nremoval to compute solutions that (1) cost at most twice as much as the optimum\nand (2) allow us to reduce the set of values for all variables simultaneously.\nWe complement the algorithmic result with two lower bounds, ruling out\nconstant-factor FPT-approximation for Min-$3$-Lin$(R)$ over any nontrivial ring\n$R$ and for Min-$2$-Lin$(R)$ over some finite commutative rings $R$.\n","authors":["Konrad K. Dabrowski","Peter Jonsson","Sebastian Ordyniak","George Osipov","Magnus Wahlström"],"pdf_url":"https://arxiv.org/pdf/2509.04976v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2410.09932"},{"id":"http://arxiv.org/abs/2509.04919v1","updated":"2025-09-05T08:37:30Z","published":"2025-09-05T08:37:30Z","title":"Optimal Variance and Covariance Estimation under Differential Privacy in\n  the Add-Remove Model and Beyond","summary":"  In this paper, we study the problem of estimating the variance and covariance\nof datasets under differential privacy in the add-remove model. While\nestimation in the swap model has been extensively studied in the literature,\nthe add-remove model remains less explored and more challenging, as the dataset\nsize must also be kept private. To address this issue, we develop efficient\nmechanisms for variance and covariance estimation based on the \\emph{B\\'{e}zier\nmechanism}, a novel moment-release framework that leverages Bernstein bases. We\nprove that our proposed mechanisms are minimax optimal in the high-privacy\nregime by establishing new minimax lower bounds. Moreover, beyond worst-case\nscenarios, we analyze instance-wise utility and show that the B\\'{e}zier-based\nestimator consistently achieves better utility compared to alternative\nmechanisms. Finally, we demonstrate the effectiveness of the B\\'{e}zier\nmechanism beyond variance and covariance estimation, showcasing its\napplicability to other statistical tasks.\n","authors":["Shokichi Takakura","Seng Pei Liew","Satoshi Hasegawa"],"pdf_url":"https://arxiv.org/pdf/2509.04919v1.pdf","comment":null}]},"2025-09-07T00:00:00Z":{"Systems and Control":[{"id":"http://arxiv.org/abs/2509.06229v1","updated":"2025-09-07T22:31:14Z","published":"2025-09-07T22:31:14Z","title":"20 Years in Life of a Smart Building: A retrospective","summary":"  Operating an intelligent smart building automation system in 2025 is met with\nmany challenges: hardware failures, vendor obsolescence, evolving security\nthreats and more. None of these have been comprehensibly addressed by the\nindustrial building nor home automation industries, limiting feasibility of\noperating large, truly smart automation deployments. This paper introduces\nKaOS, a distributed control platform for constructing robust and evolvable\nsmart building automation systems using affordable, off-the-shelf IoT hardware.\nSupporting control applications and distributed system operations by leveraging\ncontainerisation and managed resource access, KaOS seeks to achieve\nflexibility, security, and fault tolerance without sacrificing\ncost-effectiveness. Initial evaluation confirms the practical feasibility of\nour approach, highlighting its potential to sustainably maintain and\nincrementally evolve building control functionalities over extended timeframes.\n","authors":["Karolina Skrivankova","Mark Handley","Stephen Hailes"],"pdf_url":"https://arxiv.org/pdf/2509.06229v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.12185v2","updated":"2025-09-07T22:00:59Z","published":"2025-08-17T00:01:56Z","title":"Understanding the Fundamental Trade-Off Between Age of Information and\n  Throughput in Unreliable Wireless Networks","summary":"  This paper characterizes the fundamental trade-off between throughput and Age\nof Information (AoI) in wireless networks where multiple devices transmit\nstatus updates to a central base station over unreliable channels. To address\nthe complexity introduced by stochastic transmission successes, we propose the\nthroughput-AoI capacity region, which defines all feasible throughput-AoI pairs\nachievable under any scheduling policy. Using a second-order approximation that\nincorporates both mean and temporal variance, we derive an outer bound and a\ntight inner bound for the throughput-AoI capacity region. Furthermore, we\npropose a simple and low complexity scheduling policy and prove that it\nachieves every interior point within the tight inner bound. This establishes a\nsystematic and theoretically grounded framework for the joint optimization of\nthroughput and information freshness in practical wireless communication\nscenarios.\n  To validate our theoretical framework and demonstrate the utility of the\nthroughput-AoI capacity region, extensive simulations are implemented.\nSimulation results demonstrate that our proposed policy significantly\noutperforms conventional methods across various practical network optimization\nscenarios. The findings highlight our approach's effectiveness in optimizing\nboth throughput and AoI, underscoring its applicability and robustness in\npractical wireless networks.\n","authors":["Lin Wang","I-Hong Hou"],"pdf_url":"https://arxiv.org/pdf/2508.12185v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.03119v2","updated":"2025-09-07T20:49:09Z","published":"2025-09-03T08:20:55Z","title":"Forbal: Force Balanced 2-5 Degree of Freedom Robot Manipulator Built\n  from a Five Bar Linkage","summary":"  A force balanced manipulator design based on the closed chain planar five bar\nlinkage is developed and experimentally validated. We present 2 variants as a\nmodular design: Forbal-2, a planar 2-DOF manipulator, and its extension to\n5-DOF spatial motion called Forbal-5. The design considerations in terms of\ngeometric, kinematic, and dynamic design that fulfill the force balance\nconditions while maximizing workspace are discussed. Then, the inverse\nkinematics of both variants are derived from geometric principles. We validate\nthe improvements from force balancing the manipulator through comparative\nexperiments with counter mass balanced and unbalanced configurations. The\nresults show how the balanced configuration yields a reduction in the average\nreaction moments of up to 66%, a reduction of average joint torques of up to\n79%, as well as a noticeable reduction in position error for Forbal-2. For\nForbal-5, which has a higher end effector payload mass, the joint torques are\nreduced up to 84% for the balanced configuration. Experimental results validate\nthat the balanced manipulator design is suitable for applications where the\nreduction of joint torques and reaction forces/moments helps achieve millimeter\nlevel precision.\n","authors":["Yash Vyas","Matteo Bottin"],"pdf_url":"https://arxiv.org/pdf/2509.03119v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.15724v3","updated":"2025-09-07T20:11:46Z","published":"2024-02-24T05:19:33Z","title":"Offline Learning of Decision Functions in Multiplayer Games with\n  Expectation Constraints","summary":"  We explore a class of stochastic multiplayer games where each player in the\ngame aims to optimize its objective under uncertainty and adheres to some\nexpectation constraints. The study employs an offline learning paradigm,\nleveraging a pre-existing dataset containing auxiliary features. While prior\nresearch in deterministic and stochastic multiplayer games primarily explored\nvector-valued decisions, this work departs by considering function-valued\ndecisions that incorporate auxiliary features as input. We leverage the law of\nlarge deviations and degree theory to establish the almost sure convergence of\nthe offline learning solution to the true solution as the number of data\nsamples increases.\n","authors":["Yuanhanqing Huang","Jianghai Hu"],"pdf_url":"https://arxiv.org/pdf/2402.15724v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.06188v1","updated":"2025-09-07T19:49:03Z","published":"2025-09-07T19:49:03Z","title":"Ignore Drift, Embrace Simplicity: Constrained Nonlinear Control through\n  Driftless Approximation","summary":"  We present a novel technique to drive a nonlinear system to reach a target\nstate under input constraints. The proposed controller consists only of\npiecewise constant inputs, generated from a simple linear driftless\napproximation to the original nonlinear system. First, we construct this\napproximation using only the effect of the control input at the initial state.\nNext, we partition the time horizon into successively shorter intervals and\nshow that optimal controllers for the linear driftless system result in a\nbounded error from a specified target state in the nonlinear system. We also\nderive conditions under which the input constraint is guaranteed to be\nsatisfied. On applying the optimal control inputs, we show that the error\nmonotonically converges to zero as the intervals become successively shorter,\nthus achieving arbitrary closeness to the target state with time. Using\nsimulation examples on classical nonlinear systems, we illustrate how the\npresented technique is used to reach a target state while still satisfying\ninput constraints. In particular, we show that our method completes the task\neven when assumptions of the underlying theory are violated or when classical\nlinearization-based methods may fail.\n","authors":["Ram Padmanabhan","Melkior Ornik"],"pdf_url":"https://arxiv.org/pdf/2509.06188v1.pdf","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2509.06133v1","updated":"2025-09-07T16:40:30Z","published":"2025-09-07T16:40:30Z","title":"VehiclePassport: A GAIA-X-Aligned, Blockchain-Anchored\n  Privacy-Preserving, Zero-Knowledge Digital Passport for Smart Vehicles","summary":"  Modern vehicles accumulate fragmented lifecycle records across OEMs, owners,\nand service centers that are difficult to verify and prone to fraud. We propose\nVehiclePassport, a GAIA-X-aligned digital passport anchored on blockchain with\nzero-knowledge proofs (ZKPs) for privacy-preserving verification.\nVehiclePassport immutably commits to manufacturing, telemetry, and service\nevents while enabling selective disclosure via short-lived JWTs and Groth16\nproofs. Our open-source reference stack anchors hashes on Polygon zkEVM at\n<$0.02 per event, validates proofs in <10 ms, and scales to millions of\nvehicles. This architecture eliminates paper-based KYC, ensures GDPR-compliant\ntraceability, and establishes a trustless foundation for insurance, resale, and\nregulatory applications in global mobility data markets.\n","authors":["Pradyumna Kaushal"],"pdf_url":"https://arxiv.org/pdf/2509.06133v1.pdf","comment":"13 pages, 5 figures. Whitepaper submission; LaTeX source with\n  compiled .bbl. Includes architecture diagrams, tables, and code listings\n  (TypeScript & Solidity)"},{"id":"http://arxiv.org/abs/2509.06119v1","updated":"2025-09-07T16:06:08Z","published":"2025-09-07T16:06:08Z","title":"A Hybrid TDMA/CSMA Protocol for Time-Sensitive Traffic in Robot\n  Applications","summary":"  Recent progress in robotics has underscored the demand for real-time control\nin applications such as manufacturing, healthcare, and autonomous systems,\nwhere the timely delivery of mission-critical commands under heterogeneous\nrobotic traffic is paramount for operational efficacy and safety. In these\nscenarios, mission-critical traffic follows a strict deadline-constrained\ncommunication pattern: commands must arrive within defined QoS deadlines,\notherwise late arrivals can degrade performance or destabilize control loops.In\nthis work, we demonstrate on a real-time SDR platform that CSMA, widely adopted\nin robotic communications,suffers severe degradation under high robot traffic\nloads, with contention-induced collisions and delays disrupting the on-time\narrival of mission-critical packets. To address this problem, we propose an\nIEEE 802.11-compatible hybrid TDMA/CSMA protocol that combines TDMA's\ndeterministic slot scheduling with CSMA's adaptability for heterogeneous robot\ntraffic.The protocol achieves collision-free, low-latency mission-critical\ncommand delivery and IEEE 802.11 compatibility through the synergistic\nintegration of sub-microsecond PTP-based slot synchronization-essential for\nestablishing precise timing for TDMA, a three-session superframe with dynamic\nTDMA allocation for structured and adaptable traffic management,and beacon-NAV\nprotection to preemptively secure these critical communication sessions from\ninterference. Emulation experiments on real-time SDR testbed and Robot\nOperating System (ROS) simulation show that the proposed protocol reduces\nmissed-deadline errors by 93% compared to the CSMA baseline. In high-speed\nrobot path-tracking ROS simulations, the protocol lowers Root Mean Square (RMS)\ntrajectory error by up to 90% compared with a CSMA baseline, all while\nmaintaining throughput for non-critical traffic within +-2%.\n","authors":["Shiqi Xu","Lihao Zhang","Yuyang Du","Qun Yang","Soung Chang Liew"],"pdf_url":"https://arxiv.org/pdf/2509.06119v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.06115v1","updated":"2025-09-07T15:55:12Z","published":"2025-09-07T15:55:12Z","title":"Hybrid A* Path Planning with Multi-Modal Motion Extension for Four-Wheel\n  Steering Mobile Robots","summary":"  Four-wheel independent steering (4WIS) systems provide mobile robots with a\nrich set of motion modes, such as Ackermann steering, lateral steering, and\nparallel movement, offering superior maneuverability in constrained\nenvironments. However, existing path planning methods generally assume a single\nkinematic model and thus fail to fully exploit the multi-modal capabilities of\n4WIS platforms. To address this limitation, we propose an extended Hybrid A*\nframework that operates in a four-dimensional state space incorporating both\nspatial states and motion modes. Within this framework, we design multi-modal\nReeds-Shepp curves tailored to the distinct kinematic constraints of each\nmotion mode, develop an enhanced heuristic function that accounts for\nmode-switching costs, and introduce a terminal connection strategy with\nintelligent mode selection to ensure smooth transitions between different\nsteering patterns. The proposed planner enables seamless integration of\nmultiple motion modalities within a single path, significantly improving\nflexibility and adaptability in complex environments. Results demonstrate\nsignificantly improved planning performance for 4WIS robots in complex\nenvironments.\n","authors":["Runjiao Bao","Lin Zhang","Tianwei Niu","Haoyu Yuan","Shoukun Wang"],"pdf_url":"https://arxiv.org/pdf/2509.06115v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.06092v1","updated":"2025-09-07T15:15:08Z","published":"2025-09-07T15:15:08Z","title":"Mutual Support by Sensor-Attacker Team for a Passive Target","summary":"  We introduce a pursuit game played between a team of a sensor and an attacker\nand a mobile target in the unbounded Euclidean plane. The target is faster than\nthe sensor, but slower than the attacker. The sensor's objective is to keep the\ntarget within a sensing radius so that the attacker can capture the target,\nwhereas the target seeks to escape by reaching beyond the sensing radius from\nthe sensor without getting captured by the attacker. We assume that as long as\nthe target is within the sensing radius from the sensor, the sensor-attacker\nteam is able to measure the target's instantaneous position and velocity. We\npose and solve this problem as a \\emph{game of kind} in which the target uses\nan open-loop strategy (passive target). Aside from the novel formulation, our\ncontributions are four-fold. First, we present optimal strategies for both the\nsensor and the attacker, according to their respective objectives.\nSpecifically, we design a sensor strategy that maximizes the duration for which\nthe target remains within its sensing range, while the attacker uses\nproportional navigation to capture the target. Second, we characterize the\n\\emph{sensable region} -- the region in the plane in which the target remains\nwithin the sensing radius of the sensor during the game -- and show that\ncapture is guaranteed {if and only if} the Apollonius circle between the\nattacker and the target is fully contained within this region. Third, we\n{derive a lower bound} on the target's speed below which capture is guaranteed,\nand an upper bound on the target speed above which there exists an escape\nstrategy for the target, from an arbitrary initial orientation between the\nagents. Fourth, for a given initial orientation between the agents, we present\na sharper upper bound on the target speed above which there exists an escape\nstrategy for the target.\n","authors":["Prajakta Surve","Shaunak D. Bopardikar","Alexander Von Moll","Isaac Weintraub","David W. Casbeer"],"pdf_url":"https://arxiv.org/pdf/2509.06092v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.12887v3","updated":"2025-09-07T14:24:14Z","published":"2023-04-25T14:59:25Z","title":"Data-Driven Robust Optimization for Energy-Aware Safe Motion Planning of\n  Electric Vehicles","summary":"  In this paper, we simultaneously address the problems of energy optimal and\nsafe motion planning of electric vehicles (EVs) in a data-driven robust\noptimization framework. Safe maneuvers, especially in urban traffic, are\ncharacterized by frequent lateral motions, such as lane changes, overtakes and\nturning along curved roads. Motivated by our previous work which shows a 3-10 %\nincrease in energy consumption due to lateral motion when an electric vehicle\nchanges its lane once every kilometer while following standard drive cycles, we\nincorporate vehicle lateral dynamics in the modeling and control synthesis,\nwhich is in contrast with most prior works. In the context of safety, we\nleverage past data of obstacle motion to construct a future occupancy set with\nprobabilistic guarantees, and formulate robust collision avoidance constraints\nwith respect to such an occupancy set using convex programming duality.\nConsequently, we formulate a finite-horizon optimal control problem subject to\nrobust collision avoidance constraints while penalizing resulting energy\nconsumption, and solve it in a receding horizon fashion. Finally, we show the\neffectiveness of the proposed approach in reducing energy consumption and\ncollision avoidance via numerical simulations involving curved roads and\nmultiple obstacles. A detailed analysis of energy consumption along different\ncomponents of EV motion highlights appreciable improvement under the proposed\napproach.\n","authors":["Simran Kumari","Ashish R. Hota","Siddhartha Mukhopadhyay"],"pdf_url":"https://arxiv.org/pdf/2304.12887v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.19454v2","updated":"2025-09-07T13:43:10Z","published":"2025-05-26T03:20:01Z","title":"Direct Pseudospectral Optimal Control by Orthogonal Polynomial Integral\n  Collocation","summary":"  This paper details a methodology to transcribe an optimal control problem\ninto a nonlinear program for generation of the trajectories that optimize a\ngiven functional by approximating only the highest order derivatives of a given\nsystem's dynamics. The underlying method uses orthogonal polynomial integral\ncollocation by which successive integrals are taken to approximate all lower\norder states. Hence, one set of polynomial coefficients can represent an entire\ncoordinate's degree of freedom. Specifically, Chebyshev polynomials of the\nfirst and second kind and Legendre polynomials are used over their associated\ncommon interpolating grids derived from the bases' roots and extrema. Simple\nexample problems compare different polynomial bases' performance to analytical\nsolutions. The planar circular orbit raising problem is used to verify the\nmethod with solutions obtained by other pseudospectral methods in literature.\nFinally, a rocket landing flip maneuver problem is solved to demonstrate the\nability to solve complex problems with multiple states and control variables\nwith constraints. Simulations establish this method's performance, and reveal\nthat the polynomial/node choice for a given problem notably affects the\nperformance.\n","authors":["Thomas L. Ahrens","Ian M. Down","Manoranjan Majji"],"pdf_url":"https://arxiv.org/pdf/2505.19454v2.pdf","comment":"Preprint submitted to the Journal of Guidance, Control, and Dynamics\n  for publication"},{"id":"http://arxiv.org/abs/2506.19277v3","updated":"2025-09-07T08:02:59Z","published":"2025-06-24T03:14:51Z","title":"Ontology Neural Network and ORTSF: A Framework for Topological Reasoning\n  and Delay-Robust Control","summary":"  The advancement of autonomous robotic systems has led to impressive\ncapabilities in perception, localization, mapping, and control. Yet, a\nfundamental gap remains: existing frameworks excel at geometric reasoning and\ndynamic stability but fall short in representing and preserving relational\nsemantics, contextual reasoning, and cognitive transparency essential for\ncollaboration in dynamic, human-centric environments. This paper introduces a\nunified architecture comprising the Ontology Neural Network (ONN) and the\nOntological Real-Time Semantic Fabric (ORTSF) to address this gap. The ONN\nformalizes relational semantic reasoning as a dynamic topological process. By\nembedding Forman-Ricci curvature, persistent homology, and semantic tensor\nstructures within a unified loss formulation, ONN ensures that relational\nintegrity and topological coherence are preserved as scenes evolve over time.\nThe ORTSF transforms reasoning traces into actionable control commands while\ncompensating for system delays. It integrates predictive and delay-aware\noperators that ensure phase margin preservation and continuity of control\nsignals, even under significant latency conditions. Empirical studies\ndemonstrate the ONN + ORTSF framework's ability to unify semantic cognition and\nrobust control, providing a mathematically principled and practically viable\nsolution for cognitive robotics.\n","authors":["Jaehong Oh"],"pdf_url":"https://arxiv.org/pdf/2506.19277v3.pdf","comment":"12 pages, 5 figures, includes theoretical proofs and simulation\n  results"},{"id":"http://arxiv.org/abs/2507.05785v3","updated":"2025-09-07T06:49:32Z","published":"2025-07-08T08:43:29Z","title":"Robust Bandwidth Estimation for Real-Time Communication with Offline\n  Reinforcement Learning","summary":"  Accurate bandwidth estimation (BWE) is critical for real-time communication\n(RTC) systems. Traditional heuristic approaches offer limited adaptability\nunder dynamic networks, while online reinforcement learning (RL) suffers from\nhigh exploration costs and potential service disruptions. Offline RL, which\nleverages high-quality data collected from real-world environments, offers a\npromising alternative. However, challenges such as out-of-distribution (OOD)\nactions, policy extraction from behaviorally diverse datasets, and reliable\ndeployment in production systems remain unsolved. We propose RBWE, a robust\nbandwidth estimation framework based on offline RL that integrates Q-ensemble\n(an ensemble of Q-functions) with a Gaussian mixture policy to mitigate OOD\nrisks and enhance policy learning. A fallback mechanism ensures deployment\nstability by switching to heuristic methods under high uncertainty.\nExperimental results show that RBWE reduces overestimation errors by 18% and\nimproves the 10th percentile Quality of Experience (QoE) by 18.6%,\ndemonstrating its practical effectiveness in real-world RTC applications. The\nimplementation is publicly available at\nhttps://github.com/jiu2021/RBWE_offline.\n","authors":["Jian Kai","Tianwei Zhang","Zihan Ling","Yang Cao","Can Shen"],"pdf_url":"https://arxiv.org/pdf/2507.05785v3.pdf","comment":"Accepted by IEEE GLOBECOM 2025"},{"id":"http://arxiv.org/abs/2509.05935v1","updated":"2025-09-07T05:51:49Z","published":"2025-09-07T05:51:49Z","title":"Certifying the Nonexistence of Feasible Path Between Power System\n  Operating Points","summary":"  By providing the optimal operating point that satisfies both the power flow\nequations and engineering limits, the optimal power flow (OPF) problem is\ncentral to the operation of electric power systems. While extensive research\nefforts have focused on reliably computing high-quality OPF solutions,\nassessing the feasibility of transitioning between operating points remains\nchallenging since the feasible spaces of OPF problems may consist of multiple\ndisconnected components. It is not possible to transition between operating\npoints in different disconnected components without violating OPF constraints.\nTo identify such situations, this paper introduces an algorithm for certifying\nthe infeasibility of transitioning between two operating points within an OPF\nfeasible space. As an indication of potential disconnectedness, the algorithm\nfirst seeks an infeasible point on the line connecting a pair of feasible\npoints. The algorithm then certifies disconnectedness by using convex\nrelaxation and bound tightening techniques to show that all points on the plane\nthat is normal to this line are infeasible. Using this algorithm, we provide\nthe first certifications of disconnected feasible spaces for a variety of OPF\ntest cases.\n","authors":["Mohammad Rasoul Narimani","Katherine R. Davis","Daniel K. Molzahn"],"pdf_url":"https://arxiv.org/pdf/2509.05935v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.05930v1","updated":"2025-09-07T05:22:41Z","published":"2025-09-07T05:22:41Z","title":"Smoothed Online Optimization for Target Tracking: Robust and\n  Learning-Augmented Algorithms","summary":"  We introduce the Smoothed Online Optimization for Target Tracking (SOOTT)\nproblem, a new framework that integrates three key objectives in online\ndecision-making under uncertainty: (1) tracking cost for following a\ndynamically moving target, (2) adversarial perturbation cost for withstanding\nunpredictable disturbances, and (3) switching cost for penalizing abrupt\nchanges in decisions. This formulation captures real-world scenarios such as\nelastic and inelastic workload scheduling in AI clusters, where operators must\nbalance long-term service-level agreements (e.g., LLM training) against sudden\ndemand spikes (e.g., real-time inference). We first present BEST, a robust\nalgorithm with provable competitive guarantees for SOOTT. To enhance practical\nperformance, we introduce CoRT, a learning-augmented variant that incorporates\nuntrusted black-box predictions (e.g., from ML models) into its decision\nprocess. Our theoretical analysis shows that CoRT strictly improves over BEST\nwhen predictions are accurate, while maintaining robustness under arbitrary\nprediction errors. We validate our approach through a case study on workload\nscheduling, demonstrating that both algorithms effectively balance trajectory\ntracking, decision smoothness, and resilience to external disturbances.\n","authors":["Ali Zeynali","Mahsa Sahebdel","Qingsong Liu","Mohammad Hajiesmaili","Ramesh K. Sitaraman"],"pdf_url":"https://arxiv.org/pdf/2509.05930v1.pdf","comment":"10 pages, 14 pages appendix"},{"id":"http://arxiv.org/abs/2208.13687v3","updated":"2025-09-07T04:47:16Z","published":"2022-08-29T15:51:36Z","title":"Categorical semantics of compositional reinforcement learning","summary":"  Compositional knowledge representations in reinforcement learning (RL)\nfacilitate modular, interpretable, and safe task specifications. However,\ngenerating compositional models requires the characterization of minimal\nassumptions for the robustness of the compositionality feature, especially in\nthe case of functional decompositions. Using a categorical point of view, we\ndevelop a knowledge representation framework for a compositional theory of RL.\nOur approach relies on the theoretical study of the category MDP, whose objects\nare Markov decision processes (MDPs) acting as models of tasks. The categorical\nsemantics models the compositionality of tasks through the application of\npushout operations akin to combining puzzle pieces. As a practical application\nof these pushout operations, we introduce zig-zag diagrams that rely on the\ncompositional guarantees engendered by the category MDP. We further prove that\nproperties of the category MDP unify concepts, such as enforcing safety\nrequirements and exploiting symmetries, generalizing previous abstraction\ntheories for RL.\n","authors":["Georgios Bakirtzis","Michail Savvas","Ufuk Topcu"],"pdf_url":"https://arxiv.org/pdf/2208.13687v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.05907v1","updated":"2025-09-07T03:31:48Z","published":"2025-09-07T03:31:48Z","title":"A Dynamic Programming Framework for Vehicular Task Offloading with\n  Successive Action Improvement","summary":"  In this paper, task offloading from vehicles with random velocities is\noptimized via a novel dynamic programming framework. Particularly, in a\nvehicular network with multiple vehicles and base stations (BSs), computing\ntasks of vehicles are offloaded via BSs to an edge server. Due to the random\nvelocities, the exact locations of vehicles versus time, namely trajectories,\ncannot be determined in advance. Hence, instead of deterministic optimization,\nthe cell association, uplink time, and throughput allocation of multiple\nvehicles during a period of task offloading are formulated as a finite-horizon\nMarkov decision process. In order to derive a low-complexity solution\nalgorithm, a two-time-scale framework is proposed. The scheduling period is\ndivided into super slots, each super slot is further divided into a number of\ntime slots. At the beginning of each super slot, we first obtain a reference\nscheduling scheme of cell association, uplink time and throughput allocation\nvia deterministic optimization, yielding an approximation of the optimal value\nfunction. Within the super slot, the actual scheduling action of each time slot\nis determined by making improvement to the approximate value function according\nto the system state. Due to the successive improvement framework, a non-trivial\naverage cost upper bound could be derived. In the simulation, the random\ntrajectories of vehicles are generated from a high-fidelity traffic simulator.\nIt is shown that the performance gain of the proposed scheduling framework over\nthe baselines is significant.\n","authors":["Qianren Li","Yuncong Hong","Bojie Lv","Rui Wang"],"pdf_url":"https://arxiv.org/pdf/2509.05907v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01412v2","updated":"2025-09-07T02:23:05Z","published":"2024-11-03T02:45:50Z","title":"Near-Optimal Emission-Aware Online Ride Assignment Algorithm for Peak\n  Demand Hours","summary":"  Ridesharing has experienced significant global growth over the past decade\nand is becoming an integral component of modern transportation systems.\nHowever, despite their benefits, ridesharing platforms face fundamental\ninefficiencies that contribute to negative environmental impacts. A prominent\nsource of such inefficiency is the deadhead miles. This issue becomes\nespecially severe during high-demand periods, when the volume of ride requests\nexceeds the available driver supply, leading to suboptimal rider-to-driver\nassignments, longer deadhead trips, and increased emissions. Although limiting\nthese unproductive miles can reduce emissions, doing so may increase passenger\nwait times due to limited driver availability, thereby degrading the overall\nservice experience. In this paper, we introduce LARA, an online rider-to-driver\nassignment algorithm that dynamically adjusts the maximum allowable distance\nbetween rider and drivers and assigns ride requests accordingly. While LARA is\napplicable in general settings, it is particularly effective during peak demand\nperiods, achieving reductions in both emissions and wait times. We provide\ntheoretical guarantees showing that LARA achieves near-optimal performance in\nonline environments, with respect to an optimal offline benchmark. Beside our\ntheoretical analysis, our empirical evaluations on both synthetic and\nreal-world datasets show that LARA achieves up to a 34% reduction in carbon\nemissions and up to a 50% decrease in rider wait times, compared to\nstate-of-the-art baselines. While prior work has explored emission-aware ride\nassignment, LARA is, to our knowledge, the first algorithm to offer both\nrigorous theoretical guarantees and strong empirical performance.\n","authors":["Ali Zeynali","Mahsa Sahebdel","Noman Bashir","Ramesh K. Sitaraman","Mohammad Hajiesmaili"],"pdf_url":"https://arxiv.org/pdf/2411.01412v2.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2508.19153v2","updated":"2025-09-07T01:11:35Z","published":"2025-08-26T16:05:32Z","title":"QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End\n  Reinforcement Learning","summary":"  We address vision-guided quadruped motion control with reinforcement learning\n(RL) and highlight the necessity of combining proprioception with vision for\nrobust control. We propose QuadKAN, a spline-parameterized cross-modal policy\ninstantiated with Kolmogorov-Arnold Networks (KANs). The framework incorporates\na spline encoder for proprioception and a spline fusion head for\nproprioception-vision inputs. This structured function class aligns the\nstate-to-action mapping with the piecewise-smooth nature of gait, improving\nsample efficiency, reducing action jitter and energy consumption, and providing\ninterpretable posture-action sensitivities. We adopt Multi-Modal Delay\nRandomization (MMDR) and perform end-to-end training with Proximal Policy\nOptimization (PPO). Evaluations across diverse terrains, including both even\nand uneven surfaces and scenarios with static or dynamic obstacles, demonstrate\nthat QuadKAN achieves consistently higher returns, greater distances, and fewer\ncollisions than state-of-the-art (SOTA) baselines. These results show that\nspline-parameterized policies offer a simple, effective, and interpretable\nalternative for robust vision-guided locomotion. A repository will be made\navailable upon acceptance.\n","authors":["Yinuo Wang","Gavin Tao"],"pdf_url":"https://arxiv.org/pdf/2508.19153v2.pdf","comment":"14pages, 9 figures, Journal paper"}],"Hardware Architecture":[{"id":"http://arxiv.org/abs/2509.06162v1","updated":"2025-09-07T18:09:59Z","published":"2025-09-07T18:09:59Z","title":"An Improved Template for Approximate Computing","summary":"  Deploying neural networks on edge devices entails a careful balance between\nthe energy required for inference and the accuracy of the resulting\nclassification. One technique for navigating this tradeoff is approximate\ncomputing: the process of reducing energy consumption by slightly reducing the\naccuracy of arithmetic operators. In this context, we propose a methodology to\nreduce the area of the small arithmetic operators used in neural networks -\ni.e., adders and multipliers - via a small loss in accuracy, and show that we\nimprove area savings for the same accuracy loss w.r.t. the state of the art. To\nachieve our goal, we improve on a boolean rewriting technique recently\nproposed, called XPAT, where the use of a parametrisable template to rewrite\ncircuits has proved to be highly beneficial. In particular, XPAT was able to\nproduce smaller circuits than comparable approaches while utilising a naive sum\nof products template structure. In this work, we show that template parameters\ncan act as proxies for chosen metrics and we propose a novel template based on\nparametrisable product sharing that acts as a close proxy to synthesised area.\nWe demonstrate experimentally that our methodology converges better to low-area\nsolutions and that it can find better approximations than both the original\nXPAT and two other state-of-the-art approaches.\n","authors":["M. Rezaalipour","F. Costa","M. Biasion","R. Otoni","G. A. Constantinides","L. Pozzi"],"pdf_url":"https://arxiv.org/pdf/2509.06162v1.pdf","comment":"4 pages, 5 figures"},{"id":"http://arxiv.org/abs/2502.12650v2","updated":"2025-09-07T17:30:34Z","published":"2025-02-18T08:54:49Z","title":"Chronus: Understanding and Securing the Cutting-Edge Industry Solutions\n  to DRAM Read Disturbance","summary":"  We 1) present the first rigorous security, performance, energy, and cost\nanalyses of the state-of-the-art on-DRAM-die read disturbance mitigation\nmethod, Per Row Activation Counting (PRAC) and 2) propose Chronus, a new\nmechanism that addresses PRAC's two major weaknesses. Our analysis shows that\nPRAC's system performance overhead on benign applications is non-negligible for\nmodern DRAM chips and prohibitively large for future DRAM chips that are more\nvulnerable to read disturbance. We identify two weaknesses of PRAC that cause\nthese overheads. First, PRAC increases critical DRAM access latency parameters\ndue to the additional time required to increment activation counters. Second,\nPRAC performs a constant number of preventive refreshes at a time, making it\nvulnerable to an adversarial access pattern, known as the wave attack, and\nconsequently requiring it to be configured for significantly smaller activation\nthresholds. To address PRAC's two weaknesses, we propose a new on-DRAM-die\nRowHammer mitigation mechanism, Chronus. Chronus 1) updates row activation\ncounters concurrently while serving accesses by separating counters from the\ndata and 2) prevents the wave attack by dynamically controlling the number of\npreventive refreshes performed. Our performance analysis shows that Chronus's\nsystem performance overhead is near-zero for modern DRAM chips and very low for\nfuture DRAM chips. Chronus outperforms three variants of PRAC and three other\nstate-of-the-art read disturbance solutions. We discuss Chronus's and PRAC's\nimplications for future systems and foreshadow future research directions. To\naid future research, we open-source our Chronus implementation at\nhttps://github.com/CMU-SAFARI/Chronus.\n","authors":["Oğuzhan Canpolat","A. Giray Yağlıkçı","Geraldo F. Oliveira","Ataberk Olgun","Nisa Bostancı","İsmail Emir Yüksel","Haocong Luo","Oğuz Ergin","Onur Mutlu"],"pdf_url":"https://arxiv.org/pdf/2502.12650v2.pdf","comment":"To appear in HPCA'25. arXiv admin note: text overlap with\n  arXiv:2406.19094. Appendix E added that describe the errata and new results"},{"id":"http://arxiv.org/abs/2509.06101v1","updated":"2025-09-07T15:31:52Z","published":"2025-09-07T15:31:52Z","title":"SCREME: A Scalable Framework for Resilient Memory Design","summary":"  The continuing advancement of memory technology has not only fueled a surge\nin performance, but also substantially exacerbate reliability challenges.\nTraditional solutions have primarily focused on improving the efficiency of\nprotection schemes, i.e., Error Correction Codes (ECC), under the assumption\nthat allocating additional memory space for parity data is always expensive and\ntherefore not a scalable solution.\n  We break the stereotype by proposing an orthogonal approach that provides\nadditional, cost-effective memory space for resilient memory design. In\nparticular, we recognize that ECC chips (used for parity storage) do not\nnecessarily require the same performance level as regular data chips. This\noffers two-fold benefits: First, the bandwidth originally provisioned for a\nregular-performance ECC chip can instead be used to accommodate multiple\nlow-performance chips. Second, the cost of ECC chips can be effectively\nreduced, as lower performance often correlates with lower expense. In addition,\nwe observe that server-class memory chips are often provisioned with ample, yet\nunderutilized I/O resources. This further offers the opportunity to repurpose\nthese resources to enable flexible on-DIMM interconnections. Based on the above\ntwo insights, we finally propose SCREME, a scalable memory framework leverages\ncost-effective, albeit slower, chips -- naturally produced during rapid\ntechnology evolution -- to meet the growing reliability demands driven by this\nevolution.\n","authors":["Fan Li","Mimi Xie","Yanan Guo","Huize Li","Xin Xin"],"pdf_url":"https://arxiv.org/pdf/2509.06101v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.05937v1","updated":"2025-09-07T05:56:38Z","published":"2025-09-07T05:56:38Z","title":"Hardware Acceleration of Kolmogorov-Arnold Network (KAN) in Large-Scale\n  Systems","summary":"  Recent developments have introduced Kolmogorov-Arnold Networks (KAN), an\ninnovative architectural paradigm capable of replicating conventional deep\nneural network (DNN) capabilities while utilizing significantly reduced\nparameter counts through the employment of parameterized B-spline functions\nwith trainable coefficients. Nevertheless, the B-spline functional components\ninherent to KAN architectures introduce distinct hardware acceleration\ncomplexities. While B-spline function evaluation can be accomplished through\nlook-up table (LUT) implementations that directly encode functional mappings,\nthus minimizing computational overhead, such approaches continue to demand\nconsiderable circuit infrastructure, including LUTs, multiplexers, decoders,\nand related components. This work presents an algorithm-hardware co-design\napproach for KAN acceleration. At the algorithmic level, techniques include\nAlignment-Symmetry and PowerGap KAN hardware aware quantization, KAN sparsity\naware mapping strategy, and circuit-level techniques include N:1 Time\nModulation Dynamic Voltage input generator with analog-compute-in-memory (ACIM)\ncircuits. This work conducts evaluations on large-scale KAN networks to\nvalidate the proposed methodologies. Non-ideality factors, including partial\nsum deviations from process variations, have been evaluated with statistics\nmeasured from the TSMC 22nm RRAM-ACIM prototype chips. Utilizing optimally\ndetermined KAN hyperparameters in conjunction with circuit optimizations\nfabricated at the 22nm technology node, despite the parameter count for\nlarge-scale tasks in this work increasing by 500Kx to 807Kx compared to\ntiny-scale tasks in previous work, the area overhead increases by only 28Kx to\n41Kx, with power consumption rising by merely 51x to 94x, while accuracy\ndegradation remains minimal at 0.11% to 0.23%, demonstrating the scaling\npotential of our proposed architecture.\n","authors":["Wei-Hsing Huang","Jianwei Jia","Yuyao Kong","Faaiq Waqar","Tai-Hao Wen","Meng-Fan Chang","Shimeng Yu"],"pdf_url":"https://arxiv.org/pdf/2509.05937v1.pdf","comment":null}],"Programming Languages":[{"id":"http://arxiv.org/abs/2506.22370v4","updated":"2025-09-07T11:26:53Z","published":"2025-06-27T16:34:13Z","title":"Can Large Language Models Help Students Prove Software Correctness? An\n  Experimental Study with Dafny","summary":"  Students in computing education increasingly use large language models (LLMs)\nsuch as ChatGPT. Yet, the role of LLMs in supporting cognitively demanding\ntasks, like deductive program verification, remains poorly understood. This\npaper investigates how students interact with an LLM when solving formal\nverification exercises in Dafny, a language that supports functional\ncorrectness, by allowing programmers to write formal specifications and\nautomatically verifying that the implementation satisfies the specification. We\nconducted a mixed-methods study with master's students enrolled in a formal\nmethods course. Each participant completed two verification problems, one with\naccess to a custom ChatGPT interface that logged all interactions, and the\nother without. We identified strategies used by successful students and\nassessed the level of trust students place in LLMs. Our findings show that\nstudents perform significantly better when using ChatGPT; however, performance\ngains are tied to prompt quality. We conclude with practical recommendations\nfor integrating LLMs into formal methods courses more effectively, including\ndesigning LLM-aware challenges that promote learning rather than substitution.\n","authors":["Carolina Carreira","Álvaro Silva","Alexandre Abreu","Alexandra Mendes"],"pdf_url":"https://arxiv.org/pdf/2506.22370v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.23696v2","updated":"2025-09-07T11:10:45Z","published":"2025-06-30T10:17:39Z","title":"What Challenges Do Developers Face When Using Verification-Aware\n  Programming Languages?","summary":"  Software reliability is critical in ensuring that the digital systems we\ndepend on function correctly. In software development, increasing software\nreliability often involves testing. However, for complex and critical systems,\ndevelopers can use Design by Contract (DbC) methods to define precise\nspecifications that software components must satisfy. Verification-Aware (VA)\nprogramming languages support DbC and formal verification at compile-time or\nrun-time, offering stronger correctness guarantees than traditional testing.\nHowever, despite the strong guarantees provided by VA languages, their adoption\nremains limited. In this study, we investigate the barriers to adopting VA\nlanguages by analyzing developer discussions on public forums using topic\nmodeling techniques. We complement this analysis with a developer survey to\nbetter understand the practical challenges associated with VA languages. Our\nfindings reveal key obstacles to adoption, including steep learning curves and\nusability issues. Based on these insights, we identify actionable\nrecommendations to improve the usability and accessibility of VA languages. Our\nfindings suggest that simplifying tool interfaces, providing better educational\nmaterials, and improving integration with everyday development environments\ncould improve the usability and adoption of these languages. Our work provides\nactionable insights for improving the usability of VA languages and making\nverification tools more accessible.\n","authors":["Francisco Oliveira","Alexandra Mendes","Carolina Carreira"],"pdf_url":"https://arxiv.org/pdf/2506.23696v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.00948v2","updated":"2025-09-07T04:40:03Z","published":"2025-08-31T17:57:01Z","title":"Decision Procedure for A Theory of String Sequences","summary":"  The theory of sequences, supported by many SMT solvers, can model program\ndata types including bounded arrays and lists. Sequences are parameterized by\nthe element data type and provide operations such as accessing elements,\nconcatenation, forming sub-sequences and updating elements. Strings and\nsequences are intimately related; many operations, e.g., matching a string\naccording to a regular expression, splitting strings, or joining strings in a\nsequence, are frequently used in string-manipulating programs. Nevertheless,\nthese operations are typically not directly supported by existing SMT solvers,\nwhich instead only consider the generic theory of sequences. In this paper, we\npropose a theory of string sequences and study its satisfiability. We show\nthat, while it is undecidable in general, the decidability can be recovered by\nrestricting to the straight-line fragment. This is shown by encoding each\nstring sequence as a string, and each string sequence operation as a\ncorresponding string operation. We provide pre-image computation for the\nresulting string operations with respect to automata, effectively casting it\ninto the generic OSTRICH string constraint solving framework. We implement the\nnew decision procedure as a tool $\\ostrichseq$, and carry out experiments on\nbenchmark constraints generated from real-world JavaScript programs,\nhand-crafted templates and unit tests. The experiments confirm the efficacy of\nour approach.\n","authors":["Denghang Hu","Taolue Chen","Philipp Rümmer","Fu Song","Zhilin Wu"],"pdf_url":"https://arxiv.org/pdf/2509.00948v2.pdf","comment":"21 pages, 2 tables, APLAS 2025"}],"Data Structures and Algorithms":[{"id":"http://arxiv.org/abs/2509.06209v1","updated":"2025-09-07T21:14:13Z","published":"2025-09-07T21:14:13Z","title":"Efficient Catalytic Graph Algorithms","summary":"  We give fast, simple, and implementable catalytic logspace algorithms for two\nfundamental graph problems.\n  First, a randomized catalytic algorithm for $s\\to t$ connectivity running in\n$\\widetilde{O}(nm)$ time, and a deterministic catalytic algorithm for the same\nrunning in $\\widetilde{O}(n^3 m)$ time. The former algorithm is the first\nalgorithmic use of randomization in $\\mathsf{CL}$. The algorithm uses one\nregister per vertex and repeatedly ``pushes'' values along the edges in the\ngraph.\n  Second, a deterministic catalytic algorithm for simulating random walks which\nin $\\widetilde{O}( m T^2 / \\varepsilon )$ time estimates the probability a\n$T$-step random walk ends at a given vertex within $\\varepsilon$ additive\nerror. The algorithm uses one register for each vertex and increments it at\neach visit to ensure repeated visits follow different outgoing edges.\n  Prior catalytic algorithms for both problems did not have explicit runtime\nbounds beyond being polynomial in $n$.\n","authors":["James Cook","Edward Pyne"],"pdf_url":"https://arxiv.org/pdf/2509.06209v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.17338v2","updated":"2025-09-07T20:22:27Z","published":"2025-04-24T07:56:21Z","title":"Dynamic Approximate Maximum Matching in the Distributed Vertex Partition\n  Model","summary":"  We initiate the study of approximate maximum matching in the vertex partition\nmodel, for graphs subject to dynamic changes. We assume that the $n$ vertices\nof the graph are partitioned among $k$ players, who execute a distributed\nalgorithm and communicate via message passing. An adaptive adversary may\nperform dynamic updates to the graph topology by inserting or removing edges\nbetween the nodes, and the algorithm needs to respond to these changes by\nadapting the output of the players, with the goal of maintaining an approximate\nmaximum matching. The main performance metric in this setting is the\nalgorithm's update time, which corresponds to the number of rounds required for\nupdating the solution upon an adversarial change. For the standard setting of\nsingle-edge insertions and deletions, we obtain the following results:\n  We give a randomized Las Vegas algorithm with an expected update time of $O(\n\\frac{\\sqrt{m}}{\\beta k} )$ rounds that maintains a $\\frac{2}{3}$-approximate\nmaximum matching that is also maximal, where $m$ is the number of edges of the\ngraph. We also show that any algorithm has a worst case update time of $\\Omega(\n\\frac{n}{\\beta k^2\\log n} )$, assuming a link bandwidth of $O(\\beta\\log n)$\nbits per round, if it maintains a matching that is maximal and does not have\nany 3-augmenting paths. For batch-dynamic updates, where the adversary may\nmodify up to $\\ell\\ge 1$ edges at once, we prove the following: There is a\nrandomized algorithm that succeeds with high probability in maintaining a\n$\\frac{2}{3}$-approximate maximum matching and has a worst case update time of\n$\\Omega( \\frac{\\ell\\log n}{\\sqrt{\\beta k}} )$ rounds. We show that $\\Omega(\n\\frac{\\ell}{\\beta k \\log n} )$ poses a lower bound for maintaining a maximal\nmatching without 3-augmenting paths.\n","authors":["Peter Robinson","Xianbin Zhu"],"pdf_url":"https://arxiv.org/pdf/2504.17338v2.pdf","comment":"Revised Version"},{"id":"http://arxiv.org/abs/2509.06194v1","updated":"2025-09-07T20:05:50Z","published":"2025-09-07T20:05:50Z","title":"Degree Realization by Bipartite Cactus Graphs","summary":"  The \\textsc{Degree Realization} problem with respect to a graph family\n$\\mathcal{F}$ is defined as follows. The input is a sequence $d$ of $n$\npositive integers, and the goal is to decide whether there exists a graph $G\n\\in \\mathcal{F}$ whose degrees correspond to $d$. The main challenges are to\nprovide a precise characterization of all the sequences that admit a\nrealization in $\\mathcal{F}$ and to design efficient algorithms that construct\none of the possible realizations, if one exists.\n  This paper studies the problem of realizing degree sequences by bipartite\ncactus graphs (where the input is given as a single sequence, without the\nbi-partition). A characterization of the sequences that have a cactus\nrealization is already known [28]. In this paper, we provide a systematic way\nto obtain such a characterization, accompanied by a realization algorithm. This\nallows us to derive a characterization for bipartite cactus graphs, and as a\nbyproduct, also for several other interesting sub-families of cactus graphs,\nincluding bridge-less cactus graphs and core cactus graphs, as well as for the\nbipartite sub-families of these families.\n","authors":["Amotz Bar-Noy","Toni Bohnlein","David Peleg","Yingli Ran","Dror Rawitz"],"pdf_url":"https://arxiv.org/pdf/2509.06194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.06182v1","updated":"2025-09-07T19:16:16Z","published":"2025-09-07T19:16:16Z","title":"Separable convex optimization over indegree polytopes","summary":"  We study egalitarian (acyclic) orientations of undirected graphs under\nindegree-based objectives, such as minimizing the $\\varphi$-sum of indegrees\nfor a strictly convex function $\\varphi$, decreasing minimization (dec-min),\nand increasing maximization (inc-max). In the non-acyclic setting of Frank and\nMurota (2022), a single orientation simultaneously optimizes these three\nobjectives, however, restricting to acyclic orientations confines us to the\ncorners of the indegree polytope, where these fairness objectives do diverge.\nWe establish strong hardness results across a broad range of settings:\nminimizing the $\\varphi$-sum of indegrees is NP-hard for every discrete\nstrictly convex function $\\varphi$; dec-min and inc-max are NP-hard for every\nindegree bound $k \\geq 2$, as well as without a bound; and the complementary\ninc-min and dec-max problems are NP-hard even on $3$-regular graphs. On the\nalgorithmic side, we give a polynomial-time algorithm for minimizing the\nmaximum weighted indegree via a weighted smallest-last ordering. We also\nprovide an exact exponential-time algorithm for minimizing general separable\ndiscrete convex objectives over indegrees, and a polynomial-time algorithm for\nthe non-acyclic case. Finally, for maximizing the sum of the products of\nindegrees and outdegrees, we prove NP-hardness on graphs of maximum degree $4$,\ngive an algorithm for maximum degree $3$, and provide a $3$-approximation\nalgorithm. Our results delineate the algorithmic frontier of convex integral\noptimization over indegree (base-)polytopes, and highlight both theoretical\nconsequences and practical implications, notably for scheduling and\ndeadlock-free routing.\n","authors":["Nóra A. Borsik","Péter Madarasi"],"pdf_url":"https://arxiv.org/pdf/2509.06182v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.06124v1","updated":"2025-09-07T16:24:06Z","published":"2025-09-07T16:24:06Z","title":"Parameterized Algorithms for Computing Pareto Sets","summary":"  Dynamic programming over tree decompositions is a common technique in\nparameterized algorithms. In this paper, we study whether this technique can\nalso be applied to compute Pareto sets of multiobjective optimization problems.\nWe first derive an algorithm to compute the Pareto set for the multicriteria\ns-t cut problem and show how this result can be applied to a polygon\naggregation problem arising in cartography that has recently been introduced by\nRottmann et al. (GIScience 2021). We also show how to apply these techniques to\nalso compute the Pareto set of the multiobjective minimum spanning tree problem\nand for the multiobjective TSP. The running time of our algorithms is\n$O(f(w)\\cdot\\mathrm{poly}(n,p_{\\text{max}}))$, where $f$ is some function in\nthe treewidth $w$, $n$ is the input size, and $p_{\\text{max}}$ is an upper\nbound on the size of the Pareto sets of the subproblems that occur in the\ndynamic program. Finally, we present an experimental evaluation of computing\nPareto sets on real-world instances of polygon aggregation problems. For this\nmatter we devised a task-specific data structure that allows for efficient\nstorage and modification of large sets of Pareto-optimal solutions. Throughout\nthe implementation process, we incorporated several improved strategies and\nheuristics that significantly reduced both runtime and memory usage, enabling\nus to solve instances with treewidth of up to 22 within reasonable amount of\ntime. Moreover, we conducted a preprocessing study to compare different tree\ndecompositions in terms of their estimated overall runtime.\n","authors":["Joshua Könen","Heiko Röglin","Tarek Stuck"],"pdf_url":"https://arxiv.org/pdf/2509.06124v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.19365v2","updated":"2025-09-07T15:33:46Z","published":"2024-11-28T20:36:16Z","title":"Strong Linearizability without Compare&Swap: The Case of Bags","summary":"  Because strongly-linearizable objects provide stronger guarantees than\nlinearizability, they serve as valuable building blocks for the design of\nconcurrent data structures. Yet, many objects that have linearizable\nimplementations from base objects weaker than compare&swap objects do not have\nstrongly-linearizable implementations from the same base objects. We focus on\none such object: the bag, a multiset from which processes can take unspecified\nelements.\n  We present the first lock-free, strongly-linearizable implementation of a bag\nfrom interfering objects (specifically, registers, and test&set objects). This\nmay be surprising, since there are provably no such implementations of stacks\nor queues.\n  Since a bag can contain arbitrarily many elements, an unbounded amount of\nspace must be used to implement it. Hence, it makes sense to also consider a\nbag with a bound on its capacity. However, like stacks and queues, a bag with\ncapacity $b$ shared by more than $2b$ processes has no lock-free,\nstrongly-linearizable implementation from interfering objects. If we further\nrestrict a bounded bag so that only one process can insert into it, we are able\nto obtain a lock-free, strongly-linearizable implementation from $O(b + n)$\ninterfering objects, where $n$ is the number of processes.\n  Our goal is to understand the circumstances under which strongly-linearizable\nimplementations of bags exist and, more generally, to understand the power of\ninterfering objects.\n","authors":["Faith Ellen","Gal Sela"],"pdf_url":"https://arxiv.org/pdf/2411.19365v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.06091v1","updated":"2025-09-07T15:14:51Z","published":"2025-09-07T15:14:51Z","title":"Generalized Graph Packing Problems Parameterized by Treewidth","summary":"  $H$-Packing is the problem of finding a maximum number of vertex-disjoint\ncopies of $H$ in a given graph $G$. $H$-Partition is the special case of\nfinding a set of vertex-disjoint copies that cover each vertex of $G$ exactly\nonce. Our goal is to study these problems and some generalizations on\nbounded-treewidth graphs. The case of $H$ being a triangle is well understood:\ngiven a tree decomposition of $G$ having treewidth $tw$, the $K_3$-Packing\nproblem can be solved in time $2^{tw} \\cdot n^{O(1)}$, while Lokshtanov et\nal.~[{\\it ACM Transactions on Algorithms} 2018] showed, under the Strong\nExponential-Time Hypothesis (SETH), that there is no $(2-\\epsilon)^{tw}\\cdot\nn^{O(1)}$ algorithm for any $\\epsilon>0$ even for $K_3$-Partition. Similar\nresults can be obtained for any other clique $K_d$ for $d\\ge 3$. We provide\ngeneralizations in two directions:\n  - We consider a generalization of the problem where every vertex can be used\nat most $c$ times for some $c\\ge 1$. When $H$ is any clique $K_d$ with $d\\ge\n3$, then we give upper and lower bounds showing that the optimal running time\nincreases to $(c+1)^{tw}\\cdot n^{O(1)}$. We consider two variants depending on\nwhether a copy of $H$ can be used multiple times in the packing.\n  - If $H$ is not a clique, then the dependence of the running time on\ntreewidth may not be even single exponential. Specifically, we show that if $H$\nis any fixed graph where not every 2-connected component is a clique, then\nthere is no $2^{o({tw}\\log {tw})}\\cdot n^{O(1)}$ algorithm for\n\\textsc{$H$-Partition}, assuming the Exponential-Time Hypothesis (ETH).\n","authors":["Barış Can Esmer","Dániel Marx"],"pdf_url":"https://arxiv.org/pdf/2509.06091v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10158v4","updated":"2025-09-07T14:07:45Z","published":"2025-03-13T08:36:00Z","title":"Solving Modular Linear Systems with a Constraint by parallel\n  decomposition of the Smith form and extended Euclidean division modulo powers\n  of primes divisors","summary":"  Integral linear systems $Ax=b$ with matrices $A$, $b$ and solutions $x$ are\nalso required to be in integers, can be solved using invariant factors of $A$\n(by computing the Smith Canonical Form of $A$). This paper explores a new\nproblem which arises in applications, that of obtaining conditions for solving\nthe Modular Linear System $Ax=b\\rem n$ given $A,b$ in $\\zz_n$ for $x$ in\n$\\zz_n$ along with the constraint that the value of the linear function\n$\\phi(x)=\\la w,x\\ra$ is coprime to $n$ for some solution $x$. In this paper we\ndevelop decomposition of the system to coprime moduli $p^{r(p)}$ which are\ndivisors of $n$ and show how such a decomposition simplifies the computation of\nSmith form. This extends the well known index calculus method of computing the\ndiscrete logarithm where the moduli over which the linear system is reduced\nwere assumed to be prime (to solve the reduced systems over prime fields) to\nthe case when the factors of the modulus are prime powers $p^{r(p)}$. It is\nshown how this problem can be addressed effciently using the invariant factors\nand Smith form of the augmented matrix $[A,-p^{r(p)}I]$ and conditions modulo\n$p$ satisfied by $w$, where $p^{r(p)}$ vary over all divisors of $n$ with $p$\nprime.\n","authors":["Virendra Sule"],"pdf_url":"https://arxiv.org/pdf/2503.10158v4.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2509.06046v1","updated":"2025-09-07T13:13:02Z","published":"2025-09-07T13:13:02Z","title":"DISTRIBUTEDANN: Efficient Scaling of a Single DISKANN Graph Across\n  Thousands of Computers","summary":"  We present DISTRIBUTEDANN, a distributed vector search service that makes it\npossible to search over a single 50 billion vector graph index spread across\nover a thousand machines that offers 26ms median query latency and processes\nover 100,000 queries per second. This is 6x more efficient than existing\npartitioning and routing strategies that route the vector query to a subset of\npartitions in a scale out vector search system. DISTRIBUTEDANN is built using\ntwo well-understood components: a distributed key-value store and an in-memory\nANN index. DISTRIBUTEDANN has replaced conventional scale-out architectures for\nserving the Bing search engine, and we share our experience from making this\ntransition.\n","authors":["Philip Adams","Menghao Li","Shi Zhang","Li Tan","Qi Chen","Mingqin Li","Zengzhong Li","Knut Risvik","Harsha Vardhan Simhadri"],"pdf_url":"https://arxiv.org/pdf/2509.06046v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.19216v3","updated":"2025-09-07T13:09:43Z","published":"2025-05-25T16:23:44Z","title":"Grassroots Consensus","summary":"  Consider people with smartphones operating without external authorities or\nglobal resources other than the network itself. In this setting, high-end\napplications supporting sovereign democratic digital communities, community\nbanks, and digital cooperatives require consensus executed by community\nmembers, which must be reconfigurable to support community dynamics.\n  The Constitutional Consensus protocol aims to address this need by\nintroducing constitutional self-governance to consensus: participants\ndynamically amend the participant set, supermajority threshold, and timeout\nparameter through the consensus protocol itself. We achieve this by enhancing a\nDAG-based protocol (like Cordial Miners) with participant-controlled\nreconfiguration, while also supporting both high- and low-throughput operation\n(like Morpheus), remaining quiescent when idle. This three-way synthesis\nuniquely combines: (1) constitutional amendments for self-governance, (2) a\ncryptographic DAG structure for simplicity, parallelism, and throughput, and\n(3) both high- and low-throughput operation. The protocol achieves consensus in\n$3\\delta$, maintains O(n) amortized communication complexity during high\nthroughput, and seamlessly transitions between modes. The basic protocol\n(without constitutional amendments) realizes these features in 25 lines of\npseudocode, making it one of the most concise consensus protocols for eventual\nsynchrony.\n","authors":["Idit Keidar","Andrew Lewis-Pye","Ehud Shapiro"],"pdf_url":"https://arxiv.org/pdf/2505.19216v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.04264v2","updated":"2025-09-07T07:46:40Z","published":"2023-08-08T14:00:58Z","title":"Distance Estimation for High-Dimensional Discrete Distributions","summary":"  Given two distributions $\\mathcal{P}$ and $\\mathcal{Q}$ over a\nhigh-dimensional domain $\\{0,1\\}^n$, and a parameter $\\varepsilon$, the goal of\ndistance estimation is to determine the statistical distance between\n$\\mathcal{P}$ and $\\mathcal{Q}$, up to an additive tolerance $\\pm \\varepsilon$.\nSince exponential lower bounds (in $n$) are known for the problem in the\nstandard sampling model, research has focused on richer query models where one\ncan draw conditional samples. This paper presents the first polynomial query\ndistance estimator in the conditional sampling model ($\\mathsf{COND}$).\n  We base our algorithm on the relatively weaker \\textit{subcube conditional}\nsampling ($\\mathsf{SUBCOND}$) oracle, which draws samples from the distribution\nconditioned on some of the dimensions. $\\mathsf{SUBCOND}$ is a promising model\nfor widespread practical use because it captures the natural behavior of\ndiscrete samplers. Our algorithm makes $\\tilde{\\mathcal{O}}(n^3/\\varepsilon^5)$\nqueries to $\\mathsf{SUBCOND}$.\n","authors":["Gunjan Kumar","Kuldeep S. Meel","Yash Pote"],"pdf_url":"https://arxiv.org/pdf/2308.04264v2.pdf","comment":"This work appears at AISTATS 2025"},{"id":"http://arxiv.org/abs/2509.05871v1","updated":"2025-09-07T00:00:35Z","published":"2025-09-07T00:00:35Z","title":"A General Framework for Low Soundness Homomorphism Testing","summary":"  We introduce a general framework to design and analyze algorithms for the\nproblem of testing homomorphisms between finite groups in the low-soundness\nregime.\n  In this regime, we give the first constant-query tests for various families\nof groups. These include tests for: (i) homomorphisms between arbitrary cyclic\ngroups, (ii) homomorphisms between any finite group and $\\mathbb{Z}_p$, (iii)\nautomorphisms of dihedral and symmetric groups, (iv) inner automorphisms of\nnon-abelian finite simple groups and extraspecial groups, and (v) testing\nlinear characters of $\\mathrm{GL}_n(\\mathbb{F}_q)$, and finite-dimensional Lie\nalgebras over $\\mathbb{F}_q$. We also recover the result of Kiwi [TCS'03] for\ntesting homomorphisms between $\\mathbb{F}_q^n$ and $\\mathbb{F}_q$.\n  Prior to this work, such tests were only known for abelian groups with a\nconstant maximal order (such as $\\mathbb{F}_q^n$). No tests were known for\nnon-abelian groups.\n  As an additional corollary, our framework gives combinatorial list decoding\nbounds for cyclic groups with list size dependence of $O(\\varepsilon^{-2})$\n(for agreement parameter $\\varepsilon$). This improves upon the currently\nbest-known bound of $O(\\varepsilon^{-105})$ due to Dinur, Grigorescu, Kopparty,\nand Sudan [STOC'08], and Guo and Sudan [RANDOM'14].\n","authors":["Tushant Mittal","Sourya Roy"],"pdf_url":"https://arxiv.org/pdf/2509.05871v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.11487v7","updated":"2025-09-07T22:21:25Z","published":"2021-12-21T19:05:40Z","title":"On the Parallel Complexity of Group Isomorphism via Weisfeiler-Leman","summary":"  In this paper, we show that the constant-dimensional Weisfeiler-Leman\nalgorithm for groups (Brachter & Schweitzer, LICS 2020) can be fruitfully used\nto improve parallel complexity upper bounds on isomorphism testing for several\nfamilies of groups. In particular, we show:\n  - Groups with an Abelian normal Hall subgroup whose complement is\n$O(1)$-generated are identified by constant-dimensional Weisfeiler-Leman using\nonly a constant number of rounds. This places isomorphism testing for this\nfamily of groups into $\\textsf{L}$; the previous upper bound for isomorphism\ntesting was $\\textsf{P}$ (Qiao, Sarma, & Tang, STACS 2011).\n  - We use the individualize-and-refine paradigm to obtain an isomorphism test\nfor groups without Abelian normal subgroups by $\\textsf{SAC}$ circuits of depth\n$O(\\log n)$ and size $n^{O(\\log \\log n)}$, previously only known to be in\n$\\textsf{P}$ (Babai, Codenotti, \\& Qiao, ICALP 2012) and $\\mathsf{quasiSAC}^1$\n(Chattopadhyay, Tor\\'an, \\& Wagner, ACM Trans. Comput. Theory, 2013).\n  - We extend a result of Brachter \\& Schweitzer (ESA, 2022) on direct products\nof groups to the parallel setting. Namely, we also show that Weisfeiler--Leman\ncan identify direct products in parallel, provided it can identify each of the\nindecomposable direct factors in parallel. They previously showed the analogous\nresult for $\\textsf{P}$.\n  We finally consider the count-free Weisfeiler--Leman algorithm, where we show\nthat count-free WL is unable to even distinguish Abelian groups in\npolynomial-time. Nonetheless, we use count-free WL in tandem with bounded\nnon-determinism and limited counting to obtain a new upper bound of\n$\\beta_{1}\\textsf{MAC}^{0}(\\textsf{FOLL})$ for isomorphism testing of Abelian\ngroups. This improves upon the previous $\\textsf{TC}^{0}(\\textsf{FOLL})$ upper\nbound due to Chattopadhyay, Tor\\'an, \\& Wagner (ibid.).\n","authors":["Joshua A. Grochow","Michael Levet"],"pdf_url":"https://arxiv.org/pdf/2112.11487v7.pdf","comment":"A preliminary version appeared in the proceedings of FCT23. The final\n  journal version has been accepted to the Journal of Computer and System\n  Sciences"}],"Graphics":[{"id":"http://arxiv.org/abs/2509.06167v1","updated":"2025-09-07T18:37:04Z","published":"2025-09-07T18:37:04Z","title":"Exploring Urban Factors with Autoencoders: Relationship Between Static\n  and Dynamic Features","summary":"  Urban analytics utilizes extensive datasets with diverse urban information to\nsimulate, predict trends, and uncover complex patterns within cities. While\nthese data enables advanced analysis, it also presents challenges due to its\ngranularity, heterogeneity, and multimodality. To address these challenges,\nvisual analytics tools have been developed to support the exploration of latent\nrepresentations of fused heterogeneous and multimodal data, discretized at a\nstreet-level of detail. However, visualization-assisted tools seldom explore\nthe extent to which fused data can offer deeper insights than examining each\ndata source independently within an integrated visualization framework. In this\nwork, we developed a visualization-assisted framework to analyze whether fused\nlatent data representations are more effective than separate representations in\nuncovering patterns from dynamic and static urban data. The analysis reveals\nthat combined latent representations produce more structured patterns, while\nseparate ones are useful in particular cases.\n","authors":["Ximena Pocco","Waqar Hassan","Karelia Salinas","Vladimir Molchanov","Luis G. Nonato"],"pdf_url":"https://arxiv.org/pdf/2509.06167v1.pdf","comment":null}]},"2025-09-06T00:00:00Z":{"Systems and Control":[{"id":"http://arxiv.org/abs/2412.11215v3","updated":"2025-09-06T23:13:49Z","published":"2024-12-15T15:13:11Z","title":"Neural Port-Hamiltonian Differential Algebraic Equations for\n  Compositional Learning of Electrical Networks","summary":"  We develop compositional learning algorithms for coupled dynamical systems,\nwith a particular focus on electrical networks. While deep learning has proven\neffective at modeling complex relationships from data, compositional couplings\nbetween system components typically introduce algebraic constraints on state\nvariables, posing challenges to many existing data-driven approaches to\nmodeling dynamical systems. Towards developing deep learning models for\nconstrained dynamical systems, we introduce neural port-Hamiltonian\ndifferential algebraic equations (N-PHDAEs), which use neural networks to\nparameterize unknown terms in both the differential and algebraic components of\na port-Hamiltonian DAE. To train these models, we propose an algorithm that\nuses automatic differentiation to perform index reduction, automatically\ntransforming the neural DAE into an equivalent system of neural ordinary\ndifferential equations (N-ODEs), for which established model inference and\nbackpropagation methods exist. Experiments simulating the dynamics of nonlinear\ncircuits exemplify the benefits of our approach: the proposed N-PHDAE model\nachieves an order of magnitude improvement in prediction accuracy and\nconstraint satisfaction when compared to a baseline N-ODE over long prediction\ntime horizons. We also validate the compositional capabilities of our approach\nthrough experiments on a simulated DC microgrid: we train individual N-PHDAE\nmodels for separate grid components, before coupling them to accurately predict\nthe behavior of larger-scale networks.\n","authors":["Cyrus Neary","Nathan Tsao","Ufuk Topcu"],"pdf_url":"https://arxiv.org/pdf/2412.11215v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.05858v1","updated":"2025-09-06T22:53:54Z","published":"2025-09-06T22:53:54Z","title":"Genesis: A Spiking Neuromorphic Accelerator With On-chip Continual\n  Learning","summary":"  Continual learning, the ability to acquire and transfer knowledge through a\nmodels lifetime, is critical for artificial agents that interact in real-world\nenvironments. Biological brains inherently demonstrate these capabilities while\noperating within limited energy and resource budgets. Achieving continual\nlearning capability in artificial systems considerably increases memory and\ncomputational demands, and even more so when deploying on platforms with\nlimited resources. In this work, Genesis, a spiking continual learning\naccelerator, is proposed to address this gap. The architecture supports\nneurally inspired mechanisms, such as activity-dependent metaplasticity, to\nalleviate catastrophic forgetting. It integrates low-precision continual\nlearning parametersand employs a custom data movement strategy to accommodate\nthe sparsely distributed spikes. Furthermore, the architecture features a\nmemory mapping technique that places metaplasticity parameters and synaptic\nweights in a single address location for faster memory access. Results show\nthat the mean classification accuracy for Genesis is 74.6% on a task-agnostic\nsplit-MNIST benchmark with power consumption of 17.08mW in a 65nm technology\nnode.\n","authors":["Vedant Karia","Abdullah Zyarah","Dhireesha Kudithipudi"],"pdf_url":"https://arxiv.org/pdf/2509.05858v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.05853v1","updated":"2025-09-06T22:33:52Z","published":"2025-09-06T22:33:52Z","title":"Real-Time Single-Iteration Model Predictive Control for Wave Energy\n  Converters","summary":"  This paper proposes a novel real-time algorithm for controlling wave energy\nconverters (WECs). We begin with the economic model predictive control (MPC)\nproblem formulation and apply a novel, first-order optimization algorithm\ninspired by recently developed control-based algorithms for constrained\noptimization to define the controller dynamics according to the\nsingle-iteration MPC approach. We theoretically analyse the convergence of the\nemployed algorithm and the computational complexity of the obtained controller.\nResults from simulations using a benchmark WEC system indicate that the\nproposed approach significantly outperforms standard MPC, thanks to the\ninherent ability to handle faster sampling rates.\n","authors":["Simone Pirrera","Nicolas Faedo","Sophie M. Fosson","Diego Regruto"],"pdf_url":"https://arxiv.org/pdf/2509.05853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.01694v2","updated":"2025-09-06T21:19:41Z","published":"2025-09-01T18:08:33Z","title":"A QoS Framework for Service Provision in Multi-Infrastructure-Sharing\n  Networks","summary":"  We propose a framework for resource provisioning with QoS guarantees in\nshared infrastructure networks. Our novel framework provides tunable\nprobabilistic service guarantees for throughput and delay. Key to our approach\nis a Modified Dirft-plus-Penalty (MDP) policy that ensures long-term stability\nwhile capturing short-term probabilistic service guarantees using linearized\nupper-confidence bounds. We characterize the feasible region of service\nguarantees and show that our MDP procedure achieves mean rate stability and an\noptimality gap that vanishes with the frame size over which service guarantees\nare provided. Finally, empirical simulations validate our theory and\ndemonstrate the favorable performance of our algorithm in handling QoS in\nmulti-infrastructure networks.\n","authors":["Quang Minh Nguyen","Eytan Modiano"],"pdf_url":"https://arxiv.org/pdf/2509.01694v2.pdf","comment":"Accepted to ACM MobiHoc '25"},{"id":"http://arxiv.org/abs/2509.04288v2","updated":"2025-09-06T20:36:57Z","published":"2025-09-04T15:01:03Z","title":"Reinforcement Learning for Robust Ageing-Aware Control of Li-ion Battery\n  Systems with Data-Driven Formal Verification","summary":"  Rechargeable lithium-ion (Li-ion) batteries are a ubiquitous element of\nmodern technology. In the last decades, the production and design of such\nbatteries and their adjacent embedded charging and safety protocols, denoted by\nBattery Management Systems (BMS), has taken central stage. A fundamental\nchallenge to be addressed is the trade-off between the speed of charging and\nthe ageing behavior, resulting in the loss of capacity in the battery cell. We\nrely on a high-fidelity physics-based battery model and propose an approach to\ndata-driven charging and safety protocol design. Following a\nCounterexample-Guided Inductive Synthesis scheme, we combine Reinforcement\nLearning (RL) with recent developments in data-driven formal methods to obtain\na hybrid control strategy: RL is used to synthesise the individual controllers,\nand a data-driven abstraction guides their partitioning into a switched\nstructure, depending on the initial output measurements of the battery. The\nresulting discrete selection among RL-based controllers, coupled with the\ncontinuous battery dynamics, realises a hybrid system. When a design meets the\ndesired criteria, the abstraction provides probabilistic guarantees on the\nclosed-loop performance of the cell.\n","authors":["Rudi Coppola","Hovsep Touloujian","Pierfrancesco Ombrini","Manuel Mazo Jr"],"pdf_url":"https://arxiv.org/pdf/2509.04288v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.05808v1","updated":"2025-09-06T18:55:03Z","published":"2025-09-06T18:55:03Z","title":"Hierarchical Decision-Making in Population Games","summary":"  This paper introduces a hierarchical framework for population games, where\nindividuals delegate decision-making to proxies that act within their own\nstrategic interests. This framework extends classical population games, where\nindividuals are assumed to make decisions directly, to capture various\nreal-world scenarios involving multiple decision layers. We establish\nequilibrium properties and provide convergence results for the proposed\nhierarchical structure. Additionally, based on these results, we develop a\nsystematic approach to analyze population games with general convex\nconstraints, without requiring individuals to have full knowledge of the\nconstraints as in existing methods. We present a navigation application with\ncapacity constraints as a case study.\n","authors":["Yu-Wen Chen","Nuno C. Martins","Murat Arcak"],"pdf_url":"https://arxiv.org/pdf/2509.05808v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.03190v2","updated":"2025-09-06T16:51:09Z","published":"2025-04-04T05:38:00Z","title":"The Ground Cost for Optimal Transport of Angular Velocity","summary":"  We revisit the optimal transport problem over angular velocity dynamics given\nby the controlled Euler equation. The solution of this problem enables\nstochastic guidance of spin states of a rigid body (e.g., spacecraft) over a\nhard deadline constraint by transferring a given initial state statistics to a\ndesired terminal state statistics. This is an instance of generalized optimal\ntransport over a nonlinear dynamical system. While prior work has reported\nexistence-uniqueness and numerical solution of this dynamical optimal transport\nproblem, here we present structural results about the equivalent Kantorovich\na.k.a. optimal coupling formulation. Specifically, we focus on deriving the\nground cost for the associated Kantorovich optimal coupling formulation. The\nground cost is equal to the cost of transporting unit amount of mass from a\nspecific realization of the initial or source joint probability measure to a\nrealization of the terminal or target joint probability measure, and determines\nthe Kantorovich formulation. Finding the ground cost leads to solving a\nstructured deterministic nonlinear optimal control problem, which is shown to\nbe amenable to an analysis technique pioneered by Athans et al. We show that\nsuch techniques have broader applicability in determining the ground cost (thus\nKantorovich formulation) for a class of generalized optimal mass transport\nproblems involving nonlinear dynamics with translated norm-invariant drift.\n","authors":["Karthik Elamvazhuthi","Abhishek Halder"],"pdf_url":"https://arxiv.org/pdf/2504.03190v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.13315v2","updated":"2025-09-06T16:21:13Z","published":"2025-04-17T20:02:40Z","title":"Stability of Polling Systems for a Large Class of Markovian Switching\n  Policies","summary":"  We consider a polling system with two queues, where a single server is\nattending the queues in a cyclic order and requires non-zero switching times to\nswitch between the queues. Our aim is to identify a fairly general and\ncomprehensive class of Markovian switching policies that renders the system\nstable. Potentially a class of policies that can cover the Pareto frontier\nrelated to individual-queue-centric performance measures like the stationary\nexpected number of waiting customers in each queue; for instance, such a class\nof policies is identified recently for a polling system near the fluid regime\n(with large arrival and departure rates), and we aim to include that class. We\nalso aim to include a second class that facilitates switching between the\nqueues at the instance the occupancy in the opposite queue crosses a threshold\nand when that in the visiting queue is below a threshold (this inclusion\nfacilitates design of `robust' polling systems). Towards this, we consider a\nclass of two-phase switching policies, which includes the above mentioned\nclasses. In the maximum generality, our policies can be represented by eight\nparameters, while two parameters are sufficient to represent the aforementioned\nclasses. We provide simple conditions to identify the sub-class of switching\npolicies that ensure system stability. By numerically tuning the parameters of\nthe proposed class, we illustrate that the proposed class can cover the Pareto\nfrontier for the stationary expected number of customers in the two queues.\n","authors":["Konstantin Avrachenkov","Kousik Das","Veeraruna Kavitha","Vartika Singh"],"pdf_url":"https://arxiv.org/pdf/2504.13315v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.00501v2","updated":"2025-09-06T15:36:58Z","published":"2024-08-31T16:49:03Z","title":"\"Iridescent\" Reflective Tags to Enable Radar-based Orientation\n  Estimation","summary":"  Accurate orientation estimation of objects can aid in scene understanding in\nmany applications. In this paper, we consider use cases where passive tags\ncould be deployed to assist radar systems in estimating object orientation.\nTowards that end, we propose the concept of passive iridescent reflective tags\nthat selectively reflect different wavelengths in different directions. We\npropose a conceptual tag design based on leaky-wave antennas. We develop a\nframework for signal modeling and orientation estimation with a multi-tone\nradar. We analyze the impact of imperfect tag location information, revealing\nthat it minimally impacts orientation estimation accuracy. To reduce estimator\ncomplexity, we propose a radiation pointing angle-based estimator with\nnear-optimal performance. We derive its feasible orientation estimation region\nand show that it depends mainly on the system bandwidth. Monte Carlo\nsimulations validate our analytical results while evincing that the\nlow-complexity estimator achieves near-optimal accuracy and that its feasible\norientation estimation region closely matches that of the other estimators.\nFinally, we show that the optimal number of tones increases with the sensing\ntime under a power budget constraint, multipath effects may be negligible,\nsignal-to-noise ratio gains rise with the number of tones, and many radar\nantennas can hurt estimation performance when the signal contains very few\ntones.\n","authors":["Onel L. A. López","Zhu Han","Ashutosh Sabharwal"],"pdf_url":"https://arxiv.org/pdf/2409.00501v2.pdf","comment":"15 pages, 2 tables, 11 figs. Accepted as IEEE JSAC"},{"id":"http://arxiv.org/abs/2404.16376v3","updated":"2025-09-06T13:20:44Z","published":"2024-04-25T07:31:42Z","title":"A Hypergraph Approach to Distributed Broadcast","summary":"  This paper explores the distributed broadcast problem within the context of\nnetwork communications, a critical challenge in decentralized information\ndissemination. We put forth a novel hypergraph-based approach to address this\nissue, focusing on minimizing the number of broadcasts to ensure comprehensive\ndata sharing among all network users. The key contributions of this work\ninclude the establishment of a general lower bound for the problem using the\nmin-cut capacity of hypergraphs, and a distributed broadcast for quasi-trees\n(DBQT) algorithm tailored for the unique structure of quasi-trees, which is\nproven to be optimal. This paper advances both network communication strategies\nand hypergraph theory, with implications for a wide range of real-world\napplications, from vehicular and sensor networks to distributed storage\nsystems.\n","authors":["Qi Cao","Yulin Shao","Fan Yang","Octavia A. Dobre"],"pdf_url":"https://arxiv.org/pdf/2404.16376v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.23242v2","updated":"2025-09-06T12:36:42Z","published":"2025-06-29T14:04:18Z","title":"Revisiting Z Transform Laplace Inversion: To Correct flaws in Signal and\n  System Theory","summary":"  This paper revisits the classical formulation of the Z-transform and its\nrelationship to the inverse Laplace transform (L-1), originally developed by\nRagazzini in sampled-data theory. It identifies a longstanding mathematical\noversight in standard derivations, which typically neglect the contribution\nfrom the infinite arc in the complex plane during inverse Laplace evaluation.\nThis omission leads to inconsistencies, especially at discontinuities such as t\n= 0. By incorporating the full Bromwich contour, including all boundary\ncontributions, we restore internal consistency between L-1 and the Z-transform,\naligning the corrected L-1 with results from Discrete-Time Fourier Transform\n(DTFT) aliasing theory. Consequently, this necessitates a structural revision\nof the Z-transform, inverse Laplace transform, and the behavior of the\nHeaviside step function at discontinuities, providing a more accurate\nfoundation for modeling and analysis of sampled-data systems.\n","authors":["Yuxin Yang","Hang Zhou","Chaojie Li","Xin Li","Yingyi Yan","Mingyang Zheng"],"pdf_url":"https://arxiv.org/pdf/2506.23242v2.pdf","comment":"This work is to be submitted to IEEE transactions on automatic\n  control This is revision2 of the manuscript"},{"id":"http://arxiv.org/abs/2503.24151v2","updated":"2025-09-06T09:01:57Z","published":"2025-03-31T14:36:25Z","title":"Robust Feedback Optimization with Model Uncertainty: A Regularization\n  Approach","summary":"  Feedback optimization optimizes the steady state of a dynamical system by\nimplementing optimization iterations in closed loop with the plant. It relies\non online measurements and limited model information, namely, the input-output\nsensitivity. In practice, various issues including inaccurate modeling, lack of\nobservation, or changing conditions can lead to sensitivity mismatches, causing\nclosed-loop sub-optimality or even instability. To handle such uncertainties,\nwe pursue robust feedback optimization, where we optimize the closed-loop\nperformance against all possible sensitivities lying in specific uncertainty\nsets. We provide tractable reformulations for the corresponding min-max\nproblems via regularizations and characterize the online closed-loop\nperformance through the tracking error in case of time-varying optimal\nsolutions. Simulations on a distribution grid illustrate the effectiveness of\nour robust feedback optimization controller in addressing sensitivity\nmismatches in a non-stationary environment.\n","authors":["Winnie Chan","Zhiyu He","Keith Moffat","Saverio Bolognani","Michael Muehlebach","Florian Dörfler"],"pdf_url":"https://arxiv.org/pdf/2503.24151v2.pdf","comment":"Proc. 64th IEEE Conference on Decision and Control"},{"id":"http://arxiv.org/abs/2504.20653v2","updated":"2025-09-06T05:59:43Z","published":"2025-04-29T11:22:06Z","title":"ComplexVCoder: An LLM-Driven Framework for Systematic Generation of\n  Complex Verilog Code","summary":"  Recent advances have demonstrated the promising capabilities of large\nlanguage models (LLMs) in generating register-transfer level (RTL) code, such\nas Verilog. However, existing LLM-based frameworks still face significant\nchallenges in accurately handling the complexity of real-world RTL designs,\nparticularly those that are large-scale and involve multi-level module\ninstantiations. To address this issue, we present ComplexVCoder, an open-source\nLLM-driven framework that enhances both the generation quality and efficiency\nof complex Verilog code. Specifically, we introduce a two-stage generation\nmechanism, which leverages an intermediate representation to enable a more\naccurate and structured transition from natural language descriptions to\nintricate Verilog designs. In addition, we introduce a rule-based alignment\nmethod and a domain-specific retrieval-augmented generation (RAG) to further\nimprove the correctness of the synthesized code by incorporating relevant\ndesign knowledge during generation. To evaluate our approach, we construct a\ncomprehensive dataset comprising 55 complex Verilog designs derived from\nreal-world implementations. We also release an open-source benchmark suite for\nsystematically assessing the quality of auto-generated RTL code together with\nthe ComplexVCoder framework. Experimental results show that ComplexVCoder\noutperforms SOTA frameworks such as CodeV and RTLCoder by 14.6% and 22.2%,\nrespectively, in terms of function correctness on complex Verilog benchmarks.\nFurthermore, ComplexVcoder achieves comparable generation performances in terms\nof functionality correctness using a lightweight 32B model (Qwen2.5), rivaling\nlarger-scale models such as GPT-3.5 and DeepSeek-V3.\n","authors":["Jian Zuo","Junzhe Liu","Xianyong Wang","Yicheng Liu","Navya Goli","Tong Xu","Hao Zhang","Umamaheswara Rao Tida","Zhenge Jia","Mengying Zhao"],"pdf_url":"https://arxiv.org/pdf/2504.20653v2.pdf","comment":"Withdrawn due to an error in the experimental setup that affected the\n  results. A corrected version is in progress"},{"id":"http://arxiv.org/abs/2509.05581v1","updated":"2025-09-06T03:52:10Z","published":"2025-09-06T03:52:10Z","title":"Learning to Walk in Costume: Adversarial Motion Priors for Aesthetically\n  Constrained Humanoids","summary":"  We present a Reinforcement Learning (RL)-based locomotion system for Cosmo, a\ncustom-built humanoid robot designed for entertainment applications. Unlike\ntraditional humanoids, entertainment robots present unique challenges due to\naesthetic-driven design choices. Cosmo embodies these with a disproportionately\nlarge head (16% of total mass), limited sensing, and protective shells that\nconsiderably restrict movement. To address these challenges, we apply\nAdversarial Motion Priors (AMP) to enable the robot to learn natural-looking\nmovements while maintaining physical stability. We develop tailored domain\nrandomization techniques and specialized reward structures to ensure safe\nsim-to-real, protecting valuable hardware components during deployment. Our\nexperiments demonstrate that AMP generates stable standing and walking\nbehaviors despite Cosmo's extreme mass distribution and movement constraints.\nThese results establish a promising direction for robots that balance aesthetic\nappeal with functional performance, suggesting that learning-based methods can\neffectively adapt to aesthetic-driven design constraints.\n","authors":["Arturo Flores Alvarez","Fatemeh Zargarbashi","Havel Liu","Shiqi Wang","Liam Edwards","Jessica Anz","Alex Xu","Fan Shi","Stelian Coros","Dennis W. Hong"],"pdf_url":"https://arxiv.org/pdf/2509.05581v1.pdf","comment":"8 pages, 11 figures, accepted at IEEE-RAS International Conference on\n  Humanoid Robots (Humanoids) 2025"},{"id":"http://arxiv.org/abs/2509.07009v1","updated":"2025-09-06T10:22:27Z","published":"2025-09-06T10:22:27Z","title":"Computational Concept of the Psyche","summary":"  The article provides an overview of approaches to modeling the human psyche\nin the perspective of building an artificial one. Based on the review, a\nconcept of cognitive architecture is proposed, where the psyche is considered\nas an operating system of a living or artificial subject, including a space of\nneeds that determines its life meanings in connection with stimuli from the\nexternal world, and intelligence as a decision-making system for actions in\nrelation to this world in order to satisfy these needs. Based on the concept, a\ncomputational formalization is proposed for creating artificial intelligence\nsystems through learning from experience in the space of a space of needs,\ntaking into account their biological or existential significance for an\nintelligent agent. Thus, the problem of building general artificial\nintelligence as a system for making optimal decisions in the space of\nagent-specific needs under conditions of uncertainty is formalized, with\nmaximization of success in achieving goals, minimization of existential risks\nand maximization of energy efficiency. A minimal experimental implementation of\nthe model is also provided.\n","authors":["Anton Kolonin","Vladimir Kryukov"],"pdf_url":"https://arxiv.org/pdf/2509.07009v1.pdf","comment":"14 pages, in Russian, 2 figures, submitted to Neuroinformatics-2025\n  conference"}],"Hardware Architecture":[{"id":"http://arxiv.org/abs/2504.10832v2","updated":"2025-09-06T15:03:56Z","published":"2025-04-15T03:23:02Z","title":"Unlimited Vector Processing for Wireless Baseband Based on RISC-V\n  Extension","summary":"  Wireless baseband processing (WBP) serves as an ideal scenario for utilizing\nvector processing, which excels in managing data-parallel operations due to its\nparallel structure. However, conventional vector architectures face certain\nconstraints such as limited vector register sizes, reliance on power-of-two\nvector length multipliers, and vector permutation capabilities tied to specific\narchitectures. To address these challenges, we have introduced an instruction\nset extension (ISE) based on RISC-V known as unlimited vector processing (UVP).\nThis extension enhances both the flexibility and efficiency of vector\ncomputations. UVP employs a novel programming model that supports\nnon-power-of-two register groupings and hardware strip-mining, thus enabling\nsmooth handling of vectors of varying lengths while reducing the software\nstrip-mining burden. Vector instructions are categorized into symmetric and\nasymmetric classes, complemented by specialized load/store strategies to\noptimize execution. Moreover, we present a hardware implementation of UVP\nfeaturing sophisticated hazard detection mechanisms, optimized pipelines for\nsymmetric tasks such as fixed-point multiplication and division, and a robust\npermutation engine for effective asymmetric operations. Comprehensive\nevaluations demonstrate that UVP significantly enhances performance, achieving\nup to 3.0$\\times$ and 2.1$\\times$ speedups in matrix multiplication and fast\nFourier transform (FFT) tasks, respectively, when measured against lane-based\nvector architectures. Our synthesized RTL for a 16-lane configuration using\nSMIC 40nm technology spans 0.94 mm$^2$ and achieves an area efficiency of 21.2\nGOPS/mm$^2$.\n","authors":["Limin Jiang","Yi Shi","Yihao Shen","Shan Cao","Zhiyuan Jiang","Sheng Zhou"],"pdf_url":"https://arxiv.org/pdf/2504.10832v2.pdf","comment":"14 pages, 10 figures, 3 tables"},{"id":"http://arxiv.org/abs/2509.05688v1","updated":"2025-09-06T11:33:35Z","published":"2025-09-06T11:33:35Z","title":"High Utilization Energy-Aware Real-Time Inference Deep Convolutional\n  Neural Network Accelerator","summary":"  Deep convolution Neural Network (DCNN) has been widely used in computer\nvision tasks. However, for edge devices even inference has too large\ncomputational complexity and data access amount. The inference latency of\nstate-of-the-art models are impractical for real-world applications. In this\npaper, we propose a high utilization energy-aware real-time inference deep\nconvolutional neural network accelerator, which improves the performance of the\ncurrent accelerators. First, we use the 1x1 size convolution kernel as the\nsmallest unit of the computing unit. Then we design suitable computing unit\nbased on the requirements of each model. Secondly, we use Reuse Feature SRAM to\nstore the output of the current layer in the chip and use the value as the\ninput of the next layer. Moreover, we import Output Reuse Strategy and Ring\nStream Dataflow to reduce the amount of data exchange between chips and DRAM.\nFinally, we present On-fly Pooling Module to let the calculation of the Pooling\nlayer directly complete in the chip. With the aid of the proposed method, the\nimplemented acceleration chip has an extremely high hardware utilization rate.\nWe reduce a generous amount of data transfer on the specific module, ECNN.\nCompared to the methods without reuse strategy, we can reduce 533 times of data\naccess amount. At the same time, we have enough computing power to perform\nreal-time execution of the existing image classification model, VGG16 and\nMobileNet. Compared with the design in VWA, we can speed up 7.52 times and have\n1.92x energy efficiency\n","authors":["Kuan-Ting Lin","Ching-Te Chiu","Jheng-Yi Chang","Shi-Zong Huang","Yu-Ting Li"],"pdf_url":"https://arxiv.org/pdf/2509.05688v1.pdf","comment":null}],"Programming Languages":[{"id":"http://arxiv.org/abs/2509.05586v1","updated":"2025-09-06T04:18:43Z","published":"2025-09-06T04:18:43Z","title":"Fixed Parameter Tractable Linearizability Monitoring for Stack, Queue\n  and Anagram Agnostic Data Types","summary":"  Verifying linearizability of concurrent data structures is NP-hard, even for\nsimple types. We present fixed-parameter tractable algorithms for monitoring\nstacks, queues, and anagram-agnostic data types (AADTs), parameterized by the\nmaximum concurrency. Our approach leverages frontier graphs and partition\nstates to bound the search space. For AADTs, equivalence of linearizations\nenables monitoring in log-linear time. For stacks, we introduce a grammar-based\nmethod with a sub-cubic reduction to matrix multiplication, and for queues, a\nsplit-sequence transition system supporting efficient dynamic programming.\nThese results unify tractability guarantees for both order-sensitive and\nanagram-agnostic data types under bounded concurrency.\n","authors":["Lee Zheng Han","Umang Mathur"],"pdf_url":"https://arxiv.org/pdf/2509.05586v1.pdf","comment":null}],"Data Structures and Algorithms":[{"id":"http://arxiv.org/abs/2509.05870v1","updated":"2025-09-06T23:57:57Z","published":"2025-09-06T23:57:57Z","title":"A Simple and Robust Protocol for Distributed Counting","summary":"  We revisit the distributed counting problem, where a server must continuously\napproximate the total number of events occurring across $k$ sites while\nminimizing communication. The communication complexity of this problem is known\nto be $\\Theta(\\frac{k}{\\epsilon}\\log N)$ for deterministic protocols. Huang,\nYi, and Zhang (2012) showed that randomization can reduce this to\n$\\Theta(\\frac{\\sqrt{k}}{\\epsilon}\\log N)$, but their analysis is restricted to\nthe {\\em oblivious setting}, where the stream of events is independent of the\nprotocol's outputs.\n  Xiong, Zhu, and Huang (2023) presented a robust protocol for distributed\ncounting that removes the oblivious assumption. However, their communication\ncomplexity is suboptimal by a $polylog(k)$ factor and their protocol is\nsubstantially more complex than the oblivious protocol of Huang et al. (2012).\nThis left open a natural question: could it be that the simple protocol of\nHuang et al. (2012) is already robust?\n  We resolve this question with two main contributions. First, we show that the\nprotocol of Huang et al. (2012) is itself not robust by constructing an\nexplicit adaptive attack that forces it to lose its accuracy. Second, we\npresent a new, surprisingly simple, robust protocol for distributed counting\nthat achieves the optimal communication complexity of\n$O(\\frac{\\sqrt{k}}{\\epsilon} \\log N)$. Our protocol is simpler than that of\nXiong et al. (2023), perhaps even simpler than that of Huang et al. (2012), and\nis the first to match the optimal oblivious complexity in the adaptive setting.\n","authors":["Edith Cohen","Moshe Shechner","Uri Stemmer"],"pdf_url":"https://arxiv.org/pdf/2509.05870v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.02799v2","updated":"2025-09-06T23:47:53Z","published":"2025-02-05T00:52:44Z","title":"Unweighted One-Sided Code Sparsifiers and Thin Subgraphs","summary":"  For a linear code $\\mathcal{C} \\subseteq \\mathbb{F}_2^n$ and $\\alpha \\in\n[0,1]$, call a set $S \\subseteq [n]$ an (unweighted) one-sided\n$\\alpha$-sparsifier of $\\mathcal{C}$ if for all $c \\in \\mathcal{C}$,\n$\\mathrm{wt}(c_S)\\geq \\alpha \\cdot \\mathrm{wt}(c)$, where $c_S$ is the\nprojection of $c$ onto the coordinates in $S$ and $\\mathrm{wt}(c)$ is the\nHamming weight of $c$. \\\\ We show that every $k$-dimensional linear code\n$\\mathcal{C}\\subseteq \\mathbb{F}_2^n$ has at least $2^{n - k}$ many unweighted\none-sided $1/2$-sparsifiers and hence one of size at most $n/2 + O(\\sqrt{n\nk})$. As an application, letting $\\mathcal{C} \\subseteq \\mathbb{F}_2^E$ denote\nthe cut-space of a graph $G=(V, E)$, we show a lower bound of $2^{\\lvert E\n\\rvert- (\\lvert V \\rvert - 1)}$ on the number of $1/2$-thin subgraphs of $G$\nand the existence of a $1/2$-thin subgraph with at least $\\lvert E \\rvert\n/2-O(\\sqrt{\\lvert E \\rvert \\cdot \\lvert V \\rvert})$ edges. In contrast to\nprevious results on thin subgraphs, our proofs are purely \"combinatorial\".\n","authors":["Shayan Oveis Gharan","Arvin Sahami"],"pdf_url":"https://arxiv.org/pdf/2502.02799v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.05827v1","updated":"2025-09-06T20:43:35Z","published":"2025-09-06T20:43:35Z","title":"Subsequence Covers of Words","summary":"  We introduce subsequence covers (s-covers, in short), a new type of covers of\na word. A word $C$ is an s-cover of a word $S$ if the occurrences of $C$ in $S$\nas subsequences cover all the positions in $S$.\n  The s-covers seem to be computationally much harder than standard covers of\nwords (cf. Apostolico et al., Inf. Process. Lett. 1991), but, on the other\nhand, much easier than the related shuffle powers (Warmuth and Haussler, J.\nComput. Syst. Sci. 1984).\n  We give a linear-time algorithm for testing if a candidate word $C$ is an\ns-cover of a word $S$ over a polynomially-bounded integer alphabet. We also\ngive an algorithm for finding a shortest s-cover of a word $S$, which in the\ncase of a constant-sized alphabet, also runs in linear time.\n  The words without proper s-cover are called s-primitive. We complement our\nalgorithmic results with explicit lower and an upper bound on the length of a\nlongest s-primitive word. Both bounds are exponential in the size of the\nalphabet. The upper bound presented here improves the bound given in the\nconference version of this paper [SPIRE 2022].\n","authors":["Panagiotis Charalampopoulos","Solon P. Pissis","Jakub Radoszewski","Wojciech Rytter","Tomasz Waleń","Wiktor Zuba"],"pdf_url":"https://arxiv.org/pdf/2509.05827v1.pdf","comment":"Simplified algorithm in section 2"},{"id":"http://arxiv.org/abs/2310.09483v2","updated":"2025-09-06T20:33:35Z","published":"2023-10-14T04:05:47Z","title":"Sorting and Selection in Rounds with Adversarial Comparisons","summary":"  We continue the study of selection and sorting of $n$ numbers under the\nadversarial comparator model, where comparisons can be adversarially tampered\nwith if the arguments are sufficiently close.\n  We derive a randomized sorting algorithm that does $O(n \\log^2 n)$\ncomparisons and gives a correct answer with high probability, addressing an\nopen problem of Ajtai, Feldman, Hassadim, and Nelson [AFHN15]. Our algorithm\nalso implies a selection algorithm that does $O(n \\log n)$ comparisons and\ngives a correct answer with high probability. Both of these results are a\n$\\log$ factor away from the naive lower bound. [AFHN15] shows an\n$\\Omega(n^{1+\\varepsilon})$ lower bound for both sorting and selection in the\ndeterministic case, so our results also prove a discrepancy between what is\npossible with deterministic and randomized algorithms in this setting.\n  We also consider both sorting and selection in rounds, exploring the tradeoff\nbetween accuracy, number of comparisons, and number of rounds. Using results\nfrom sorting networks, we give general algorithms for sorting in $d$ rounds\nwhere the number of comparisons increases with $d$ and the accuracy decreases\nwith $d$. Using these algorithms, we derive selection algorithms in $d+O(\\log\nd)$ rounds that use the same number of comparisons as the corresponding sorting\nalgorithm, but have a constant accuracy. Notably, this gives selection\nalgorithms in $d$ rounds that use $n^{1 + o(1)}$ comparisons and have constant\naccuracy for all $d = \\omega(1)$, which still beats the deterministic lower\nbound of $\\Omega(n^{1+\\varepsilon})$.\n","authors":["Chris Trevisan"],"pdf_url":"https://arxiv.org/pdf/2310.09483v2.pdf","comment":"SODA 2024; minor revisions"},{"id":"http://arxiv.org/abs/2509.05762v1","updated":"2025-09-06T16:28:13Z","published":"2025-09-06T16:28:13Z","title":"Scalable Learning of One-Counter Automata via State-Merging Algorithms","summary":"  We propose One-counter Positive Negative Inference (OPNI), a passive learning\nalgorithm for deterministic real-time one-counter automata (DROCA). Inspired by\nthe RPNI algorithm for regular languages, OPNI constructs a DROCA consistent\nwith any given valid sample set.\n  We further present a method for combining OPNI with active learning of DROCA,\nand provide an implementation of the approach. Our experimental results\ndemonstrate that this approach scales more effectively than existing\nstate-of-the-art algorithms. We also evaluate the performance of the proposed\napproach for learning visibly one-counter automata.\n","authors":["Shibashis Guha","Anirban Majumdar","Prince Mathew","A. V. Sreejith"],"pdf_url":"https://arxiv.org/pdf/2509.05762v1.pdf","comment":"18 pages, 24 figures, 3 procedures"},{"id":"http://arxiv.org/abs/2509.05750v1","updated":"2025-09-06T15:43:36Z","published":"2025-09-06T15:43:36Z","title":"Toward Efficient and Scalable Design of In-Memory Graph-Based Vector\n  Search","summary":"  Vector data is prevalent across business and scientific applications, and its\npopularity is growing with the proliferation of learned embeddings. Vector data\ncollections often reach billions of vectors with thousands of dimensions, thus,\nincreasing the complexity of their analysis. Vector search is the backbone of\nmany critical analytical tasks, and graph-based methods have become the best\nchoice for analytical tasks that do not require guarantees on the quality of\nthe answers. Although several paradigms (seed selection, incremental insertion,\nneighborhood propagation, neighborhood diversification, and divide-and-conquer)\nhave been employed to design in-memory graph-based vector search algorithms, a\nsystematic comparison of the key algorithmic advances is still missing. We\nconduct an exhaustive experimental evaluation of twelve state-of-the-art\nmethods on seven real data collections, with sizes up to 1 billion vectors. We\nshare key insights about the strengths and limitations of these methods; e.g.,\nthe best approaches are typically based on incremental insertion and\nneighborhood diversification, and the choice of the base graph can hurt\nscalability. Finally, we discuss open research directions, such as the\nimportance of devising more sophisticated data adaptive seed selection and\ndiversification strategies.\n","authors":["Ilias Azizi","Karima Echihab","Themis Palpanas","Vassilis Christophides"],"pdf_url":"https://arxiv.org/pdf/2509.05750v1.pdf","comment":"Presented at ICML 2025 VecDB Workshop; an extended version appeared\n  in ACM SIGMOD 2025 ('Graph-Based Vector Search: An Experimental Evaluation of\n  the State-of-the-Art')"},{"id":"http://arxiv.org/abs/2505.16937v2","updated":"2025-09-06T14:27:10Z","published":"2025-05-22T17:27:40Z","title":"Quasi-optimal hierarchically semi-separable matrix approximation","summary":"  We present a randomized algorithm for producing a quasi-optimal\nhierarchically semi-separable (HSS) approximation to an $N\\times N$ matrix $A$\nusing only matrix-vector products with $A$ and $A^T$. We prove that, using $O(k\n\\log(N/k))$ matrix-vector products and ${O}(N k^2 \\log(N/k))$ additional\nruntime, the algorithm returns an HSS matrix $B$ with rank-$k$ blocks whose\nexpected Frobenius norm error $\\mathbb{E}[\\|A - B\\|_F^2]$ is at most\n$O(\\log(N/k))$ times worse than the best possible approximation error by an HSS\nrank-$k$ matrix. In fact, the algorithm we analyze in a simple modification of\nan empirically effective method proposed by [Levitt & Martinsson, SISC 2024].\nAs a stepping stone towards our main result, we prove two results that are of\nindependent interest: a similar guarantee for a variant of the algorithm which\naccesses $A$'s entries directly, and explicit error bounds for near-optimal\nsubspace approximation using projection-cost-preserving sketches. To the best\nof our knowledge, our analysis constitutes the first polynomial-time\nquasi-optimality result for HSS matrix approximation, both in the explicit\naccess model and the matrix-vector product query model.\n","authors":["Noah Amsel","Tyler Chen","Feyza Duman Keles","Diana Halikias","Cameron Musco","Christopher Musco","David Persson"],"pdf_url":"https://arxiv.org/pdf/2505.16937v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.04984v2","updated":"2025-09-06T12:50:56Z","published":"2024-09-08T05:46:21Z","title":"FPT approximations for Capacitated Sum of Radii and Diameters","summary":"  The Capacitated Sum of Radii problem involves partitioning a set of points\n$P$, where each point $p\\in P$ has capacity $U_p$, into $k$ clusters that\nminimize the sum of cluster radii, such that the number of points in the\ncluster centered at point $p$ is at most $U_p$. We begin by showing that the\nproblem is APX-hard, and that under gap-ETH there is no parameterized\napproximation scheme (FPT-AS). We then construct a $\\approx5.83$-approximation\nalgorithm in FPT time (improving a previous $\\approx7.61$ approximation in FPT\ntime). Our results also hold when the objective is a general monotone symmetric\nnorm of radii. We also improve the approximation factors for the uniform\ncapacity case, and for the closely related problem of Capacitated Sum of\nDiameters.\n","authors":["Arnold Filtser","Ameet Gadekar"],"pdf_url":"https://arxiv.org/pdf/2409.04984v2.pdf","comment":"improved hardness of approximation factor and minor edits"}],"Graphics":[{"id":"http://arxiv.org/abs/2509.05855v1","updated":"2025-09-06T22:42:11Z","published":"2025-09-06T22:42:11Z","title":"Programming tension in 3D printed networks inspired by spiderwebs","summary":"  Each element in tensioned structural networks -- such as tensegrity,\narchitectural fabrics, or medical braces/meshes -- requires a specific tension\nlevel to achieve and maintain the desired shape, stability, and compliance.\nThese structures are challenging to manufacture, 3D print, or assemble because\nflattening the network during fabrication introduces multiplicative\ninaccuracies in the network's final tension gradients. This study overcomes\nthis challenge by offering a fabrication algorithm for direct 3D printing of\nsuch networks with programmed tension gradients, an approach analogous to the\nspinning of spiderwebs. The algorithm: (i) defines the desired network and\nprescribes its tension gradients using the force density method; (ii) converts\nthe network into an unstretched counterpart by numerically optimizing vertex\nlocations toward target element lengths and converting straight elements into\narcs to resolve any remaining error; and (iii) decomposes the network into\nprintable toolpaths; Optional additional steps are: (iv) flattening curved 2D\nnetworks or 3D networks to ensure 3D printing compatibility; and (v)\nautomatically resolving any unwanted crossings introduced by the flattening\nprocess. The proposed method is experimentally validated using 2D unit cells of\nviscoelastic filaments, where accurate tension gradients are achieved with an\naverage element strain error of less than 1.0\\%. The method remains effective\nfor networks with element minimum length and maximum stress of 5.8 mm and 7.3\nMPa, respectively. The method is used to demonstrate the fabrication of three\ncomplex cases: a flat spiderweb, a curved mesh, and a tensegrity system. The\nprogrammable tension gradient algorithm can be utilized to produce compact,\nintegrated cable networks, enabling novel applications such as moment-exerting\nstructures in medical braces and splints.\n","authors":["Thijs Masmeijer","Caleb Swain","Jeff Hill","Ed Habtour"],"pdf_url":"https://arxiv.org/pdf/2509.05855v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.18597v2","updated":"2025-09-06T19:34:22Z","published":"2025-08-26T02:01:20Z","title":"SemLayoutDiff: Semantic Layout Generation with Diffusion Model for\n  Indoor Scene Synthesis","summary":"  We present SemLayoutDiff, a unified model for synthesizing diverse 3D indoor\nscenes across multiple room types. The model introduces a scene layout\nrepresentation combining a top-down semantic map and attributes for each\nobject. Unlike prior approaches, which cannot condition on architectural\nconstraints, SemLayoutDiff employs a categorical diffusion model capable of\nconditioning scene synthesis explicitly on room masks. It first generates a\ncoherent semantic map, followed by a cross-attention-based network to predict\nfurniture placements that respect the synthesized layout. Our method also\naccounts for architectural elements such as doors and windows, ensuring that\ngenerated furniture arrangements remain practical and unobstructed. Experiments\non the 3D-FRONT dataset show that SemLayoutDiff produces spatially coherent,\nrealistic, and varied scenes, outperforming previous methods.\n","authors":["Xiaohao Sun","Divyam Goel","Angel X. Chang"],"pdf_url":"https://arxiv.org/pdf/2508.18597v2.pdf","comment":"Project page: https://3dlg-hcvc.github.io/SemLayoutDiff/"},{"id":"http://arxiv.org/abs/2509.05595v1","updated":"2025-09-06T04:42:05Z","published":"2025-09-06T04:42:05Z","title":"PaMO: Parallel Mesh Optimization for Intersection-Free Low-Poly Modeling\n  on the GPU","summary":"  Reducing the triangle count in complex 3D models is a basic geometry\npreprocessing step in graphics pipelines such as efficient rendering and\ninteractive editing. However, most existing mesh simplification methods exhibit\na few issues. Firstly, they often lead to self-intersections during decimation,\na major issue for applications such as 3D printing and soft-body simulation.\nSecond, to perform simplification on a mesh in the wild, one would first need\nto perform re-meshing, which often suffers from surface shifts and losses of\nsharp features. Finally, existing re-meshing and simplification methods can\ntake minutes when processing large-scale meshes, limiting their applications in\npractice. To address the challenges, we introduce a novel GPU-based mesh\noptimization approach containing three key components: (1) a parallel\nre-meshing algorithm to turn meshes in the wild into watertight, manifold, and\nintersection-free ones, and reduce the prevalence of poorly shaped triangles;\n(2) a robust parallel simplification algorithm with intersection-free\nguarantees; (3) an optimization-based safe projection algorithm to realign the\nsimplified mesh with the input, eliminating the surface shift introduced by\nre-meshing and recovering the original sharp features. The algorithm\ndemonstrates remarkable efficiency, simplifying a 2-million-face mesh to 20k\ntriangles in 3 seconds on RTX4090. We evaluated the approach on the Thingi10K\ndataset and showcased its exceptional performance in geometry preservation and\nspeed.\n","authors":["Seonghun Oh","Xiaodi Yuan","Xinyue Wei","Ruoxi Shi","Fanbo Xiang","Minghua Liu","Hao Su"],"pdf_url":"https://arxiv.org/pdf/2509.05595v1.pdf","comment":null}]},"2025-09-09T00:00:00Z":{"Systems and Control":[{"id":"http://arxiv.org/abs/2509.07919v1","updated":"2025-09-09T16:59:43Z","published":"2025-09-09T16:59:43Z","title":"A Markov Decision Process Model for Intrusion Tolerance Problems","summary":"  We formulate and analyze a simplest Markov decision process model for\nintrusion tolerance problems, assuming that (i) each attack proceeds through\none or more steps before the system's security fails, (ii) defensive responses\nthat target these intermediate steps may only sometimes thwart the attack and\n(iii) reset responses that are sensible upon discovering an attack's completion\nmay not always recover from the security failure. The analysis shows that, even\nin the ideal case of perfect detectors, it can be sub-optimal in the long run\nto employ defensive responses while under attack; that is, depending on attack\ndynamics and response effectiveness, the total overhead of ongoing defensive\ncountermeasures can exceed the total risk of intermittent security failures.\nThe analysis similarly examines the availability loss versus the risk reduction\nof employing preemptive resets, isolating key factors that determine whether\nsystem recovery is best initiated reactively or proactively. We also discuss\nmodel extensions and related work looking towards intrusion tolerance\napplications with (i) imperfect or controllable detectors, (ii) multiple types\nof attacks, (iii) continuous-time dynamics or (iv) strategic attackers.\n","authors":["Patrick Kreidl"],"pdf_url":"https://arxiv.org/pdf/2509.07919v1.pdf","comment":"19 pages, 9 figures, unpublished/rejected manuscript circa 2010"},{"id":"http://arxiv.org/abs/2509.07918v1","updated":"2025-09-09T16:59:09Z","published":"2025-09-09T16:59:09Z","title":"Partitioning and Self-organization of Distributed Generation in Large\n  Distribution Networks","summary":"  Distribution networks will experience more installations of distributed\ngeneration (DG) that is unpredictable and stochastic in nature. Greater\ndistributed control and intelligence will allow challenges such as voltage\ncontrol to be handled effectively. The partitioning of power networks into\nsmaller clusters provides a method to split the control problem into manageable\nsub-problems. This paper presents a community detection-based partitioning\ntechnique for distribution networks considering local DGs, allowing them to be\ngrouped and controlled in a distributed manner by using local signals and\nmeasurements. This method also allows each community to control the voltage\nusing only neighboring DGs, and for each community to self-organize to reflect\nvarying DG conditions and to maintain stable control. Simulations demonstrate\nthat the partitioning of the large distribution network is effective, and each\ncommunity is able to self-organize and to regulate the voltage independently\nusing only its local DGs.\n","authors":["Badr Al Faiya","Stephen McArthur","Ivana Kockar"],"pdf_url":"https://arxiv.org/pdf/2509.07918v1.pdf","comment":"IEEE General Meeting, 5 pages"},{"id":"http://arxiv.org/abs/2109.03445v7","updated":"2025-09-09T16:45:32Z","published":"2021-09-08T06:06:28Z","title":"Convergence of Batch Asynchronous Stochastic Approximation With\n  Applications to Reinforcement Learning","summary":"  We begin by briefly surveying some results on the convergence of the\nStochastic Gradient Descent (SGD) Method, proved in a companion paper by the\npresent authors. These results are based on viewing SGD as a version of\nStochastic Approximation (SA). Ever since its introduction in the classic paper\nof Robbins and Monro in 1951, SA has become a standard tool for finding a\nsolution of an equation of the form $f(\\theta) = 0$, when only noisy\nmeasurements of $f(\\cdot)$ are available. In most situations, \\textit{every\ncomponent} of the putative solution $\\theta_t$ is updated at each step $t$. In\nsome applications in Reinforcement Learning (RL), \\textit{only one component}\nof $\\theta_t$ is updated at each $t$. This is known as \\textbf{asynchronous}\nSA. In this paper, we study \\textbf{Block Asynchronous SA (BASA)}, in which, at\neach step $t$, \\textit{some but not necessarily all} components of $\\theta_t$\nare updated. The theory presented here embraces both conventional (synchronous)\nSA as well as asynchronous SA, and all in-between possibilities. We provide\nsufficient conditions for the convergence of BASA, and also prove bounds on the\n\\textit{rate} of convergence of $\\theta_t$ to the solution. For the case of\nconventional SGD, these results reduce to those proved in our companion paper.\nThen we apply these results to the problem of finding a fixed point of a map\nwith only noisy measurements. This problem arises frequently in RL. We prove\nsufficient conditions for convergence as well as estimates for the rate of\nconvergence.\n","authors":["Rajeeva L. Karandikar","M. Vidyasagar"],"pdf_url":"https://arxiv.org/pdf/2109.03445v7.pdf","comment":"34 pages, 1 figure"},{"id":"http://arxiv.org/abs/2509.07847v1","updated":"2025-09-09T15:23:12Z","published":"2025-09-09T15:23:12Z","title":"Multi-Topic Projected Opinion Dynamics for Resource Allocation","summary":"  We propose a model of opinion formation on resource allocation among multiple\ntopics by multiple agents, who are subject to hard budget constraints. We\ndefine a utility function for each agent and then derive a projected dynamical\nsystem model of opinion evolution assuming that each agent myopically seeks to\nmaximize its utility subject to its constraints. Inter-agent coupling arises\nfrom an undirected social network, while inter-topic coupling arises from\nresource constraints. We show that opinions always converge to the equilibrium\nset. For special networks with very weak antagonistic relations, the opinions\nconverge to a unique equilibrium point. We further show that the underlying\nopinion formation game is a potential game. We relate the equilibria of the\ndynamics and the Nash equilibria of the game and characterize the unique Nash\nequilibrium for networks with no antagonistic relations. Finally, simulations\nillustrate our findings.\n","authors":["Prashil Wankhede","Nirabhra Mandal","Sonia Martínez","Pavankumar Tallapragada"],"pdf_url":"https://arxiv.org/pdf/2509.07847v1.pdf","comment":"8 pages, 4 figures, accepted for presentation in IEEE Conference on\n  Decision and Control (CDC), 2025"},{"id":"http://arxiv.org/abs/2509.07843v1","updated":"2025-09-09T15:16:54Z","published":"2025-09-09T15:16:54Z","title":"Feedback Linearization-based Guidance Law for Guaranteed Interception","summary":"  This paper presents an input-output feedback linearization (IOL)-based\nguidance law to ensure interception in a pursuer-evader engagement scenario. A\npoint-mass dynamic model for both the pursuer and the evader is considered. An\nIOL guidance law is derived using range and line-of-sight (LOS) rate\nmeasurements. It is found that the range-based IOL guidance law exhibits a\nsingularity under certain conditions. To address this issue, a fuzzy logic\nsystem is employed to smoothly blend the IOL guidance with the classical\nproportional guidance law, thereby avoiding the singularity. In contrast, the\nLOS-based IOL guidance law is free of singularities but suffers from divergence\nissues due to angle-related complications. To resolve this, a simple correction\nfunction is introduced to ensure consistent interception behavior. Results from\nMonte Carlo simulations indicate that both modifications of the IOL guidance\nlaws cause interception with control limits applied.\n","authors":["Alexander Dorsey","Ankit Goel"],"pdf_url":"https://arxiv.org/pdf/2509.07843v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07840v1","updated":"2025-09-09T15:13:57Z","published":"2025-09-09T15:13:57Z","title":"Sensor Management in Multi-Stage Stochastic Control Problems with\n  Imperfect State Information","summary":"  Technological advancements in miniaturization and wireless communications are\nyielding more affordable and versatile sensors and, in turn, more applications\nin which a network of sensors can be actively managed to best support overall\ndecision-making objectives. We propose modeling the opportunity for sensor\nmanagement within multi-stage stochastic control problems with imperfect state\ninformation. Such formulations inherently assume the state of the modeled\nenvironment cannot be accessed directly but instead the controller can observe\nonly noisy measurements of the state and, therefore, at each decision stage\nsome form of state estimation is required before a control is actuated. The\nnotion of sensor management arises when the modeled controls not only affect\nthe subsequent evolution of the state but can also affect the nature of future\nmeasurements and, hence, the quality of state estimates that drive future\ncontrol decisions. In principle, the optimal strategy for any appropriately\nmodeled multi-stage stochastic control problem with imperfect state information\n(with or without opportunity for sensor management) is the solution to a\ndynamic program; in practice, the computational requirements are typically\nprohibitive yet dynamic programming methods are still useful to guide the\ndevelopment of effective suboptimal strategies. In this spirit, we model the\nopportunity for sensor management within small-scale examples of two\nwell-studied dynamic programming formulations, namely (1) the\nfinite-state/finite-action Partially-Observable Markov Decision Process\n(PO-MDP) and (2) the Linear-Quadratic-Gaussian Regulator (LQGR). These examples\nadmit solvable dynamic programs and confirm how the interplay between sensing\nand acting is a natural by-product of a dynamic programming solution.\n","authors":["Patrick Kreidl"],"pdf_url":"https://arxiv.org/pdf/2509.07840v1.pdf","comment":"34 pages, 9 figures, unpublished/unreviewed manuscript circa 2002"},{"id":"http://arxiv.org/abs/2509.07837v1","updated":"2025-09-09T15:12:00Z","published":"2025-09-09T15:12:00Z","title":"Filtering in Multivariate Systems with Quantized Measurements using a\n  Gaussian Mixture-Based Indicator Approximation","summary":"  This work addresses the problem of state estimation in multivariable dynamic\nsystems with quantized outputs, a common scenario in applications involving\nlow-resolution sensors or communication constraints. A novel method is proposed\nto explicitly construct the probability mass function associated with the\nquantized measurements by approximating the indicator function of each region\ndefined by the quantizer using Gaussian mixture models. Unlike previous\napproaches, this technique generalizes to any number of quantized outputs\nwithout requiring case-specific numerical solutions, making it a scalable and\nefficient solution. Simulation results demonstrate that the proposed filter\nachieves high accuracy in state estimation, both in terms of fidelity of the\nfiltering distributions and mean squared error, while maintaining significantly\nreduced computational cost.\n","authors":["Angel L. Cedeño","Rodrigo A. González","Boris I. Godoy","Juan C. Agüero"],"pdf_url":"https://arxiv.org/pdf/2509.07837v1.pdf","comment":"This work has been acepted for presentation in the 64th IEEE\n  Conference on Decision and Control. 6 pages, 8 Figures"},{"id":"http://arxiv.org/abs/2410.08756v2","updated":"2025-09-09T14:34:26Z","published":"2024-10-11T12:15:25Z","title":"State Estimation with Protecting Exogenous Inputs via Cramér-Rao Lower\n  Bound Approach","summary":"  This paper addresses the real-time state estimation problem for dynamic\nsystems while protecting exogenous inputs against adversaries, who may be\nhonest-but-curious third parties or external eavesdroppers. The Cram\\'er-Rao\nlower bound (CRLB) is employed to constrain the mean square error (MSE) of the\nadversary's estimate for the exogenous inputs above a specified threshold. By\nminimizing the MSE of the state estimate while ensuring a certain privacy level\nmeasured by CRLB, the problem is formulated as a constrained optimization. To\nsolve the optimization problem, an explicit expression for CRLB is first\nprovided. As the computational complexity of the CRLB increases with the time\nstep, a low-complexity approach is proposed to make the complexity independent\nof time. Then, a relaxation approach is proposed to efficiently solve the\noptimization problem. Finally, a privacy-preserving state estimation algorithm\nwith low complexity is developed, which also ensures $(\\epsilon,\n\\delta)$-differential privacy. Two illustrative examples, including a practical\nscenario for protecting building occupancy, demonstrate the effectiveness of\nthe proposed algorithm.\n","authors":["Liping Guo","Jimin Wang","Yanlong Zhao","Ji-Feng Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.08756v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07748v1","updated":"2025-09-09T13:49:41Z","published":"2025-09-09T13:49:41Z","title":"Swarm-optimized Adaptive Augmentation of Missile Autopilot","summary":"  This paper considers the problem of optimizing a missile autopilot. In\nparticular, the paper investigates the application of an online learning\ntechnique to learn and optimize the gains of a three-loop topology autopilot\nfor a planar missile modeled with nonlinear dynamics and nonlinear aerodynamics\nforces and moments. The classical autopilot for a missile is based on a\nthree-loop topology, where each loop consists of tunable proportional gains. An\nadaptive three-loop autopilot is constructed by augmenting the classical\nautopilot's fixed-gain controllers with a learning-based controller, which is\nrecursively optimized using retrospective cost optimization. Numerical\nsimulations show that online learning improves the tracking performance of the\nclassical autopilot in both nominal and off-nominal interception scenarios.\n","authors":["Alexander Dorsey","Parham Oveissi","Jeffrey D. Barton","Ankit Goel"],"pdf_url":"https://arxiv.org/pdf/2509.07748v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07707v1","updated":"2025-09-09T13:10:58Z","published":"2025-09-09T13:10:58Z","title":"Fault Tolerant Control of a Quadcopter using Reinforcement Learning","summary":"  This study presents a novel reinforcement learning (RL)-based control\nframework aimed at enhancing the safety and robustness of the quadcopter, with\na specific focus on resilience to in-flight one propeller failure. Addressing\nthe critical need of a robust control strategy for maintaining a desired\naltitude for the quadcopter to safe the hardware and the payload in physical\napplications. The proposed framework investigates two RL methodologies Dynamic\nProgramming (DP) and Deep Deterministic Policy Gradient (DDPG), to overcome the\nchallenges posed by the rotor failure mechanism of the quadcopter. DP, a\nmodel-based approach, is leveraged for its convergence guarantees, despite high\ncomputational demands, whereas DDPG, a model-free technique, facilitates rapid\ncomputation but with constraints on solution duration. The research challenge\narises from training RL algorithms on large dimensions and action domains. With\nmodifications to the existing DP and DDPG algorithms, the controllers were\ntrained not only to cater for large continuous state and action domain and also\nachieve a desired state after an inflight propeller failure. To verify the\nrobustness of the proposed control framework, extensive simulations were\nconducted in a MATLAB environment across various initial conditions and\nunderscoring its viability for mission-critical quadcopter applications. A\ncomparative analysis was performed between both RL algorithms and their\npotential for applications in faulty aerial systems.\n","authors":["Muzaffar Habib","Adnan Maqsood","Adnan Fayyaz ud Din"],"pdf_url":"https://arxiv.org/pdf/2509.07707v1.pdf","comment":"e-ISSN: 1946-3901, ISSN: 1946-3855,\n  https://www.sae.org/publications/technical-papers/content/01-18-01-0006/"},{"id":"http://arxiv.org/abs/2509.07703v1","updated":"2025-09-09T13:09:57Z","published":"2025-09-09T13:09:57Z","title":"Prescribed-Time Event-Triggered Control for Matrix-Scaled Networks","summary":"  This article proposes a distributed control method for matrix-scaled\nmulti-agent networks aimed at achieving convergence within a user-defined time\nframe. The control law of each individual agent relies only on information from\nneighboring agents and is updated at discrete intervals determined by\nstate-dependent triggering functions, reducing the frequency of agent\ninteractions. To this end, first, the controller is augmented with a\ntime-varying gain. Then, the dynamics of the closed-loop system over the\nfinite-time interval is transformed into an infinite-time frame using time\nscaling. Lyapunov-based analysis is employed to derive suitable triggering\nconditions that guarantee the asymptotic convergence of the time-transformed\nsystem, thereby ensuring the prescribed-time convergence of the original\nsystem.\n","authors":["Sunny K P","Rakesh R Warier"],"pdf_url":"https://arxiv.org/pdf/2509.07703v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2509.07669v1","updated":"2025-09-09T12:36:34Z","published":"2025-09-09T12:36:34Z","title":"On-chip microwave sensing of quasiparticles in tantalum superconducting\n  circuits on silicon for scalable quantum technologies","summary":"  The performance and scalability of superconducting quantum circuits are\nfundamentally constrained by non-equilibrium quasiparticles, which induce\nmicrowave losses that limit resonator quality factors and qubit coherence\ntimes. Understanding and mitigating these excitations is therefore central to\nadvancing scalable quantum technologies. Here, we demonstrate on-chip microwave\nsensing of quasiparticles in high-Q {\\alpha}-tantalum coplanar waveguide\nresonators on silicon, operated in the single-photon regime.\nTemperature-dependent measurements reveal persistent non-equilibrium\nquasiparticles at millikelvin temperatures, producing a measurable suppression\nof the internal quality factor (Qi) relative to theoretical expectations. By\nbenchmarking across materials, we find that the quasiparticle density in\n{\\alpha}-Ta is approximately one-third that of NbN at equivalent normalised\ntemperatures (T/Tc), directly correlating with reduced microwave loss. Our\nmethodology establishes a scalable platform for probing quasiparticle dynamics\nand points towards new routes for engineering superconducting circuits with\nimproved coherence, with impact on qubit readout resonators, kinetic-inductance\ndetectors, and emerging quantum processors and sensors.\n","authors":["Shima Poorgholam-Khanjari","Paniz Foshat","Mingqi Zhang","Valentino Seferai","Martin Weides","Kaveh Delfanazari"],"pdf_url":"https://arxiv.org/pdf/2509.07669v1.pdf","comment":"16 pages, 7 figures"},{"id":"http://arxiv.org/abs/2509.07634v1","updated":"2025-09-09T12:00:47Z","published":"2025-09-09T12:00:47Z","title":"A kernel-based approach to physics-informed nonlinear system\n  identification","summary":"  This paper presents a kernel-based framework for physics-informed nonlinear\nsystem identification. The key contribution is a structured methodology that\nextends kernel-based techniques to seamlessly integrate partially known\nphysics-based models, improving parameter estimation and overall model\naccuracy. The proposed method enhances traditional modeling approaches by\nintegrating a parametric model, which provides physical interpretability, with\na kernel-based function, which accounts for unmodelled dynamics. The two\nmodel's components are identified from data simultaneously, minimizing a\nsuitable cost that balances the relative importance of the physical and the\nblack-box parts of the model. Additionally, nonlinear state smoothing is\nemployed to address scenarios involving state-space models with not fully\nmeasurable states. Numerical simulations on an experimental benchmark system\ndemonstrate the effectiveness of the proposed approach, with performance\ncomparisons against state-of-the-art identification techniques.\n","authors":["Cesare Donati","Martina Mammarella","Giuseppe C. Calafiore","Fabrizio Dabbene","Constantino Lagoa","Carlo Novara"],"pdf_url":"https://arxiv.org/pdf/2509.07634v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2509.07593v1","updated":"2025-09-09T11:05:44Z","published":"2025-09-09T11:05:44Z","title":"Can SSD-Mamba2 Unlock Reinforcement Learning for End-to-End Motion\n  Control?","summary":"  End-to-end reinforcement learning for motion control promises unified\nperception-action policies that scale across embodiments and tasks, yet most\ndeployed controllers are either blind (proprioception-only) or rely on fusion\nbackbones with unfavorable compute-memory trade-offs. Recurrent controllers\nstruggle with long-horizon credit assignment, and Transformer-based fusion\nincurs quadratic cost in token length, limiting temporal and spatial context.\nWe present a vision-driven cross-modal RL framework built on SSD-Mamba2, a\nselective state-space backbone that applies state-space duality (SSD) to enable\nboth recurrent and convolutional scanning with hardware-aware streaming and\nnear-linear scaling. Proprioceptive states and exteroceptive observations\n(e.g., depth tokens) are encoded into compact tokens and fused by stacked\nSSD-Mamba2 layers. The selective state-space updates retain long-range\ndependencies with markedly lower latency and memory use than quadratic\nself-attention, enabling longer look-ahead, higher token resolution, and stable\ntraining under limited compute. Policies are trained end-to-end under curricula\nthat randomize terrain and appearance and progressively increase scene\ncomplexity. A compact, state-centric reward balances task progress, energy\nefficiency, and safety. Across diverse motion-control scenarios, our approach\nconsistently surpasses strong state-of-the-art baselines in return, safety\n(collisions and falls), and sample efficiency, while converging faster at the\nsame compute budget. These results suggest that SSD-Mamba2 provides a practical\nfusion backbone for scalable, foresightful, and efficient end-to-end motion\ncontrol.\n","authors":["Gavin Tao","Yinuo Wang","Jinzhao Zhou"],"pdf_url":"https://arxiv.org/pdf/2509.07593v1.pdf","comment":"4 figures and 6 tables"},{"id":"http://arxiv.org/abs/2509.07546v1","updated":"2025-09-09T09:31:25Z","published":"2025-09-09T09:31:25Z","title":"Differential Dynamic Programming for the Optimal Control Problem with an\n  Ellipsoidal Target Set and Its Statistical Inference","summary":"  This work addresses an extended class of optimal control problems where a\ntarget for a system state has the form of an ellipsoid rather than a fixed,\nsingle point. As a computationally affordable method for resolving the extended\nproblem, we present a revised version of the differential dynamic programming\n(DDP), termed the differential dynamic programming with ellipsoidal target set\n(ETS-DDP). To this end, the problem with an ellipsoidal target set is\nreformulated into an equivalent form with the orthogonal projection operator,\nyielding that the resulting cost functions turn out to be discontinuous at some\npoints. As the DDP usually requires the differentiability of cost functions, in\nthe ETS-DDP formulation we locally approximate the (nonsmooth) cost functions\nto smoothed ones near the path generated at the previous iteration, by\nutilizing the explicit form of the orthogonal projection operator. Moreover, a\nstatistical inference method is also presented for designing the ellipsoidal\ntarget set, based on data on admissible target points collected by expert\ndemonstrations. Via a simulation on autonomous parking of a vehicle, it is seen\nthat the proposed ETS-DDP efficiently derives an admissible state trajectory\nwhile running much faster than the point-targeted DDP, at the expense of\noptimality.\n","authors":["Sungjun Eom","Gyunghoon Park"],"pdf_url":"https://arxiv.org/pdf/2509.07546v1.pdf","comment":"25th International Conference on Control, Automation and Systems\n  (ICCAS)"},{"id":"http://arxiv.org/abs/2504.16048v2","updated":"2025-09-09T09:13:51Z","published":"2025-04-22T17:25:40Z","title":"PRIME: Fast Primal-Dual Feedback Optimization for Markets with\n  Application to Optimal Power Flow","summary":"  Online Feedback Optimization (OFO) controllers iteratively drive a plant to\nan optimal operating point that satisfies input and output constraints, relying\nsolely on the input-output sensitivity as model information. This paper\nintroduces PRIME (PRoximal Iterative MarkEts), a novel OFO approach based on\nproximal-point iterations. Unlike existing OFO solutions, PRIME admits a\nmarket-based implementation, where self-interested actors are incentivized to\nmake choices that result in safe and efficient operation, without communicating\nprivate costs or constraints. Furthermore, PRIME can handle non-smooth\nobjective functions, achieve fast convergence rates and rapid constraint\nsatisfaction, and effectively reject measurement noise. We demonstrate PRIME on\nan AC optimal power flow problem, obtaining an efficient real-time nonlinear\nlocal marginal pricing scheme.\n","authors":["Nicholas Julian Behr","Mattia Bianchi","Keith Moffat","Saverio Bolognani","Florian Dörfler"],"pdf_url":"https://arxiv.org/pdf/2504.16048v2.pdf","comment":"Source code available at https://github.com/NicholasBehr/prime"},{"id":"http://arxiv.org/abs/2509.00896v2","updated":"2025-09-09T09:02:42Z","published":"2025-08-31T15:20:11Z","title":"AI-Enhanced Intelligent NIDS Framework: Leveraging Metaheuristic\n  Optimization for Robust Attack Detection and Prevention","summary":"  In todays rapidly evolving digital landscape, safeguarding network\ninfrastructures against cyberattacks has become a critical priority. This\nresearch presents an innovative AI-driven real-time intrusion detection\nframework designed to enhance network security, particularly in Wireless Sensor\nNetworks (WSNs), Cloud Computing (CC), and Internet of Things (IoT)\nenvironments. The system employs classical machine learning models, Logistic\nRegression, decision trees, and K-Nearest Neighbors, optimized through the\nnovel Energy Valley Optimization (EVO) method using the NSL-KDD dataset.\nFeature selection significantly reduced the number of input features from 42 to\n18, while maintaining strong detection capabilities. The proposed system\nachieved 98.95 percent. accuracy with Decision Tree, 98.47 percent with\nK-Nearest Neighbors, and 88.84 percent with Logistic Regression. Moreover, high\nprecision, recall, and F1-scores were attained across all classifiers while\nsubstantially reducing training and testing times, making the framework highly\nsuitable for real-time applications. To ensure fair detection across diverse\nattack types, dataset balancing via Downsampling was applied to address class\nimbalance challenges. This investigation focuses on the significance of\nadvancing IDSs. in cloud computing and WSNs. Overall, this work advances secure\ncommunications by delivering a scalable, low-latency, and high-accuracy\nintrusion detection solution aligned with the latest trends in artificial\nintelligence, cybersecurity, and real-time digital networks.\n","authors":["Maryam Mahdi Alhusseini","Mohammad Reza Feizi Derakhshi"],"pdf_url":"https://arxiv.org/pdf/2509.00896v2.pdf","comment":"16 pages, 12 figures, Second version"},{"id":"http://arxiv.org/abs/2507.21625v2","updated":"2025-09-09T08:49:11Z","published":"2025-07-29T09:35:55Z","title":"Real-Time Gradient Waveform Design for Arbitrary $k$-Space Trajectories","summary":"  \\textbf{Objective: }To develop a real-time method for designing gradient\nwaveforms for arbitrary $k$-space trajectories that are time-optimal and\nhardware-compliant. \\textbf{Methods: }The gradient waveform is solved\nrecursively under both the slew-rate and the trajectory constraints. The\ngradient constraint is enforced by thresholding the $\\ell_2$-norm of the next\ngradient vector. The constraints form a quadratic equation. To ensure the\nexistence of the solution, a novel Discrete-Time Forward and Backward Sweep\n(DTFBS) strategy is proposed. To ensure the existence of the trajectory\nderivatives, the trajectory function is reparameterized as a piecewise cubic\npolynomial function with $C^2$ continuity. To ensure trajectory fidelity, the\noutput gradient waveform is reparameterized by the finite difference of the\ntrajectory samples. Simulation experiments across seven commonly adopted\nnon-Cartesian trajectories were conducted to validate generality,\ntime-optimality, real-time capability, slew-rate accuracy, and improvements\nover prior work. Imaging feasibility of the designed time-optimal gradient\nwaveform was validated in phantom and in vivo experiments. \\textbf{Results:\n}The proposed method achieves a $>89\\%$ reduction in computation time and\nsimultaneously reduces slew-rate overshoot by $>98\\%$ compared to the prior\nmethod across all involved trajectories. The computation time of the proposed\nmethod is shorter than the gradient duration for all tested cases, validating\nthe real-time capability of the proposed method. \\textbf{Conclusions: }The\nproposed method enables real-time and hardware-compliant gradient waveform\ndesign, achieving significant reductions in computation time and slew-rate\novershoot compared to the previous method. \\textbf{Significance: }This is the\nfirst method achieving real-time gradient waveform design for arbitrary\n$k$-space trajectories.\n","authors":["Rui Luo","Hongzhang Huang","Qinfang Miao","Jian Xu","Peng Hu","Haikun Qi"],"pdf_url":"https://arxiv.org/pdf/2507.21625v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.01585v2","updated":"2025-09-09T08:30:59Z","published":"2025-04-02T10:41:49Z","title":"Nonlinear Bandwidth and Bode Diagrams based on Scaled Relative Graphs","summary":"  Scaled Relative Graphs (SRGs) provide a novel graphical frequency-domain\nmethod for the analysis of Nonlinear (NL) systems. In this paper, we restrict\nthe SRG to particular input spaces to compute frequency-dependent incremental\ngain bounds for nonlinear systems. This leads to a NL generalization of the\nBode diagram, where the sinusoidal, harmonic, and subharmonic inputs are\nconsidered separately. When applied to the analysis of the NL loop transfer and\nsensitivity, we define a notion of bandwidth for both the open-loop and\nclosed-loop, compatible with the Linear Time-Invariant (LTI) definitions. We\nillustrate the power of our method on the analysis of a DC motor with a\nparasitic nonlinearity and verify our results in simulations.\n","authors":["Julius P. J. Krebbekx","Roland Tóth","Amritam Das"],"pdf_url":"https://arxiv.org/pdf/2504.01585v2.pdf","comment":"8 pages, accepted for CDC 2025"},{"id":"http://arxiv.org/abs/2509.07464v1","updated":"2025-09-09T07:43:10Z","published":"2025-09-09T07:43:10Z","title":"Safe and Non-Conservative Contingency Planning for Autonomous Vehicles\n  via Online Learning-Based Reachable Set Barriers","summary":"  Autonomous vehicles must navigate dynamically uncertain environments while\nbalancing the safety and driving efficiency. This challenge is exacerbated by\nthe unpredictable nature of surrounding human-driven vehicles (HVs) and\nperception inaccuracies, which require planners to adapt to evolving\nuncertainties while maintaining safe trajectories. Overly conservative planners\ndegrade driving efficiency, while deterministic approaches may encounter\nserious issues and risks of failure when faced with sudden and unexpected\nmaneuvers. To address these issues, we propose a real-time contingency\ntrajectory optimization framework in this paper. By employing event-triggered\nonline learning of HV control-intent sets, our method dynamically quantifies\nmulti-modal HV uncertainties and refines the forward reachable set (FRS)\nincrementally. Crucially, we enforce invariant safety through FRS-based barrier\nconstraints that ensure safety without reliance on accurate trajectory\nprediction of HVs. These constraints are embedded in contingency trajectory\noptimization and solved efficiently through consensus alternative direction\nmethod of multipliers (ADMM). The system continuously adapts to the\nuncertainties in HV behaviors, preserving feasibility and safety without\nresorting to excessive conservatism. High-fidelity simulations on highway and\nurban scenarios, as well as a series of real-world experiments demonstrate\nsignificant improvements in driving efficiency and passenger comfort while\nmaintaining safety under uncertainty. The project page is available at\nhttps://pathetiue.github.io/frscp.github.io/.\n","authors":["Rui Yang","Lei Zheng","Shuzhi Sam Ge","Jun Ma"],"pdf_url":"https://arxiv.org/pdf/2509.07464v1.pdf","comment":"16 pages, 13 figures"},{"id":"http://arxiv.org/abs/2405.15454v3","updated":"2025-09-09T07:03:01Z","published":"2024-05-24T11:30:44Z","title":"Linearly Controlled Language Generation with Performative Guarantees","summary":"  The increasing prevalence of Large Language Models (LMs) in critical\napplications highlights the need for controlled language generation strategies\nthat are not only computationally efficient but that also enjoy performance\nguarantees. To achieve this, we use a common model of concept semantics as\nlinearly represented in an LM's latent space. In particular, we take the view\nthat natural language generation traces a trajectory in this continuous\nsemantic space, realized by the language model's hidden activations. This view\npermits a control-theoretic treatment of text generation in latent space, in\nwhich we propose a lightweight, gradient-free intervention that dynamically\nsteers trajectories away from regions corresponding to undesired meanings. In\nparticular, we propose to directly intervene the activations of the token that\nis being generated in embedding space in an online fashion. Crucially, we do\nnot simply steer activations towards a desirable region. Instead, our method\nrelies on classical techniques from control theory to precisely control\nactivations in a context-dependent way, and guarantees that they are brought\ninto a specific pre-defined region of embedding space that corresponds to\nallowed semantics. Our intervention is computed in closed-form according to an\noptimal controller formulation, minimally impacting generation time. This\ncontrol of the activations in embedding space allows for fine-grained steering\nof attributes of the generated sequence. We demonstrate the effectiveness of\nour approach on different objectives -- toxicity avoidance and sentiment\ncontrol -- while maintaining text quality.\n","authors":["Emily Cheng","Carmen Amo Alonso"],"pdf_url":"https://arxiv.org/pdf/2405.15454v3.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2509.07402v1","updated":"2025-09-09T05:30:43Z","published":"2025-09-09T05:30:43Z","title":"Electric Vehicle Routing Problem with Time Windows and Station-based or\n  Route-based Charging Options","summary":"  The Electric Vehicle Routing Problem with Time Windows and Station-based or\nRoute-based Charging Options addresses fleet optimization incorporating both\nconventional charging stations and continuous wireless charging infrastructure.\nThis paper extends Schneider et al.'s foundational EVRP-TW model with arc-based\ndynamic wireless charging representation, partial coverage modeling, and\nhierarchical multi-objective optimization prioritizing fleet minimization.\nComputational experiments on Schneider benchmark instances demonstrate\nsubstantial operational benefits, with distance and time improvements ranging\nfrom 0.7% to 35.9% in secondary objective components. Analysis reveals that 20%\nwireless coverage achieves immediate benefits, while 60% coverage delivers\noptimal performance across all test instances for infrastructure investment\ndecisions.\n","authors":["Tran Trung Duc","Vu Duc Minh","Nguyen Ngoc Doanh","Pham Gia Nguyen","Laurent El Ghaoui","Ha Minh Hoang"],"pdf_url":"https://arxiv.org/pdf/2509.07402v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07400v1","updated":"2025-09-09T05:29:00Z","published":"2025-09-09T05:29:00Z","title":"A smart fridge with AI-enabled food computing","summary":"  The Internet of Things (IoT) plays a crucial role in enabling seamless\nconnectivity and intelligent home automation, particularly in food management.\nBy integrating IoT with computer vision, the smart fridge employs an ESP32-CAM\nto establish a monitoring subsystem that enhances food management efficiency\nthrough real-time food detection, inventory tracking, and temperature\nmonitoring. This benefits waste reduction, grocery planning improvement, and\nhousehold consumption optimization. In high-density inventory conditions,\ncapturing partial or layered images complicates object detection, as\noverlapping items and occluded views hinder accurate identification and\ncounting. Besides, varied angles and obscured details in multi-layered setups\nreduce algorithm reliability, often resulting in miscounts or\nmisclassifications. Our proposed system is structured into three core modules:\ndata pre-processing, object detection and management, and a web-based\nvisualization. To address the challenge of poor model calibration caused by\noverconfident predictions, we implement a variant of focal loss that mitigates\nover-confidence and under-confidence in multi-category classification. This\napproach incorporates adaptive, class-wise error calibration via temperature\nscaling and evaluates the distribution of predicted probabilities across\nmethods. Our results demonstrate that robust functional calibration\nsignificantly improves detection reliability under varying lighting conditions\nand scalability challenges. Further analysis demonstrates a practical,\nuser-focused approach to modern food management, advancing sustainable living\ngoals through reduced waste and more informed consumption.\n","authors":["Khue Nong Thuc","Khoa Tran Nguyen Anh","Tai Nguyen Huy","Du Nguyen Hao Hong","Khanh Dinh Ba"],"pdf_url":"https://arxiv.org/pdf/2509.07400v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.15031v2","updated":"2025-09-09T05:12:08Z","published":"2025-07-20T16:32:51Z","title":"Safety Controller Synthesis for Stochastic Networked Systems under\n  Communication Constraints","summary":"  This paper develops a framework for synthesizing safety controllers for\ndiscrete-time stochastic linear control systems (dt-SLS) operating under\ncommunication imperfections. The control unit is remote and communicates with\nthe sensor and actuator through an imperfect wireless network. We consider a\nconstant delay in the sensor-to-controller channel (uplink), and data loss in\nboth sensor-to-controller and controller-to-actuator (downlink) channels. In\nour proposed scheme, data loss in each channel is modeled as an independent\nBernoulli-distributed random process. To systematically handle the uplink\ndelay, we first introduce an augmented discrete-time stochastic linear system\n(dt-ASLS) by concatenating all states and control inputs that sufficiently\nrepresent the state-input evolution of the original dt-SLS under the delay and\npacket loss constraints. We then leverage control barrier certificates for\ndt-ASLS to synthesize a controller that ensures the stochastic safety of\ndt-SLS, guaranteeing that all trajectories remain outside unsafe regions with a\nquantified probabilistic bound. Our approach translates safety constraints into\nmatrix inequalities, leading to an optimization problem that eventually\nquantifies the probability of satisfying the safety specification in the\npresence of communication imperfections. We validate our results on an RLC\ncircuit subject to both constant delay and probabilistic data loss.\n","authors":["Omid Akbarzadeh","Mohammad H. Mamduhi","Abolfazl Lavaei"],"pdf_url":"https://arxiv.org/pdf/2507.15031v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07384v1","updated":"2025-09-09T04:25:17Z","published":"2025-09-09T04:25:17Z","title":"Adaptive Event-Triggered MPC for Linear Parameter-Varying Systems with\n  State Delays, Actuator Saturation and Disturbances","summary":"  This paper proposes a unified adaptive event-triggered model predictive\ncontrol (ETMPC) scheme for linear parameter-varying (LPV) systems subject to\nstate delays, actuator saturation, and external disturbances. In existing\nstudies, only a limited number of ETMPC methods have attempted to address\neither state delays or actuator saturation, and even these few methods\ntypically lack co-design optimization between adaptive event-triggering\nmechanisms and the control law. To overcome these limitations, this paper\npresents a Lyapunov-Krasovskii-based adaptive ETMPC strategy that enables the\nco-design optimization of both the triggering mechanism and the controller.\nSpecifically, the event-triggering parameter matrix is adaptively optimized by\nembedding an internal adaptive variable within the Lyapunov-Krasovskii-like\nfunction. Furthermore, the actuator saturation nonlinearity is transformed into\na convex hull representation. The infinite-horizon robust optimization problem\nis reformulated as a convex optimization problem with linear matrix inequality\n(LMI) constraints. Invariant set constraints are introduced to ensure recursive\nfeasibility, and mean-square input-to-state stability (ISS) under multiple\nuncertainties is rigorously established. Simulations on an industrial electric\nheating system validate the proposed method's effectiveness in reducing\ncommunication load.\n","authors":["Aiping Zhong","Wanlin Lu","Langwen Zhang","Ziyang Bao"],"pdf_url":"https://arxiv.org/pdf/2509.07384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.17325v4","updated":"2025-09-09T04:15:09Z","published":"2025-07-23T08:50:18Z","title":"Grid impedance estimation based Kalman Filter","summary":"  Modern power systems face new operational hurdles due to the increasing\nadoption of inverter-coupled distributed energy resources, which impact system\nstability and control. Central to these challenges is the dynamic nature of\ngrid impedance. To address this, a novel real-time estimation algorithm based\non the Discrete Fourier Transform is proposed. This algorithm is embedded\nwithin an Advanced Angle Estimation Kalman Filter framework that employs a\nLinear Quadratic Regulator for current control (AAEKF-LQR). The impedance data\ndirectly informs and refines the controller's phase angle estimation.\nSimulation analyses demonstrate robust collaboration between the estimator and\ncontroller, sustaining system stability under weak grid conditions. The\ntechnique proves capable of delivering swift and accurate impedance updates\nduring grid variations, which is crucial for maintaining stable inverter\noperation\n","authors":["Phuoc Sang Nguyen","Ghavameddin Nourbakhsh","Gerard Ledwich"],"pdf_url":"https://arxiv.org/pdf/2507.17325v4.pdf","comment":"This paper has been withdrawn by the author because it does not\n  include grid voltage estimation, which is essential for accurate grid\n  impedance estimation. Additional validation and the application of\n  appropriate methods for grid voltage estimation are required before the work\n  can be finalised"},{"id":"http://arxiv.org/abs/2509.07356v1","updated":"2025-09-09T03:06:27Z","published":"2025-09-09T03:06:27Z","title":"Anti-Disturbance Hierarchical Sliding Mode Controller for Deep-Sea\n  Cranes with Adaptive Control and Neural Network Compensation","summary":"  To address non-linear disturbances and uncertainties in complex marine\nenvironments, this paper proposes a disturbance-resistant controller for\ndeep-sea cranes. The controller integrates hierarchical sliding mode control,\nadaptive control, and neural network compensation techniques. By designing a\nglobal sliding mode surface, the dynamic coordination between the driving and\nnon-driving subsystems is achieved, ensuring overall system stability. The\nsubsystem surfaces reduce oscillations and enhance tracking accuracy. Adaptive\ncontrol dynamically adjusts system parameters, enhancing robustness against\nexternal uncertainties, while the neural network compensates for time-varying\ndisturbances through real-time learning. The stability of the control scheme is\nverified on the basis of Lyapunov theory. The simulation results demonstrate\nthat, compared to traditional PID control, the proposed controller exhibits\nsignificant advantages in trajectory tracking accuracy, response speed, and\ndisturbance rejection.\n","authors":["Qian Zuo","Shujie Wu","Yuzhe Qian"],"pdf_url":"https://arxiv.org/pdf/2509.07356v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07345v1","updated":"2025-09-09T02:47:13Z","published":"2025-09-09T02:47:13Z","title":"Distributed Frequency Control for Multi-Area Power Systems Considering\n  Transient Frequency Safety","summary":"  High penetration of renewable energy sources intensifies frequency\nfluctuations in multi-area power systems, challenging both stability and\noperational safety. This paper proposes a novel distributed frequency control\nmethod that ensures transient frequency safety and enforces generation capacity\nconstraints, while achieving steady-state frequency restoration and optimal\neconomic operation. The method integrates a feedback optimization (FO)-based\ncontroller and a safety corrector. The FO-based controller generates reference\nsetpoints by solving an optimization problem, driving the system to the steady\nstate corresponding to the optimal solution of this problem. The safety\ncorrector then modifies these references using control barrier functions to\nmaintain frequencies within prescribed safe bounds during transients while\nrespecting capacity constraints. The proposed method combines low computational\nburden with improved regulation performance and enhanced practical\napplicability. Theoretical analysis establishes optimality, asymptotic\nstability, and transient frequency safety for the closed-loop system.\nSimulation studies show that, compared with conventional FO-based schemes, the\nmethod consistently enforces frequency safety and capacity limits, achieves\nsmaller frequency deviations and faster recovery, thereby demonstrating its\npractical effectiveness and advantages.\n","authors":["Xiemin Mo","Tao Liu"],"pdf_url":"https://arxiv.org/pdf/2509.07345v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07320v1","updated":"2025-09-09T01:40:26Z","published":"2025-09-09T01:40:26Z","title":"Data-knowledge fusion driven frequency security assessment: A robust\n  framework for renewable-dominated power grids","summary":"  Frequency security is critical for power grids, as deviations can trigger\nwidespread outages and result in substantial economic losses. However, modern\nrenewable-dominated power grids face an increased risk of insecurity due to low\ninertia and nonlinear frequency responses. To mitigate these risks, robust\npre-fault frequency security assessment (FSA) is critical, which enables grid\noperators to implement preventive control strategies. We propose a\ndata-knowledge fusion framework to achieve intelligent FSA in actual power\ngrids. First, we classify FSA domain knowledge into two distinct categories:\n(1) physics-guided knowledge directs the neural network pre-training process,\nensuring that the fusion model's predictions consistent with frequency response\nmechanisms, and (2) physics-constrained knowledge establishes quantitative\nrelationship on predictions, which forces them within theoretical ranges\ndefined by domain knowledge. Furthermore, we develop a dual-channel neural\nnetwork architecture to simultaneously capture both local and global\ncharacteristics of the power system. Finally, we introduce a data-knowledge\nfusion training algorithm that integrates guided learning with constrained\nnetwork architecture to enhance model reliability and generalization. Case\nstudies on China's Yunnan Provincial Power Grid validate the superior\nperformance of our framework: it reduces average prediction error to 1.26% (a\n49.2% reduction over data-driven methods), and maintains 97.60% accuracy in\nuntrained scenarios (3.85% higher than data-driven methods), therefore\nsatisfies the accuracy, reliability, and generalization requirements for actual\npower grids. The proposed methodology establishes a new paradigm for enhancing\nrobustness of FSA in power grids, with potential application to cross-domain\nsecurity assessment.\n","authors":["Yurun Zhang","Wei Yao","Yutian Lan","Hang Shuai","Shanyang Wei","Wei Gan","Chao Duan","Jinyu Wen","Shijie Cheng"],"pdf_url":"https://arxiv.org/pdf/2509.07320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07304v1","updated":"2025-09-09T00:36:11Z","published":"2025-09-09T00:36:11Z","title":"Distributed Leader-Follower Consensus for Uncertain Multiagent Systems\n  with Time-Triggered Switching of the Communication Network","summary":"  A distributed adaptive control strategy is developed for heterogeneous\nmultiagent systems in nonlinear Brunovsky form with \\({\\pd}\\)-dimensional\n$n^{\\text{th}}$-order dynamics, operating under time-triggered switching\ncommunication topologies. The approach uses repulsive potential functions to\nensure agent-agent and obstacle safety, while neural network estimators\ncompensate for system uncertainties and disturbances. A high-order control\nbarrier function framework is then employed to certify the positive invariance\nof the safe sets and the boundedness of the proposed control inputs. The\nresulting distributed control and adaptive laws, together with dwell-time\nrequirements for topology transitions, achieve leader-following consensus. This\nintegrated design provides synchronized formation and robust disturbance\nrejection in evolving network configurations, and its effectiveness is\ndemonstrated through numerical simulations.\n","authors":["Armel Koulong","Ali Pakniyat"],"pdf_url":"https://arxiv.org/pdf/2509.07304v1.pdf","comment":"Joint submission paper MECC-JDSMC. Accepted for the 2025 Modeling,\n  Estimation and Control Conference (MECC). Currently under review by the ASME\n  Journal of Dynamic Systems, Measurement, and Control (JDSMC)"},{"id":"http://arxiv.org/abs/2509.08166v1","updated":"2025-09-09T22:00:56Z","published":"2025-09-09T22:00:56Z","title":"A Linear Pricing Mechanism for Load Management in Day-Ahead Retail\n  Energy Markets","summary":"  Regulators and utilities have been exploring hourly retail electricity\npricing, with several existing programs providing day-ahead hourly pricing\nschedules. At the same time, customers are deploying distributed energy\nresources and smart energy management systems that have significant flexibility\nand can optimally follow price signals. In aggregate, these optimally\ncontrolled loads can create congestion management issues for distribution\nsystem operators (DSOs). In this paper, we describe a new linear pricing\nmechanism for day-ahead retail electricity pricing that provides a signal for\ncustomers to follow to mitigate over-consumption while still consuming energy\nat hours that are preferential for system performance. We show that by\nbroadcasting a linear price designed for price-signal control of\ncost-optimizing loads, we can shape customer load profiles to provide\ncongestion management without the need for bi-directional communication or\ncustomer bidding programs.\n","authors":["Phillippe K. Phanivong","Duncan S. Callaway"],"pdf_url":"https://arxiv.org/pdf/2509.08166v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08152v1","updated":"2025-09-09T21:26:20Z","published":"2025-09-09T21:26:20Z","title":"EnergyNet Explained: Internetification of Energy Distribution","summary":"  In developing EnergyNet we have leveraged and are extending lessons from\ntelecom's shift from a centralized, circuit-switched phone system to\ndecentralized, packet-switched data networks. EnergyNet utilizes 1) an Energy\nRouter that enforces galvanic separation and utilizes software-controlled\nenergy flows over a DC backplane, 2) Energy Local and Wide Area Networks\n(ELAN/EWAN) based on DC microgrids that interconnect through an open Energy\nProtocol (EP), and 3) a control plane comprised of the Energy Router Operating\nSystem (EROS) and EP Server which is managed at operator scale through an\nEnergy Network Management System (ENMS). We distinguish the architectural\ncontribution (Tier-1 including components, interfaces, and operating model)\nfrom expected outcomes contingent on adoption (Tier-2). The latter includes\nlocal-first autonomy with global interoperability, near-real-time operation\nwith local buffering, removal of EV-charging bottlenecks, freed grid capacity\nfor data centers and industrial electrification, as well as a trend toward low,\npredictable, fixed-cost clean energy. Evidence from early municipal\ndemonstrators illustrates feasibility and migration paths. The contribution is\na coherent, open, and testable blueprint for software-defined, decentralized\nenergy distribution, aligning power-systems engineering with networking\nprinciples and offering a practical route from legacy, synchronous grids to\nresilient, digitally routed energy distribution systems.\n","authors":["Jonas Birgersson","Marc A. Weiss","Jimmy Chen","Daniel Kammen","Tomas Kåberger","Franklin Carrero-Martínez","Joakim Wernberg","Michael Menser","Newsha K. Ajami"],"pdf_url":"https://arxiv.org/pdf/2509.08152v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08135v1","updated":"2025-09-09T20:38:00Z","published":"2025-09-09T20:38:00Z","title":"Admission Control for Inelastic Traffic on a Link Shared by\n  Deadline-Driven Elastic Traffic","summary":"  Consider a (logical) link between two distributed data centers with available\nbandwidth designated for both deadline-driven elastic traffic, such as for\nscheduled synchronization services, and profitable inelastic traffic, such as\nfor real-time streaming services. Admission control in this setting is cast as\na stochastic shortest path problem, with state space derived from\n(discretization of) the elastic flow's size/deadline and action space\ncorresponding to alternative subsets of admitted inelastic flows: the\nprobabilistic model expresses uncertainty in both the link's available\nbandwidth and the inelastic flows' offered loads, while the objective function\ncaptures both congestion avoidance and the option to specify a desired minimum\nelastic rate. Its solution is shown to (i) balance the accumulation of\ninstantaneous inelastic reward with the risk of missing the elastic deadline\nand (ii) exhibit a degree of robustness to link & flow modeling errors that is\ntunable via choice of the desired minimum elastic rate. Also discussed are\nstate augmentations that befit urgent or non-interruptible inelastic traffic.\n","authors":["Patrick Kreidl"],"pdf_url":"https://arxiv.org/pdf/2509.08135v1.pdf","comment":"21 pages, 12 figures, unpublished/rejected manuscript circa 2018"},{"id":"http://arxiv.org/abs/2509.08124v1","updated":"2025-09-09T20:05:26Z","published":"2025-09-09T20:05:26Z","title":"UTM Performance Under Stressing Scenarios","summary":"  Proliferation of new classes of airspace participants, including uncrewed and\nadvanced aerial mobility vehicles, necessitates the development and deployment\nof novel airspace management solutions, such as the Unmanned Traffic Management\n(UTM) system and the Provider of Services to UAM (PSU) Network. The efficacy of\nsuch systems has been demonstrated on multiple occasions via real-world\ndeployments in limited test environments, however exploration of system\nbehavior under stressing conditions requires the development of appropriate\nmodeling and simulation (M&S) environments. Autonomy Networks for Advanced\nMobility at Lincoln Laboratory (ANAMLL) is a virtual Systems Integration\nLaboratory (SIL) designed to host federated autonomy networks, such as a UTM or\nPSU Network, and to enable test and validation at scales not available in\nreal-world deployments. As an example of ANAMLL's utility, we explore the\nperformance of a representative UTM network during a stressing demand scenario.\nIn a close examination of the demand scenario, ANAMLL demonstrates a UTM system\ndemand point at which in-flight replanning can no longer be accomplished within\nan allowable time window. In a second analysis of the same scenario, ANAMLL\ndemonstrates the impact of network connectivity performance on end-user\nairspace access.\n","authors":["Ian Jessen"],"pdf_url":"https://arxiv.org/pdf/2509.08124v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08117v1","updated":"2025-09-09T19:46:21Z","published":"2025-09-09T19:46:21Z","title":"Online Learning and Coverage of Unknown Fields Using Random-Feature\n  Gaussian Processes","summary":"  This paper proposes a framework for multi-robot systems to perform\nsimultaneous learning and coverage of the domain of interest characterized by\nan unknown and potentially time-varying density function. To overcome the\nlimitations of Gaussian Process (GP) regression, we employ Random Feature GP\n(RFGP) and its online variant (O-RFGP) that enables online and incremental\ninference. By integrating these with Voronoi-based coverage control and Upper\nConfidence Bound (UCB) sampling strategy, a team of robots can adaptively focus\non important regions while refining the learned spatial field for efficient\ncoverage. Under mild assumptions, we provide theoretical guarantees and\nevaluate the framework through simulations in time-invariant scenarios.\nFurthermore, its effectiveness in time-varying settings is demonstrated through\nadditional simulations and a physical experiment.\n","authors":["Ruijie Du","Ruoyu Lin","Yanning Shen","Magnus Egerstedt"],"pdf_url":"https://arxiv.org/pdf/2509.08117v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08085v1","updated":"2025-09-09T18:43:19Z","published":"2025-09-09T18:43:19Z","title":"Planar Juggling of a Devil-Stick using Discrete VHCs","summary":"  Planar juggling of a devil-stick using impulsive inputs is addressed using\nthe concept of discrete virtual holonomic constraints (DVHC). The location of\nthe center-of-mass of the devil-stick is specified in terms of its orientation\nat the discrete instants when impulsive control inputs are applied. The\ndiscrete zero dynamics (DZD) resulting from the choice of DVHC provides\nconditions for stable juggling. A control design that enforces the DVHC and an\norbit stabilizing controller are presented. The approach is validated in\nsimulation.\n","authors":["Aakash Khandelwal","Ranjan Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2509.08085v1.pdf","comment":"7 pages, 4 figures"}],"Hardware Architecture":[{"id":"http://arxiv.org/abs/2504.03732v3","updated":"2025-09-09T17:18:28Z","published":"2025-03-31T23:36:26Z","title":"SAGe: A Lightweight Algorithm-Architecture Co-Design for Mitigating the\n  Data Preparation Bottleneck in Large-Scale Genome Sequence Analysis","summary":"  Genome sequence analysis, which analyzes the DNA sequences of organisms,\ndrives advances in many critical medical and biotechnological fields. Given its\nimportance and the exponentially growing volumes of genomic sequence data,\nthere are extensive efforts to accelerate genome sequence analysis. In this\nwork, we demonstrate a major bottleneck that greatly limits and diminishes the\nbenefits of state-of-the-art genome sequence analysis accelerators: the data\npreparation bottleneck, where genomic sequence data is stored in compressed\nform and needs to be decompressed and formatted first before an accelerator can\noperate on it. To mitigate this bottleneck, we propose SAGe, an\nalgorithm-architecture co-design for highly-compressed storage and\nhigh-performance access of large-scale genomic sequence data. The key challenge\nis to improve data preparation performance while maintaining high compression\nratios (comparable to genomic-specific compression algorithms) at low hardware\ncost. We address this challenge by leveraging key properties of genomic\ndatasets to co-design (i) a new (de)compression algorithm, (ii) hardware that\ndecompresses data with lightweight operations and efficient streaming accesses,\n(iii) storage data layout, and (iv) interface commands to access data. SAGe is\nhighly versatile as it supports datasets from different sequencing technologies\nand species. Thanks to its lightweight design, SAGe can be seamlessly\nintegrated with a broad range of genome sequence analysis hardware accelerators\nto mitigate their data preparation bottlenecks. Our results demonstrate that\nSAGe improves the average end-to-end performance and energy efficiency of two\nstate-of-the-art genome sequence analysis accelerators by 3.0x-32.1x and\n13.0x-34.0x, respectively, compared to when the accelerators rely on\nstate-of-the-art decompression tools.\n","authors":["Nika Mansouri Ghiasi","Talu Güloglu","Harun Mustafa","Can Firtina","Konstantina Koliogeorgi","Konstantinos Kanellopoulos","Haiyu Mao","Rakesh Nadig","Mohammad Sadrosadati","Jisung Park","Onur Mutlu"],"pdf_url":"https://arxiv.org/pdf/2504.03732v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07690v1","updated":"2025-09-09T12:55:44Z","published":"2025-09-09T12:55:44Z","title":"HYLU: Hybrid Parallel Sparse LU Factorization","summary":"  This article introduces HYLU, a hybrid parallel LU factorization-based\ngeneral-purpose solver designed for efficiently solving sparse linear systems\n(Ax=b) on multi-core shared-memory architectures. The key technical feature of\nHYLU is the integration of hybrid numerical kernels so that it can adapt to\nvarious sparsity patterns of coefficient matrices. Tests on 34 sparse matrices\nfrom SuiteSparse Matrix Collection reveal that HYLU outperforms Intel MKL\nPARDISO in the numerical factorization phase by geometric means of 1.74X (for\none-time solving) and 2.26X (for repeated solving). HYLU can be downloaded from\nhttps://github.com/chenxm1986/hylu.\n","authors":["Xiaoming Chen"],"pdf_url":"https://arxiv.org/pdf/2509.07690v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.18330v2","updated":"2025-09-09T08:05:54Z","published":"2024-11-27T13:29:29Z","title":"QUADOL: A Quality-Driven Approximate Logic Synthesis Method Exploiting\n  Dual-Output LUTs for Modern FPGAs","summary":"  Approximate computing is a new computing paradigm. One important area of it\nis designing approximate circuits for FPGA. Modern FPGAs support dual-output\nLUT, which can significantly reduce the area of FPGA designs. Several existing\nworks explored the use of dual-output in approximate computing. However, they\nare limited to small-scale arithmetic circuits. To address the problem, this\nwork proposes QUADOL, a quality-driven ALS method by exploiting dual-output\nLUTs for modern FPGAs. We propose a technique to approximately merge two\nsingle-output LUTs (i.e., a LUT pair) into a dual-output LUT. In addition, we\ntransform the problem of selecting multiple LUT pairs for simultaneous\napproximate merging into a maximum matching problem to maximize the area\nreduction. Since QUADOL exploits a new dimension, i.e., approximately merging a\nLUT pair into a dual-output LUT, it can be integrated with any existing ALS\nmethods to strengthen them. Therefore, we also introduce QUADOL+, which is a\ngeneric framework to integrate QUADOL into existing ALS methods. The\nexperimental results showed that QUADOL+ can reduce the LUT count by up to 18%\ncompared to the state-of-the-art ALS methods for FPGA. Moreover, the\napproximate multipliers optimized by QUADOL+ dominate most prior FPGA-based\napproximate multipliers in the area-error plane.\n","authors":["Jian Shi","Xuan Wang","Chang Meng","Weikang Qian"],"pdf_url":"https://arxiv.org/pdf/2411.18330v2.pdf","comment":"The work will be incorporated into a larger project and will undergo\n  significant revisions. As such, it will be resubmitted as part of a new\n  paper. Thank you for your understanding"},{"id":"http://arxiv.org/abs/2509.07378v1","updated":"2025-09-09T03:57:04Z","published":"2025-09-09T03:57:04Z","title":"Optimizing Task Scheduling in Fog Computing with Deadline Awareness","summary":"  The rise of Internet of Things (IoT) devices has led to the development of\nnumerous applications that require quick responses and low latency. Fog\ncomputing has emerged as a solution for processing these IoT applications, but\nit faces challenges such as resource allocation and job scheduling. Therefore,\nit is crucial to determine how to assign and schedule tasks on Fog nodes. A\nwell-designed job scheduling algorithm can help decrease energy usage and\nimprove response times for application requests. This work aims to schedule\ntasks in IoT while minimizing the total energy consumption of nodes and\nenhancing the Quality of Service (QoS) requirements of IoT tasks, taking into\naccount task deadlines. Initially, this paper classifies the Fog nodes into two\ncategories based on their traffic level: low and high. It schedules\nlow-deadline tasks on low-traffic-level nodes using an Improved Golden Eagle\nOptimization (IGEO) algorithm, an enhancement of the Golden Eagle Optimization\nAlgorithm that utilizes genetic operators for discretization. High-deadline\ntasks are processed on high-traffic nodes using reinforcement learning (RL).\nThis combined approach is called the Reinforcement Improved Golden Eagle\nOptimization (RIGEO) algorithm. Experimental results demonstrate that the\nproposed algorithms optimize system response time, total deadline violation\ntime, and resource and system energy consumption compared to other\nstate-of-the-art algorithms.\n","authors":["Mohammad Sadegh Sirjani","Somayeh Sobati-Moghadam"],"pdf_url":"https://arxiv.org/pdf/2509.07378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.01742v2","updated":"2025-09-09T00:15:05Z","published":"2025-09-01T19:49:21Z","title":"BOLT: Bandwidth-Optimized Lightning-Fast Oblivious Map powered by Secure\n  HBM Accelerators","summary":"  While Trusted Execution Environments provide a strong foundation for secure\ncloud computing, they remain vulnerable to access pattern leakages. Oblivious\nMaps (OMAPs) mitigate this by fully hiding access patterns but suffer from high\noverhead due to randomized remapping and worst-case padding. We argue these\ncosts are not fundamental. Modern accelerators featuring High-Bandwidth Memory\n(HBM) offer a new opportunity: Vaswani et al. [OSDI'18] point out that\neavesdropping on HBM is difficult -- even for physical attackers -- as its\nmemory channels are sealed together with processor cores inside the same\nphysical package. Later, Hunt et al. [NSDI'20] show that, with proper\nisolation, HBM can be turned into an unobservable region where both data and\nmemory traces are hidden. This motivates a rethink of OMAP design with\nHBM-backed solutions to finally overcome their traditional performance limits.\nBuilding on these insights, we present BOLT, a Bandwidth Optimized,\nLightning-fast OMAP accelerator that, for the first time, achieves O(1) +\nO(log_2(log_2 (N))) bandwidth overhead. BOLT introduces three key innovations:\n(i) a new OMAP algorithm that leverages isolated HBM as an unobservable cache\nto accelerate oblivious access to large host memory; (ii) a self-hosted\narchitecture that offloads execution and memory control from the host to\nmitigate CPU-side leakage; and (iii) tailored algorithm-architecture co-designs\nthat maximize resource efficiency. We implement a prototype BOLT on a Xilinx\nU55C FPGA. Evaluations show that BOLT achieves up to 279x and 480x speedups in\ninitialization and query time, respectively, over state-of-the-art OMAPs,\nincluding an industry implementation from Facebook.\n","authors":["Yitong Guo","Hongbo Chen","Haobin Hiroki Chen","Yukui Luo","XiaoFeng Wang","Chenghong Wang"],"pdf_url":"https://arxiv.org/pdf/2509.01742v2.pdf","comment":"Accepted by CCS 2025"},{"id":"http://arxiv.org/abs/2509.08193v1","updated":"2025-09-09T23:53:46Z","published":"2025-09-09T23:53:46Z","title":"Lifetime-Aware Design of Item-Level Intelligence","summary":"  We present FlexiFlow, a lifetime-aware design framework for item-level\nintelligence (ILI) where computation is integrated directly into disposable\nproducts like food packaging and medical patches. Our framework leverages\nnatively flexible electronics which offer significantly lower costs than\nsilicon but are limited to kHz speeds and several thousands of gates. Our\ninsight is that unlike traditional computing with more uniform deployment\npatterns, ILI applications exhibit 1000X variation in operational lifetime,\nfundamentally changing optimal architectural design decisions when considering\ntrillion-item deployment scales. To enable holistic design and optimization, we\nmodel the trade-offs between embodied carbon footprint and operational carbon\nfootprint based on application-specific lifetimes. The framework includes: (1)\nFlexiBench, a workload suite targeting sustainability applications from\nspoilage detection to health monitoring; (2) FlexiBits, area-optimized RISC-V\ncores with 1/4/8-bit datapaths achieving 2.65X to 3.50X better energy\nefficiency per workload execution; and (3) a carbon-aware model that selects\noptimal architectures based on deployment characteristics. We show that\nlifetime-aware microarchitectural design can reduce carbon footprint by 1.62X,\nwhile algorithmic decisions can reduce carbon footprint by 14.5X. We validate\nour approach through the first tape-out using a PDK for flexible electronics\nwith fully open-source tools, achieving 30.9kHz operation. FlexiFlow enables\nexploration of computing at the Extreme Edge where conventional design\nmethodologies must be reevaluated to account for new constraints and\nconsiderations.\n","authors":["Shvetank Prakash","Andrew Cheng","Olof Kindgren","Ashiq Ahamed","Graham Knight","Jed Kufel","Francisco Rodriguez","Arya Tschand","David Kong","Mariam Elgamal","Jerry Huang","Emma Chen","Gage Hills","Richard Price","Emre Ozer","Vijay Janapa Reddi"],"pdf_url":"https://arxiv.org/pdf/2509.08193v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23035v3","updated":"2025-09-09T19:37:20Z","published":"2025-07-30T19:01:25Z","title":"KLLM: Fast LLM Inference with K-Means Quantization","summary":"  Large language model (LLM) inference poses significant challenges due to its\nintensive memory and computation demands. Weight and activation quantization\n(WAQ) offers a promising solution by reducing both memory footprint and\narithmetic complexity. Traditional WAQ designs rely on uniform integer\nquantization for hardware efficiency, but often suffer from significant model\nperformance degradation at low precision. In contrast, K-Means quantization, a\nnon-uniform technique, achieves higher accuracy by aligning with the\nGaussian-like distributions of weights and activations in LLMs. However, two\nkey challenges prevent the efficient deployment of K-Means-based WAQ designs\nfor LLM inference: (1) The non-uniform structure of K-Means-quantized data\nprecludes direct execution on low-precision compute units, necessitating\ndequantization and floating-point matrix multiplications (MatMuls) during\ninference. (2) Activation outliers hinder effective low-precision quantization.\nOffline thresholding methods for outlier detection degrade model performance\nsubstantially, while existing online detection techniques introduce significant\nruntime overhead. To address the aforementioned challenges and fully unleash\nthe potential of K-Means-based WAQ for LLM inference, in this paper, we propose\nKLLM, an LLM inference accelerator for efficient execution with\nK-Means-quantized weights and activations. KLLM features an index-based\ncomputation scheme for efficient execution of MatMuls and nonlinear operations\non K-Means-quantized data, which avoids most of the dequantization and\nfull-precision computations. Moreover, KLLM incorporates a lightweight outlier\ndetection engine, Orizuru, that efficiently identifies the top-$k$ largest and\nsmallest elements in the activation data stream during online inference.\n","authors":["Xueying Wu","Baijun Zhou","Zhihui Gao","Yuzhe Fu","Qilin Zheng","Yintao He","Hai Li"],"pdf_url":"https://arxiv.org/pdf/2507.23035v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08067v1","updated":"2025-09-09T18:08:53Z","published":"2025-09-09T18:08:53Z","title":"Analyzing the capabilities of HLS and RTL tools in the design of an FPGA\n  Montgomery Multiplier","summary":"  We present the analysis of various FPGA design implementations of a\nMontgomery Modular Multiplier, compatible with the BLS12-381 elliptic curve,\nusing the Coarsely Integrated Operand Scanning approach of working with\ncomplete partial products on different digit sizes. The scope of the\nimplemented designs is to achieve a high-frequency, high-throughput solution\ncapable of computing millions of operations per second, which can provide a\nstrong foundation for different Elliptic Curve Cryptography operations such as\npoint addition and point multiplication. One important constraint for our\ndesigns was to only use FPGA DSP primitives for the arithmetic operations\nbetween digits employed in the CIOS algorithm as these primitives, when\npipelined properly, can operate at a high frequency while also relaxing the\nresource consumption of FPGA LUTs and FFs. The target of the analysis is to see\nhow different design choices and tool configurations influence the frequency,\nlatency and resource consumption when working with the latest AMD-Xilinx tools\nand Alveo FPGA boards in an RTL-HLS hybrid approach. We compare three\ncategories of designs: a Verilog naive approach where we rely on the Vivado\nsynthesizer to automatically choose when and where to use DSPs, a Verilog\noptimized approach by manually instantiating the DSP primitives ourselves and a\ncomplete High-Level Synthesis approach. We also compare the FPGA\nimplementations with an optimized software implementation of the same\nMontgomery multiplier written in Rust.\n","authors":["Rares Ifrim","Decebal Popescu"],"pdf_url":"https://arxiv.org/pdf/2509.08067v1.pdf","comment":null}],"Programming Languages":[{"id":"http://arxiv.org/abs/2509.07763v1","updated":"2025-09-09T13:58:46Z","published":"2025-09-09T13:58:46Z","title":"What Were You Thinking? An LLM-Driven Large-Scale Study of Refactoring\n  Motivations in Open-Source Projects","summary":"  Context. Code refactoring improves software quality without changing external\nbehavior. Despite its advantages, its benefits are hindered by the considerable\ncost of time, resources, and continuous effort it demands. Aim. Understanding\nwhy developers refactor, and which metrics capture these motivations, may\nsupport wider and more effective use of refactoring in practice. Method. We\nperformed a large-scale empirical study to analyze developers refactoring\nactivity, leveraging Large Language Models (LLMs) to identify underlying\nmotivations from version control data, comparing our findings with previous\nmotivations reported in the literature. Results. LLMs matched human judgment in\n80% of cases, but aligned with literature-based motivations in only 47%. They\nenriched 22% of motivations with more detailed rationale, often highlighting\nreadability, clarity, and structural improvements. Most motivations were\npragmatic, focused on simplification and maintainability. While metrics related\nto developer experience and code readability ranked highest, their correlation\nwith motivation categories was weak. Conclusions. We conclude that LLMs\neffectively capture surface-level motivations but struggle with architectural\nreasoning. Their value lies in providing localized explanations, which, when\ncombined with software metrics, can form hybrid approaches. Such integration\noffers a promising path toward prioritizing refactoring more systematically and\nbalancing short-term improvements with long-term architectural goals.\n","authors":["Mikel Robredo","Matteo Esposito","Fabio Palomba","Rafael Peñaloza","Valentina Lenarduzzi"],"pdf_url":"https://arxiv.org/pdf/2509.07763v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07609v1","updated":"2025-09-09T11:34:40Z","published":"2025-09-09T11:34:40Z","title":"What's in the Box: Ergonomic and Expressive Capture Tracking over\n  Generic Data Structures (Extended Version)","summary":"  Capturing types in Scala unify static effect and resource tracking with\nobject capabilities, enabling lightweight effect polymorphism with minimal\nnotational overhead. However, their expressiveness has been insufficient for\ntracking capabilities embedded in generic data structures, preventing them from\nscaling to the standard collections library -- an essential prerequisite for\nbroader adoption. This limitation stems from the inability to name capabilities\nwithin the system's notion of box types.\n  This paper develops System Capless, a new foundation for capturing types that\nprovides the theoretical basis for reach capabilities (rcaps), a novel\nmechanism for naming \"what's in the box.\" The calculus refines the universal\ncapability notion into a new scheme with existential and universal capture set\nquantification. Intuitively, rcaps witness existentially quantified capture\nsets inside the boxes of generic types in a way that does not require exposing\nexistential capture types in the surface language. We have fully mechanized the\nformal metatheory of System Capless in Lean, including proofs of type soundness\nand scope safety. System Capless supports the same lightweight notation of\ncapturing types plus rcaps, as certified by a type-preserving translation, and\nalso enables fully optional explicit capture-set quantification to increase\nexpressiveness.\n  Finally, we present a full reimplementation of capture checking in Scala 3\nbased on System Capless and migrate the entire Scala collections library and an\nasynchronous programming library to evaluate its practicality and ergonomics.\nOur results demonstrate that reach capabilities enable the adoption of capture\nchecking in production code with minimal changes and minimal-to-zero notational\noverhead in a vast majority of cases.\n","authors":["Yichen Xu","Oliver Bračevac","Cao Nguyen Pham","Martin Odersky"],"pdf_url":"https://arxiv.org/pdf/2509.07609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07551v1","updated":"2025-09-09T09:41:20Z","published":"2025-09-09T09:41:20Z","title":"Fast and Extensible Hybrid Embeddings with Micros","summary":"  Macro embedding is a popular approach to defining extensible shallow\nembeddings of object languages in Scheme like host languages. While macro\nembedding has even been shown to enable implementing extensible typed languages\nin systems like Racket, it comes at a cost: compile-time performance. In this\npaper, we revisit micros - syntax to intermediate representation (IR)\ntransformers, rather than source syntax to source syntax transformers (macros).\nMicro embedding enables stopping at an IR, producing a deep embedding and\nenabling high performance compile-time functions over an efficient IR, before\nshallowly embedding the IR back into source syntax. Combining micros with\nseveral design patterns to enable the IR and functions over it to be\nextensible, we achieve extensible hybrid embedding of statically typed\nlanguages with significantly improved compile-time compared to macro-embedding\napproaches. We describe our design patterns and propose new abstractions\npackaging these patterns.\n","authors":["Sean Bocirnea","William J. Bowman"],"pdf_url":"https://arxiv.org/pdf/2509.07551v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2509.08182v1","updated":"2025-09-09T23:03:53Z","published":"2025-09-09T23:03:53Z","title":"XML Prompting as Grammar-Constrained Interaction: Fixed-Point Semantics,\n  Convergence Guarantees, and Human-AI Protocols","summary":"  Structured prompting with XML tags has emerged as an effective way to steer\nlarge language models (LLMs) toward parseable, schema-adherent outputs in\nreal-world systems. We develop a logic-first treatment of XML prompting that\nunifies (i) grammar-constrained decoding, (ii) fixed-point semantics over\nlattices of hierarchical prompts, and (iii) convergent human-AI interaction\nloops. We formalize a complete lattice of XML trees under a refinement order\nand prove that monotone prompt-to-prompt operators admit least fixed points\n(Knaster-Tarski) that characterize steady-state protocols; under a task-aware\ncontraction metric on trees, we further prove Banach-style convergence of\niterative guidance. We instantiate these results with context-free grammars\n(CFGs) for XML schemas and show how constrained decoding guarantees\nwell-formedness while preserving task performance. A set of multi-layer\nhuman-AI interaction recipes demonstrates practical deployment patterns,\nincluding multi-pass \"plan $\\to$ verify $\\to$ revise\" routines and agentic tool\nuse. We provide mathematically complete proofs and tie our framework to recent\nadvances in grammar-aligned decoding, chain-of-verification, and programmatic\nprompting.\n","authors":["Faruk Alpay","Taylan Alpay"],"pdf_url":"https://arxiv.org/pdf/2509.08182v1.pdf","comment":"7 pages, multiple XML prompts"}],"Data Structures and Algorithms":[{"id":"http://arxiv.org/abs/2508.03961v2","updated":"2025-09-09T16:50:49Z","published":"2025-08-05T22:54:28Z","title":"Decoupling via Affine Spectral-Independence: Beck-Fiala and Komlós\n  Bounds Beyond Banaszczyk","summary":"  The Beck-Fiala Conjecture [Discrete Appl. Math, 1981] asserts that any set\nsystem of $n$ elements with degree $k$ has combinatorial discrepancy\n$O(\\sqrt{k})$. A substantial generalization is the Koml\\'os Conjecture, which\nstates that any $m \\times n$ matrix with unit length columns has discrepancy\n$O(1)$.\n  In this work, we resolve the Beck-Fiala Conjecture for $k \\geq \\log^2 n$. We\nalso give an $\\widetilde{O}(\\sqrt{k} + \\sqrt{\\log n})$ bound for $k \\leq \\log^2\nn$, where $\\widetilde{O}(\\cdot)$ hides $\\mathsf{poly}(\\log \\log n)$ factors.\nThese bounds improve upon the $O(\\sqrt{k \\log n})$ bound due to Banaszczyk\n[Random Struct. Algor., 1998].\n  For the Komlos problem, we give an $\\widetilde{O}(\\log^{1/4} n)$ bound,\nimproving upon the previous $O(\\sqrt{\\log n})$ bound [Random Struct. Algor.,\n1998]. All of our results also admit efficient polynomial-time algorithms.\n  To obtain these results, we exploit a new technique of ``decoupling via\naffine spectral-independence'' in designing rounding algorithms. In particular,\nour algorithms obtain the desired colorings via a discrete Brownian motion,\nguided by a semidefinite program (SDP). Besides standard constraints used in\nprior works, we add some extra affine spectral-independence constraints, which\neffectively decouple the evolution of discrepancies across different rows, and\nallow us to better control how many rows accumulate large discrepancies at any\npoint during the process. This new technique is quite general and may be of\nindependent interest.\n","authors":["Nikhil Bansal","Haotian Jiang"],"pdf_url":"https://arxiv.org/pdf/2508.03961v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07827v1","updated":"2025-09-09T15:04:42Z","published":"2025-09-09T15:04:42Z","title":"Compressibility Measures and Succinct Data Structures for Piecewise\n  Linear Approximations","summary":"  We study the problem of deriving compressibility measures for \\emph{Piecewise\nLinear Approximations} (PLAs), i.e., error-bounded approximations of a set of\ntwo-dimensional {\\em increasing} data points using a sequence of segments. Such\napproximations are widely used tools in implementing many \\emph{learned data\nstructures}, which mix learning models with traditional algorithmic design\nblocks to exploit regularities in the underlying data distribution, providing\nnovel and effective space-time trade-offs.\n  We introduce the first lower bounds to the cost of storing PLAs in two\nsettings, namely {\\em compression} and {\\em indexing}. We then compare these\ncompressibility measures to known data structures, and show that they are\nasymptotically optimal up to a constant factor from the space lower bounds.\nFinally, we design the first data structures for the aforementioned settings\nthat achieve the space lower bounds plus small additive terms, which turn out\nto be {\\em succinct} in most practical cases. Our data structures support the\nefficient retrieval and evaluation of a segment in the (compressed) PLA for a\ngiven $x$-value, which is a core operation in any learned data structure\nrelying on PLAs.\n  As a result, our paper offers the first theoretical analysis of the maximum\ncompressibility achievable by PLA-based learned data structures, and provides\nnovel storage schemes for PLAs offering strong theoretical guarantees while\nalso suggesting simple and efficient practical implementations.\n","authors":["Paolo Ferragina","Filippo Lari"],"pdf_url":"https://arxiv.org/pdf/2509.07827v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.11107v3","updated":"2025-09-09T14:33:35Z","published":"2025-03-14T05:59:30Z","title":"Discrete Effort Distribution via Regret-enabled Greedy Algorithm","summary":"  This paper addresses resource allocation problem with a separable objective\nfunction under a single linear constraint, formulated as maximizing\n$\\sum_{j=1}^{n}R_j(x_j)$ subject to $\\sum_{j=1}^{n}x_j=k$ and\n$x_j\\in\\{0,\\dots,m\\}$. While classical dynamic programming approach solves this\nproblem in $O(n^2m^2)$ time, we propose a regret-enabled greedy algorithm that\nachieves $O(n\\log n)$ time when $m=O(1)$. The algorithm significantly\noutperforms traditional dynamic programming for small $m$. Our algorithm\nactually solves the problem for all $k~(0\\leq k\\leq nm)$ in the mentioned time.\n","authors":["Song Cao","Taikun Zhu","Kai Jin"],"pdf_url":"https://arxiv.org/pdf/2503.11107v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07732v1","updated":"2025-09-09T13:33:58Z","published":"2025-09-09T13:33:58Z","title":"Proximity Graphs for Similarity Search: Fast Construction, Lower Bounds,\n  and Euclidean Separation","summary":"  Proximity graph-based methods have emerged as a leading paradigm for\napproximate nearest neighbor (ANN) search in the system community. This paper\npresents fresh insights into the theoretical foundation of these methods. We\ndescribe an algorithm to build a proximity graph for $(1+\\epsilon)$-ANN search\nthat has $O((1/\\epsilon)^\\lambda \\cdot n \\log \\Delta)$ edges and guarantees\n$(1/\\epsilon)^\\lambda \\cdot \\text{polylog }\\Delta$ query time. Here, $n$ and\n$\\Delta$ are the size and aspect ratio of the data input, respectively, and\n$\\lambda = O(1)$ is the doubling dimension of the underlying metric space. Our\nconstruction time is near-linear to $n$, improving the $\\Omega(n^2)$ bounds of\nall previous constructions. We complement our algorithm with lower bounds\nrevealing an inherent limitation of proximity graphs: the number of edges needs\nto be at least $\\Omega((1/\\epsilon)^\\lambda \\cdot n + n \\log \\Delta)$ in the\nworst case, up to a subpolynomial factor. The hard inputs used in our\nlower-bound arguments are non-geometric, thus prompting the question of whether\nimprovement is possible in the Euclidean space (a key subclass of metric\nspaces). We provide an affirmative answer by using geometry to reduce the graph\nsize to $O((1/\\epsilon)^\\lambda \\cdot n)$ while preserving nearly the same\nquery and construction time.\n","authors":["Shangqi Lu","Yufei Tao"],"pdf_url":"https://arxiv.org/pdf/2509.07732v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.05847v3","updated":"2025-09-09T12:19:22Z","published":"2025-05-09T07:37:38Z","title":"Smaller and More Flexible Cuckoo Filters","summary":"  Cuckoo filters are space-efficient approximate set membership data structures\nwith a controllable false positive rate (FPR) and zero false negatives, similar\nto Bloom filters. In contrast to Bloom filters, Cuckoo filters store multi-bit\nfingerprints of keys in a hash table using variants of Cuckoo hashing, allowing\neach fingerprint to be stored at a small number of possible locations. Existing\nCuckoo filters use fingerprints of $(k+3)$ bits per key and an additional space\noverhead factor of at least $1.05$ to achieve an FPR of $2^{-k}$. For $k=10$,\nthis amounts to $1.365\\, kn$ bits to store $n$ keys, which is better than\n$1.443\\, kn$ bits for Bloom filters. The $+3$ for the fingerprint size is\nrequired to balance out the multiplied FPR caused by looking for the\nfingerprint at several locations. In the original Cuckoo filter, the number of\nhash table buckets is restricted to a power of 2, which may lead to much larger\nspace overheads, up to $2.1\\, (1+3/k)\\, kn$ bits.\n  We present two improvements of Cuckoo filters. First, we remove the\nrestriction that the number of buckets must be a power of 2 by using a\ndifferent placement strategy. Second, we reduce the space overhead factor of\nCuckoo filters to $1.06 \\, (1+2/k)$ by using overlapping windows instead of\ndisjoint buckets to maintain the load threshold of the hash table, while\nreducing the number of alternative slots where any fingerprint may be found.\n  A detailed evaluation demonstrates that the alternative memory layout based\non overlapping windows decreases the size of Cuckoo filters not only in theory,\nbut also in practice. A comparison with other state-of-the art filter types,\nPrefix filters and Vector Quotient filters (VQFs), shows that the reduced space\noverhead makes windowed Cuckoo filters the smallest filters supporting online\ninsertions, with similarly fast queries, but longer insertion times.\n","authors":["Johanna Elena Schmitz","Jens Zentgraf","Sven Rahmann"],"pdf_url":"https://arxiv.org/pdf/2505.05847v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07599v1","updated":"2025-09-09T11:17:12Z","published":"2025-09-09T11:17:12Z","title":"Tight Bounds for Low-Error Frequency Moment Estimation and the Power of\n  Multiple Passes","summary":"  Estimating the second frequency moment $F_2$ of a data stream up to a $(1 \\pm\n\\varepsilon)$ factor is a central problem in the streaming literature. For\nerrors $\\varepsilon > \\Omega(1/\\sqrt{n})$, the tight bound\n$\\Theta\\left(\\log(\\varepsilon^2 n)/\\varepsilon^2\\right)$ was recently\nestablished by Braverman and Zamir. In this work, we complete the picture by\nresolving the remaining regime of small error, $\\varepsilon < 1/\\sqrt{n}$,\nshowing that the optimal space complexity is $\\Theta\\left( \\min\\left(n,\n\\frac{1}{\\varepsilon^2} \\right) \\cdot \\left(1 + \\left| \\log(\\varepsilon^2 n)\n\\right| \\right) \\right)$ bits for all $\\varepsilon \\geq 1/n^2$, assuming a\nsufficiently large universe. This closes the gap between the best known\n$\\Omega(n)$ lower bound and the straightforward $O(n \\log n)$ upper bound in\nthat range, and shows that essentially storing the entire stream is necessary\nfor high-precision estimation.\n  To derive this bound, we fully characterize the two-party communication\ncomplexity of estimating the size of a set intersection up to an arbitrary\nadditive error $\\varepsilon n$. In particular, we prove a tight $\\Omega(n \\log\nn)$ lower bound for one-way communication protocols when $\\varepsilon <\nn^{-1/2-\\Omega(1)}$, in contrast to classical $O(n)$-bit protocols that use\ntwo-way communication. Motivated by this separation, we present a two-pass\nstreaming algorithm that computes the exact histogram of a stream with high\nprobability using only $O(n \\log \\log n)$ bits of space, in contrast to the\n$\\Theta(n \\log n)$ bits required in one pass even to approximate $F_2$ with\nsmall error. This yields the first asymptotic separation between one-pass and\n$O(1)$-passes space complexity for small frequency moment estimation.\n","authors":["Naomi Green-Maimon","Or Zamir"],"pdf_url":"https://arxiv.org/pdf/2509.07599v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07587v1","updated":"2025-09-09T10:54:20Z","published":"2025-09-09T10:54:20Z","title":"The General Expiration Streaming Model: Diameter, $k$-Center, Counting,\n  Sampling, and Friends","summary":"  An important thread in the study of data-stream algorithms focuses on\nsettings where stream items are active only for a limited time. We introduce a\nnew expiration model, where each item arrives with its own expiration time. The\nspecial case where items expire in the order that they arrive, which we call\nconsistent expirations, contains the classical sliding-window model of Datar,\nGionis, Indyk, and Motwani [SICOMP 2002] and its timestamp-based variant of\nBraverman and Ostrovsky [FOCS 2007].\n  Our first set of results presents algorithms (in the expiration streaming\nmodel) for several fundamental problems, including approximate counting,\nuniform sampling, and weighted sampling by efficiently tracking active items\nwithout explicitly storing them all. Naturally, these algorithms have many\nimmediate applications to other problems.\n  Our second and main set of results designs algorithms (in the expiration\nstreaming model) for the diameter and $k$-center problems, where items are\npoints in a metric space. Our results significantly extend those known for the\nspecial case of sliding-window streams by Cohen-Addad, Schwiegelshohn, and\nSohler [ICALP 2016], including also a strictly better approximation factor for\nthe diameter in the important special case of high-dimensional Euclidean space.\nWe develop new decomposition and coordination techniques along with a geometric\ndominance framework, to filter out redundant points based on both temporal and\nspatial proximity.\n","authors":["Lotte Blank","Sergio Cabello","MohammadTaghi Hajiaghayi","Robert Krauthgamer","Sepideh Mahabadi","André Nusser","Jeff M. Phillips","Jonas Sauer"],"pdf_url":"https://arxiv.org/pdf/2509.07587v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.11430v2","updated":"2025-09-09T08:01:08Z","published":"2025-05-16T16:48:40Z","title":"Computing in a Faulty Congested Clique","summary":"  We study a Faulty Congested Clique model, in which an adversary may fail\nnodes in the network throughout the computation. We show that any task of\n$O(n\\log{n})$-bit input per node can be solved in roughly $n$ rounds, where $n$\nis the size of the network. This nearly matches the linear upper bound on the\ncomplexity of the non-faulty Congested Clique model for such problems, by\nlearning the entire input, and it holds in the faulty model even with a linear\nnumber of faults.\n  Our main contribution is that we establish that one can do much better by\nlooking more closely at the computation. Given a deterministic algorithm\n$\\mathcal{A}$ for the non-faulty Congested Clique model, we show how to\ntransform it into an algorithm $\\mathcal{A}'$ for the faulty model, with an\noverhead that could be as small as some logarithmic-in-$n$ factor, by\nconsidering refined complexity measures of $\\mathcal{A}$.\n  As an exemplifying application of our approach, we show that the\n$O(n^{1/3})$-round complexity of semi-ring matrix multiplication\n[Censor-Hillel, Kaski, Korhonen, Lenzen, Paz, Suomela, PODC 2015] remains the\nsame up to polylog factors in the faulty model, even if the adversary can fail\n$99\\%$ of the nodes (or any other constant fraction).\n","authors":["Keren Censor-Hillel","Pedro Soto"],"pdf_url":"https://arxiv.org/pdf/2505.11430v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07444v1","updated":"2025-09-09T07:09:06Z","published":"2025-09-09T07:09:06Z","title":"Dimension Reduction for Clustering: The Curious Case of Discrete Centers","summary":"  The Johnson-Lindenstrauss transform is a fundamental method for dimension\nreduction in Euclidean spaces, that can map any dataset of $n$ points into\ndimension $O(\\log n)$ with low distortion of their distances. This dimension\nbound is tight in general, but one can bypass it for specific problems. Indeed,\ntremendous progress has been made for clustering problems, especially in the\n\\emph{continuous} setting where centers can be picked from the ambient space\n$\\mathbb{R}^d$. Most notably, for $k$-median and $k$-means, the dimension bound\nwas improved to $O(\\log k)$ [Makarychev, Makarychev and Razenshteyn, STOC\n2019].\n  We explore dimension reduction for clustering in the \\emph{discrete} setting,\nwhere centers can only be picked from the dataset, and present two results that\nare both parameterized by the doubling dimension of the dataset, denoted as\n$\\operatorname{ddim}$. The first result shows that dimension\n$O_{\\epsilon}(\\operatorname{ddim} + \\log k + \\log\\log n)$ suffices, and is\nmoreover tight, to guarantee that the cost is preserved within factor\n$1\\pm\\epsilon$ for every set of centers. Our second result eliminates the\n$\\log\\log n$ term in the dimension through a relaxation of the guarantee\n(namely, preserving the cost only for all approximately-optimal sets of\ncenters), which maintains its usefulness for downstream applications.\n  Overall, we achieve strong dimension reduction in the discrete setting, and\nfind that it differs from the continuous setting not only in the dimension\nbound, which depends on the doubling dimension, but also in the guarantees\nbeyond preserving the optimal value, such as which clusterings are preserved.\n","authors":["Shaofeng H. -C. Jiang","Robert Krauthgamer","Shay Sapir","Sandeep Silwal","Di Yue"],"pdf_url":"https://arxiv.org/pdf/2509.07444v1.pdf","comment":"35 pages"},{"id":"http://arxiv.org/abs/2508.18718v2","updated":"2025-09-09T05:47:52Z","published":"2025-08-26T06:28:38Z","title":"Max-Min and 1-Bounded Space Algorithms for the Bin Packing Problem","summary":"  In the (1-dimensional) bin packing problem, we are asked to pack all the\ngiven items into bins, each of capacity one, so that the number of non-empty\nbins is minimized. Zhu~[Chaos, Solitons \\& Fractals 2016] proposed an\napproximation algorithm $MM$ that sorts the item sequence in a non-increasing\norder by size at the beginning, and then repeatedly packs, into the current\nsingle open bin, first as many of the largest items in the remaining sequence\nas possible and then as many of the smallest items in the remaining sequence as\npossible. In this paper we prove that the asymptotic approximation ratio of\n$MM$ is at most 1.5. Next, focusing on the fact that $MM$ is at the\nintersection of two algorithm classes, max-min algorithms and 1-bounded space\nalgorithms, we comprehensively analyze the theoretical performance bounds of\neach subclass derived from the two classes. Our results include a lower bound\nof 1.25 for the intersection of the two classes. Furthermore, we extend the\ntheoretical analysis over algorithm classes to the cardinality constrained bin\npacking problem.\n","authors":["Hiroshi Fujiwara","Rina Atsumi","Hiroaki Yamamoto"],"pdf_url":"https://arxiv.org/pdf/2508.18718v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08148v1","updated":"2025-09-09T21:10:15Z","published":"2025-09-09T21:10:15Z","title":"A Dynamic, Self-balancing k-d Tree","summary":"  The original description of the k-d tree recognized that rebalancing\ntechniques, such as used to build an AVL tree or a red-black tree, are not\napplicable to a k-d tree, because these techniques involve cyclic exchange (aka\nrotation) of tree nodes, which destroys the sorted order of the k-d tree. For\nthis reason, a static k-d tree is often built from all of the k-dimensional\ndata en masse. However, it is possible to build a dynamic k-d tree that\nself-balances when necessary after insertion or deletion of each individual\nk-dimensional datum. This article describes insertion and deletion algorithms\nfor a dynamic k-d tree, and measures their performance.\n","authors":["Russell A. Brown"],"pdf_url":"https://arxiv.org/pdf/2509.08148v1.pdf","comment":"16 pages, 4 figures, 6 tables"}],"Graphics":[{"id":"http://arxiv.org/abs/2509.07897v1","updated":"2025-09-09T16:29:12Z","published":"2025-09-09T16:29:12Z","title":"dciWebMapper2: Enhancing the dciWebMapper framework toward integrated,\n  interactive visualization of linked multi-type maps, charts, and spatial\n  statistics and analysis","summary":"  As interactive web-based geovisualization becomes increasingly vital across\ndisciplines, there is a growing need for open-source frameworks that support\ndynamic, multi-attribute spatial analysis and accessible design. This paper\nintroduces dciWebMapper2, a significant expansion of the original dciWebMapper\nframework, designed to enable exploratory analysis across domains such as\nclimate justice, food access, and social vulnerability. The enhanced framework\nintegrates multiple map types, including choropleth, proportional symbol, small\nmultiples, and heatmaps, with linked statistical charts (e.g., scatter plots,\nboxplots) and time sliders, all within a coordinated-view environment.\nDropdown-based controls allow flexible, high-dimensional comparisons while\nmaintaining visual clarity. Grounded in cartographic and information\nvisualization principles, dciWebMapper2 is fully open-source, self-contained,\nand server-free, supporting modularity, reproducibility, and long-term\nsustainability. Three applied use cases demonstrate its adaptability and\npotential to democratize interactive web cartography. This work offers a\nversatile foundation for inclusive spatial storytelling and transparent\ngeospatial analysis in research, education, and civic engagement.\n","authors":["Sarigai Sarigai","Liping Yang","Katie Slack","Carolyn Fish","Michaela Buenemann","Qiusheng Wu","Yan Lin","Joseph A. Cook","David Jacobs"],"pdf_url":"https://arxiv.org/pdf/2509.07897v1.pdf","comment":"15 figures, 2 tables, and three advanced interactive web map apps\n  that are openly available to the public"},{"id":"http://arxiv.org/abs/2502.08297v2","updated":"2025-09-09T14:05:14Z","published":"2025-02-12T10:58:09Z","title":"BEAM: Bridging Physically-based Rendering and Gaussian Modeling for\n  Relightable Volumetric Video","summary":"  Volumetric video enables immersive experiences by capturing dynamic 3D\nscenes, enabling diverse applications for virtual reality, education, and\ntelepresence. However, traditional methods struggle with fixed lighting\nconditions, while neural approaches face trade-offs in efficiency, quality, or\nadaptability for relightable scenarios. To address these limitations, we\npresent BEAM, a novel pipeline that bridges 4D Gaussian representations with\nphysically-based rendering (PBR) to produce high-quality, relightable\nvolumetric videos from multi-view RGB footage. BEAM recovers detailed geometry\nand PBR properties via a series of available Gaussian-based techniques. It\nfirst combines Gaussian-based human performance tracking with geometry-aware\nrasterization in a coarse-to-fine optimization framework to recover spatially\nand temporally consistent geometries. We further enhance Gaussian attributes by\nincorporating PBR properties step by step. We generate roughness via a\nmulti-view-conditioned diffusion model, and then derive AO and base color using\na 2D-to-3D strategy, incorporating a tailored Gaussian-based ray tracer for\nefficient visibility computation. Once recovered, these dynamic, relightable\nassets integrate seamlessly into traditional CG pipelines, supporting real-time\nrendering with deferred shading and offline rendering with ray tracing. By\noffering realistic, lifelike visualizations under diverse lighting conditions,\nBEAM opens new possibilities for interactive entertainment, storytelling, and\ncreative visualization.\n","authors":["Yu Hong","Yize Wu","Zhehao Shen","Chengcheng Guo","Yuheng Jiang","Yingliang Zhang","Jingyi Yu","Lan Xu"],"pdf_url":"https://arxiv.org/pdf/2502.08297v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.18407v2","updated":"2025-09-09T12:36:01Z","published":"2025-06-23T08:42:57Z","title":"IntuiTF: MLLM-Guided Transfer Function Optimization for Direct Volume\n  Rendering","summary":"  Direct volume rendering (DVR) is a fundamental technique for visualizing\nvolumetric data, where transfer functions (TFs) play a crucial role in\nextracting meaningful structures. However, designing effective TFs remains\nunintuitive due to the semantic gap between user intent and TF parameter space.\nAlthough numerous TF optimization methods have been proposed to mitigate this\nissue, existing approaches still face two major challenges: the vast\nexploration space and limited generalizability. To address these issues, we\npropose IntuiTF, a novel framework that leverages Multimodal Large Language\nModels (MLLMs) to guide TF optimization in alignment with user intent.\nSpecifically, our method consists of two key components: (1) an\nevolution-driven explorer for effective exploration of the TF space, and (2) an\nMLLM-guided human-aligned evaluator that provides generalizable visual feedback\non rendering quality. The explorer and the evaluator together establish an\nefficient Trial-Insight-Replanning paradigm for TF space exploration. We\nfurther extend our framework with an interactive TF design system. We\ndemonstrate the broad applicability of our framework through three case studies\nand validate the effectiveness of each component through extensive experiments.\nWe strongly recommend readers check our cases, demo video, and source code at:\nhttps://github.com/wyysteelhead/IntuiTF\n","authors":["Yiyao Wang","Bo Pan","Ke Wang","Han Liu","Jinyuan Mao","Yuxin Liu","Minfeng Zhu","Xiuqi Huang","Weifeng Chen","Bo Zhang","Wei Chen"],"pdf_url":"https://arxiv.org/pdf/2506.18407v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07653v1","updated":"2025-09-09T12:18:31Z","published":"2025-09-09T12:18:31Z","title":"Topology-Aware Optimization of Gaussian Primitives for Human-Centric\n  Volumetric Videos","summary":"  Volumetric video is emerging as a key medium for digitizing the dynamic\nphysical world, creating the virtual environments with six degrees of freedom\nto deliver immersive user experiences. However, robustly modeling general\ndynamic scenes, especially those involving topological changes while\nmaintaining long-term tracking remains a fundamental challenge. In this paper,\nwe present TaoGS, a novel topology-aware dynamic Gaussian representation that\ndisentangles motion and appearance to support, both, long-range tracking and\ntopological adaptation. We represent scene motion with a sparse set of motion\nGaussians, which are continuously updated by a spatio-temporal tracker and\nphotometric cues that detect structural variations across frames. To capture\nfine-grained texture, each motion Gaussian anchors and dynamically activates a\nset of local appearance Gaussians, which are non-rigidly warped to the current\nframe to provide strong initialization and significantly reduce training time.\nThis activation mechanism enables efficient modeling of detailed textures and\nmaintains temporal coherence, allowing high-fidelity rendering even under\nchallenging scenarios such as changing clothes. To enable seamless integration\ninto codec-based volumetric formats, we introduce a global Gaussian Lookup\nTable that records the lifespan of each Gaussian and organizes attributes into\na lifespan-aware 2D layout. This structure aligns naturally with standard video\ncodecs and supports up to 40 compression. TaoGS provides a unified, adaptive\nsolution for scalable volumetric video under topological variation, capturing\nmoments where \"elegance in motion\" and \"Power in Stillness\", delivering\nimmersive experiences that harmonize with the physical world.\n","authors":["Yuheng Jiang","Chengcheng Guo","Yize Wu","Yu Hong","Shengkun Zhu","Zhehao Shen","Yingliang Zhang","Shaohui Jiao","Zhuo Su","Lan Xu","Marc Habermann","Christian Theobalt"],"pdf_url":"https://arxiv.org/pdf/2509.07653v1.pdf","comment":"Accepted at SIGGRAPH Asia 2025. Project page:\n  https://guochch.github.io/TaoGS/"},{"id":"http://arxiv.org/abs/2509.07643v1","updated":"2025-09-09T12:10:22Z","published":"2025-09-09T12:10:22Z","title":"ReShape: a Collaborative Art Experience","summary":"  This article describes a project called ReShape in which we created and\ndesigned a crowdsourced art initiative, inspired and powered by mathematics.\n","authors":["Hugo Parlier","Bruno Teheux"],"pdf_url":"https://arxiv.org/pdf/2509.07643v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2502.05752v2","updated":"2025-09-09T08:58:33Z","published":"2025-02-09T03:06:19Z","title":"PINGS: Gaussian Splatting Meets Distance Fields within a Point-Based\n  Implicit Neural Map","summary":"  Robots benefit from high-fidelity reconstructions of their environment, which\nshould be geometrically accurate and photorealistic to support downstream\ntasks. While this can be achieved by building distance fields from range\nsensors and radiance fields from cameras, realising scalable incremental\nmapping of both fields consistently and at the same time with high quality is\nchallenging. In this paper, we propose a novel map representation that unifies\na continuous signed distance field and a Gaussian splatting radiance field\nwithin an elastic and compact point-based implicit neural map. By enforcing\ngeometric consistency between these fields, we achieve mutual improvements by\nexploiting both modalities. We present a novel LiDAR-visual SLAM system called\nPINGS using the proposed map representation and evaluate it on several\nchallenging large-scale datasets. Experimental results demonstrate that PINGS\ncan incrementally build globally consistent distance and radiance fields\nencoded with a compact set of neural points. Compared to state-of-the-art\nmethods, PINGS achieves superior photometric and geometric rendering at novel\nviews by constraining the radiance field with the distance field. Furthermore,\nby utilizing dense photometric cues and multi-view consistency from the\nradiance field, PINGS produces more accurate distance fields, leading to\nimproved odometry estimation and mesh reconstruction. We also provide an\nopen-source implementation of PING at: https://github.com/PRBonn/PINGS.\n","authors":["Yue Pan","Xingguang Zhong","Liren Jin","Louis Wiesmann","Marija Popović","Jens Behley","Cyrill Stachniss"],"pdf_url":"https://arxiv.org/pdf/2502.05752v2.pdf","comment":"15 pages, 8 figures, presented at RSS 2025"},{"id":"http://arxiv.org/abs/2509.07522v1","updated":"2025-09-09T08:58:13Z","published":"2025-09-09T08:58:13Z","title":"Neural Cone Radiosity for Interactive Global Illumination with Glossy\n  Materials","summary":"  Modeling of high-frequency outgoing radiance distributions has long been a\nkey challenge in rendering, particularly for glossy material. Such\ndistributions concentrate radiative energy within a narrow lobe and are highly\nsensitive to changes in view direction. However, existing neural radiosity\nmethods, which primarily rely on positional feature encoding, exhibit notable\nlimitations in capturing these high-frequency, strongly view-dependent radiance\ndistributions. To address this, we propose a highly-efficient approach by\nreflectance-aware ray cone encoding based on the neural radiosity framework,\nnamed neural cone radiosity. The core idea is to employ a pre-filtered\nmulti-resolution hash grid to accurately approximate the glossy BSDF lobe,\nembedding view-dependent reflectance characteristics directly into the encoding\nprocess through continuous spatial aggregation. Our design not only\nsignificantly improves the network's ability to model high-frequency reflection\ndistributions but also effectively handles surfaces with a wide range of\nglossiness levels, from highly glossy to low-gloss finishes. Meanwhile, our\nmethod reduces the network's burden in fitting complex radiance distributions,\nallowing the overall architecture to remain compact and efficient.\nComprehensive experimental results demonstrate that our method consistently\nproduces high-quality, noise-free renderings in real time under various\nglossiness conditions, and delivers superior fidelity and realism compared to\nbaseline approaches.\n","authors":["Jierui Ren","Haojie Jin","Bo Pang","Yisong Chen","Guoping Wang","Sheng Li"],"pdf_url":"https://arxiv.org/pdf/2509.07522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.01839v3","updated":"2025-09-09T07:53:14Z","published":"2025-09-01T23:43:43Z","title":"HodgeFormer: Transformers for Learnable Operators on Triangular Meshes\n  through Data-Driven Hodge Matrices","summary":"  Currently, prominent Transformer architectures applied on graphs and meshes\nfor shape analysis tasks employ traditional attention layers that heavily\nutilize spectral features requiring costly eigenvalue decomposition-based\nmethods. To encode the mesh structure, these methods derive positional\nembeddings, that heavily rely on eigenvalue decomposition based operations,\ne.g. on the Laplacian matrix, or on heat-kernel signatures, which are then\nconcatenated to the input features. This paper proposes a novel approach\ninspired by the explicit construction of the Hodge Laplacian operator in\nDiscrete Exterior Calculus as a product of discrete Hodge operators and\nexterior derivatives, i.e. $(L := \\star_0^{-1} d_0^T \\star_1 d_0)$. We adjust\nthe Transformer architecture in a novel deep learning layer that utilizes the\nmulti-head attention mechanism to approximate Hodge matrices $\\star_0$,\n$\\star_1$ and $\\star_2$ and learn families of discrete operators $L$ that act\non mesh vertices, edges and faces. Our approach results in a\ncomputationally-efficient architecture that achieves comparable performance in\nmesh segmentation and classification tasks, through a direct learning\nframework, while eliminating the need for costly eigenvalue decomposition\noperations or complex preprocessing operations.\n","authors":["Akis Nousias","Stavros Nousias"],"pdf_url":"https://arxiv.org/pdf/2509.01839v3.pdf","comment":"13 pages, 11 figures, 9 tables"},{"id":"http://arxiv.org/abs/2509.08855v1","updated":"2025-09-09T08:49:34Z","published":"2025-09-09T08:49:34Z","title":"Morphology-Preserving Remeshing Approach to Particulate Microstructures\n  via Harmonic Decomposition","summary":"  Harmonic decomposition of surfaces, such as spherical and spheroidal\nharmonics, is used to analyze morphology, reconstruct, and generate surface\ninclusions of particulate microstructures. However, obtaining high-quality\nmeshes of engineering microstructures using these approaches remains an open\nquestion. In harmonic approaches, we usually reconstruct surfaces by evaluating\nthe harmonic bases on equidistantly sampled simplicial complexes of the base\ndomains (e.g., triangular spheroids and disks). However, this traditional\nsampling does not account for local changes in the Jacobian of the basis\nfunctions, resulting in nonuniform discretization after reconstruction or\ngeneration. As it impacts the accuracy and time step, high-quality\ndiscretization of microstructures is crucial for efficient numerical\nsimulations (e.g., finite element and discrete element methods). To circumvent\nthis issue, we propose an efficient hierarchical diffusion-based approach for\nresampling the surface-i.e., performing a reparameterization-to yield an\nequalized mesh triangulation. Analogous to heat problems, we use nonlinear\ndiffusion to resample the curvilinear coordinates of the analysis domain,\nthereby enlarging small triangles at the expense of large triangles on\nsurfaces. We tested isotropic and anisotropic diffusion schemes on the recent\nspheroidal and hemispheroidal harmonics methods. The results show a substantial\nimprovement in the quality metrics for surface triangulation. Unlike\ntraditional surface reconstruction and meshing techniques, this approach\npreserves surface morphology, along with the areas and volumes of surfaces. We\ndiscuss the results and the associated computational costs for large 2D and 3D\nmicrostructures, such as digital twins of concrete and stone masonry, and their\nfuture applications.\n","authors":["Mahmoud Shaqfa"],"pdf_url":"https://arxiv.org/pdf/2509.08855v1.pdf","comment":null}]},"2025-09-10T00:00:00Z":{"Operating Systems":[{"id":"http://arxiv.org/abs/2509.03855v3","updated":"2025-09-10T02:43:08Z","published":"2025-09-04T03:31:31Z","title":"Towards Deterministic Sub-0.5 us Response on Linux through Interrupt\n  Isolation","summary":"  Real-time responsiveness in Linux is often constrained by interrupt\ncontention and timer handling overhead, making it challenging to achieve\nsub-microsecond latency. This work introduces an interrupt isolation approach\nthat centralizes and minimizes timer interrupt interference across CPU cores.\nBy enabling a dedicated API to selectively invoke timer handling routines and\nsuppress non-critical inter-processor interrupts, our design significantly\nreduces jitter and response latency. Experiments conducted on an ARM-based\nmulticore platform demonstrate that the proposed mechanism consistently\nachieves sub-0.5 us response times, outperforming conventional Linux PREEMPT-RT\nconfigurations. These results highlight the potential of interrupt isolation as\na lightweight and effective strategy for deterministic real-time workloads in\ngeneral-purpose operating systems.\n","authors":["Zhouyi Zhou","Zhili Liu","Shancong Zhang","Jiemin Li","Dengke Du","Mengke Sun","Zhiqiang Wang","Hongyan Liu","Guokai Xu"],"pdf_url":"https://arxiv.org/pdf/2509.03855v3.pdf","comment":"9 pages, 11 figures"}],"Systems and Control":[{"id":"http://arxiv.org/abs/2509.08783v1","updated":"2025-09-10T17:13:24Z","published":"2025-09-10T17:13:24Z","title":"Distributed Unknown Input Observer Design with Relaxed Conditions:\n  Theory and Application to Vehicle Platooning","summary":"  Designing observers for linear systems with both known and unknown inputs is\nan important problem in several research contexts, for example, fault diagnosis\nand fault-tolerant control, and cyber-secure control systems, and presents\nsignificant challenges in distributed state estimation due to the limited\nsensing capabilities of individual nodes. Existing methods typically impose an\nindividual input-to-output rank condition on each estimator node, which\nseverely restricts applicability in practical applications. This paper presents\na novel distributed unknown-input observer design scheme based on a geometric\napproach under much weaker assumptions than the ones available in the\nliterature. By leveraging the properties of the $(C, A)$-invariant (conditioned\ninvariant) subspace at each node, our methodology aims at reconstructing\nportions of the system state that remain unaffected by local unknown inputs,\nwhile integrating these estimates via a network-based information exchange. A\ncase study on vehicle platoon control shows the effectiveness of the proposed\napproach.\n","authors":["Ruixuan Zhao","Guitao Yang","Thomas Parisini","Boli Chen"],"pdf_url":"https://arxiv.org/pdf/2509.08783v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08776v1","updated":"2025-09-10T17:05:53Z","published":"2025-09-10T17:05:53Z","title":"CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks\n  with Entropy Regularization","summary":"  Massive MIMO systems rely on accurate Channel State Information (CSI)\nfeedback to enable high-gain beam-forming. However, the feedback overhead\nscales linearly with the number of antennas, presenting a major bottleneck.\nWhile recent deep learning methods have improved CSI compression, most overlook\nthe impact of quantization and entropy coding, limiting their practical\ndeployability. In this work, we propose an end-to-end CSI compression framework\nthat integrates a Spatial Correlation-Guided Attention Mechanism with\nquantization and entropy-aware training. Our model effectively exploits the\nspatial correlation among the antennas, thereby learning compact,\nentropy-optimized latent representations for efficient coding. This reduces the\nrequired feedback bitrates without sacrificing reconstruction accuracy, thereby\nyielding a superior rate-distortion trade-off. Experiments show that our method\nsurpasses existing end-to-end CSI compression schemes, exceeding benchmark\nperformance by an average of 21.5% on indoor datasets and 18.9% on outdoor\ndatasets. The proposed framework results in a practical and efficient CSI\nfeedback scheme.\n","authors":["Maryam Ansarifard","Mostafa Rahmani","Mohit K. Sharma","Kishor C. Joshi","George Exarchakos","Alister Burr"],"pdf_url":"https://arxiv.org/pdf/2509.08776v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.13441v2","updated":"2025-09-10T15:53:04Z","published":"2024-01-24T13:30:18Z","title":"Guiding Soft Robots with Motor-Imagery Brain Signals and Impedance\n  Control","summary":"  Integrating Brain-Machine Interfaces into non-clinical applications like\nrobot motion control remains difficult - despite remarkable advancements in\nclinical settings. Specifically, EEG-based motor imagery systems are still\nerror-prone, posing safety risks when rigid robots operate near humans. This\nwork presents an alternative pathway towards safe and effective operation by\ncombining wearable EEG with physically embodied safety in soft robots. We\nintroduce and test a pipeline that allows a user to move a soft robot's end\neffector in real time via brain waves that are measured by as few as three EEG\nchannels. A robust motor imagery algorithm interprets the user's intentions to\nmove the position of a virtual attractor to which the end effector is\nattracted, thanks to a new Cartesian impedance controller. We specifically\nfocus here on planar soft robot-based architected metamaterials, which require\nthe development of a novel control architecture to deal with the peculiar\nnonlinearities - e.g., non-affinity in control. We preliminarily but\nquantitatively evaluate the approach on the task of setpoint regulation. We\nobserve that the user reaches the proximity of the setpoint in 66% of steps and\nthat for successful steps, the average response time is 21.5s. We also\ndemonstrate the execution of simple real-world tasks involving interaction with\nthe environment, which would be extremely hard to perform if it were not for\nthe robot's softness.\n","authors":["Maximilian Stölzle","Sonal Santosh Baberwal","Daniela Rus","Shirley Coyle","Cosimo Della Santina"],"pdf_url":"https://arxiv.org/pdf/2401.13441v2.pdf","comment":"8 pages, presented at 7th IEEE-RAS International Conference on Soft\n  Robotics (2024)"},{"id":"http://arxiv.org/abs/2509.08699v1","updated":"2025-09-10T15:43:32Z","published":"2025-09-10T15:43:32Z","title":"TANGO: Traversability-Aware Navigation with Local Metric Control for\n  Topological Goals","summary":"  Visual navigation in robotics traditionally relies on globally-consistent 3D\nmaps or learned controllers, which can be computationally expensive and\ndifficult to generalize across diverse environments. In this work, we present a\nnovel RGB-only, object-level topometric navigation pipeline that enables\nzero-shot, long-horizon robot navigation without requiring 3D maps or\npre-trained controllers. Our approach integrates global topological path\nplanning with local metric trajectory control, allowing the robot to navigate\ntowards object-level sub-goals while avoiding obstacles. We address key\nlimitations of previous methods by continuously predicting local trajectory\nusing monocular depth and traversability estimation, and incorporating an\nauto-switching mechanism that falls back to a baseline controller when\nnecessary. The system operates using foundational models, ensuring open-set\napplicability without the need for domain-specific fine-tuning. We demonstrate\nthe effectiveness of our method in both simulated environments and real-world\ntests, highlighting its robustness and deployability. Our approach outperforms\nexisting state-of-the-art methods, offering a more adaptable and effective\nsolution for visual navigation in open-set environments. The source code is\nmade publicly available: https://github.com/podgorki/TANGO.\n","authors":["Stefan Podgorski","Sourav Garg","Mehdi Hosseinzadeh","Lachlan Mares","Feras Dayoub","Ian Reid"],"pdf_url":"https://arxiv.org/pdf/2509.08699v1.pdf","comment":"9 pages, 5 figures, ICRA 2025"},{"id":"http://arxiv.org/abs/2509.08672v1","updated":"2025-09-10T15:09:01Z","published":"2025-09-10T15:09:01Z","title":"Universal Graph Learning for Power System Reconfigurations: Transfer\n  Across Topology Variations","summary":"  This work addresses a fundamental challenge in applying deep learning to\npower systems: developing neural network models that transfer across\nsignificant system changes, including networks with entirely different\ntopologies and dimensionalities, without requiring training data from unseen\nreconfigurations. Despite extensive research, most ML-based approaches remain\nsystem-specific, limiting real-world deployment. This limitation stems from a\ndual barrier. First, topology changes shift feature distributions and alter\ninput dimensions due to power flow physics. Second, reconfigurations redefine\noutput semantics and dimensionality, requiring models to handle\nconfiguration-specific outputs while maintaining transferable feature\nextraction. To overcome this challenge, we introduce a Universal Graph\nConvolutional Network (UGCN) that achieves transferability to any\nreconfiguration or variation of existing power systems without any prior\nknowledge of new grid topologies or retraining during implementation. Our\napproach applies to both transmission and distribution networks and\ndemonstrates generalization capability to completely unseen system\nreconfigurations, such as network restructuring and major grid expansions.\nExperimental results across power system applications, including false data\ninjection detection and state forecasting, show that UGCN significantly\noutperforms state-of-the-art methods in cross-system zero-shot transferability\nof new reconfigurations.\n","authors":["Tong Wu","Anna Scaglione","Sandy Miguel","Daniel Arnold"],"pdf_url":"https://arxiv.org/pdf/2509.08672v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2509.08656v1","updated":"2025-09-10T14:52:14Z","published":"2025-09-10T14:52:14Z","title":"Analysis and Control of Acoustic Emissions from Marine Energy Converters","summary":"  This study investigates the mitigation of acoustic emissions from tidal\ncurrent converters (TCCs) through optimized control strategies to enhance power\ngeneration efficiency while minimizing environmental impacts on marine life. A\nMATLAB/Simulink-based model of a Tidal Current Conversion System (TCCS) was\ndeveloped to simulate the effects of variable control parameters, including\nswitching frequencies, maximum power point tracking (MPPT) coefficients, and\nthe elimination of the gearbox, on underwater noise levels. Acoustic emissions\nwere quantified in terms of sound pressure levels (SPLs), and their potential\nimpacts on marine mammals and fish were evaluated against species-specific\nauditory thresholds for temporary and permanent hearing threshold shifts. The\nresults indicate that adjusting control parameters can significantly reduce\nSPLs, with the removal of the gearbox yielding the greatest noise reduction.\nThe study identifies operational conditions under which marine species are at\nrisk of auditory damage and proposes control strategies to mitigate these risks\nwithout compromising energy output. These findings contribute to the\nunderstanding of how control system modifications can balance the efficiency of\nmarine energy systems with ecological considerations, offering guidance for the\ndesign and operation of environmentally compliant TCCs.\n","authors":["Jiaqin He","Max Malyi","Jonathan Shek"],"pdf_url":"https://arxiv.org/pdf/2509.08656v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08646v1","updated":"2025-09-10T14:41:07Z","published":"2025-09-10T14:41:07Z","title":"Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute\n  Implementations","summary":"  As Large Language Model (LLM) agents become increasingly capable of\nautomating complex, multi-step tasks, the need for robust, secure, and\npredictable architectural patterns is paramount. This paper provides a\ncomprehensive guide to the ``Plan-then-Execute'' (P-t-E) pattern, an agentic\ndesign that separates strategic planning from tactical execution. We explore\nthe foundational principles of P-t-E, detailing its core components - the\nPlanner and the Executor - and its architectural advantages in predictability,\ncost-efficiency, and reasoning quality over reactive patterns like ReAct\n(Reason + Act). A central focus is placed on the security implications of this\ndesign, particularly its inherent resilience to indirect prompt injection\nattacks by establishing control-flow integrity. We argue that while P-t-E\nprovides a strong foundation, a defense-in-depth strategy is necessary, and we\ndetail essential complementary controls such as the Principle of Least\nPrivilege, task-scoped tool access, and sandboxed code execution. To make these\nprinciples actionable, this guide provides detailed implementation blueprints\nand working code references for three leading agentic frameworks: LangChain\n(via LangGraph), CrewAI, and AutoGen. Each framework's approach to implementing\nthe P-t-E pattern is analyzed, highlighting unique features like LangGraph's\nstateful graphs for re-planning, CrewAI's declarative tool scoping for\nsecurity, and AutoGen's built-in Docker sandboxing. Finally, we discuss\nadvanced patterns, including dynamic re-planning loops, parallel execution with\nDirected Acyclic Graphs (DAGs), and the critical role of Human-in-the-Loop\n(HITL) verification, to offer a complete strategic blueprint for architects,\ndevelopers, and security engineers aiming to build production-grade, resilient,\nand trustworthy LLM agents.\n","authors":["Ron F. Del Rosario","Klaudia Krawiecka","Christian Schroeder de Witt"],"pdf_url":"https://arxiv.org/pdf/2509.08646v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07218v2","updated":"2025-09-10T14:38:05Z","published":"2025-09-08T20:55:54Z","title":"Electricity Demand and Grid Impacts of AI Data Centers: Challenges and\n  Prospects","summary":"  The rapid growth of artificial intelligence (AI) is driving an unprecedented\nincrease in the electricity demand of AI data centers, raising emerging\nchallenges for electric power grids. Understanding the characteristics of AI\ndata center loads and their interactions with the grid is therefore critical\nfor ensuring both reliable power system operation and sustainable AI\ndevelopment. This paper provides a comprehensive review and vision of this\nevolving landscape. Specifically, this paper (i) presents an overview of AI\ndata center infrastructure and its key components, (ii) examines the key\ncharacteristics and patterns of electricity demand across the stages of model\npreparation, training, fine-tuning, and inference, (iii) analyzes the critical\nchallenges that AI data center loads pose to power systems across three\ninterrelated timescales, including long-term planning and interconnection,\nshort-term operation and electricity markets, and real-time dynamics and\nstability, and (iv) discusses potential solutions from the perspectives of the\ngrid, AI data centers, and AI end-users to address these challenges. By\nsynthesizing current knowledge and outlining future directions, this review\naims to guide research and development in support of the joint advancement of\nAI data centers and power systems toward reliable, efficient, and sustainable\noperation.\n","authors":["Xin Chen","Xiaoyang Wang","Ana Colacelli","Matt Lee","Le Xie"],"pdf_url":"https://arxiv.org/pdf/2509.07218v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.14040v3","updated":"2025-09-10T14:19:31Z","published":"2025-04-18T19:10:13Z","title":"Towards Optimal Orders for Entanglement Swapping in Path Graphs: A\n  Greedy Approach","summary":"  This paper considers the problem of finding an optimal order for entanglement\nswapping in a heterogeneous path of quantum repeaters so as to maximize the\npath throughput defined as the delivery rate of end-to-end entanglements. The\nprimary difficulty in addressing this problem lies in the vast array of\npossible swapping orders for large paths and the complexity of the expected\nthroughput, which depends on the attributes of each node and edge along the\npath, as well as the order of swapping. To cope with these issues, we first\npropose simple approximations in estimating the swapping outcome between two\nentanglement distributions that can run in constant time, thereby providing an\nefficient approach for evaluating and comparing different swapping orders,\nallowing us to solve the problem exactly for small paths. Second, as the number\nof possible orders grows exponentially with the number of repeaters in the\npath, we develop an efficient heuristic based on the greedy selection of nodes\nto sequentially perform swaps according to their swapping scores, defined as\nthe expected number of entanglements resulting from their swaps. The scores are\nlocal but dynamic in the sense that they depend not just on the entanglement\ndistributions available on the path but also on prior swapping decisions.\nFinally, we illustrate the efficiency and effectiveness of our proposed model\nand approach through extensive experimentation conducted using a general\nquantum network simulator.\n","authors":["Van Sy Mai","Abderrahim Amlou","Amar Abane","Abdella Battou"],"pdf_url":"https://arxiv.org/pdf/2504.14040v3.pdf","comment":"11 pages, 11 figures"},{"id":"http://arxiv.org/abs/2509.08572v1","updated":"2025-09-10T13:18:19Z","published":"2025-09-10T13:18:19Z","title":"Optimal control of stochastic networks of $M/M/\\infty$ queues with\n  linear costs","summary":"  We consider an arbitrary network of $M/M/\\infty$ queues with controlled\ntransitions between queues. We consider optimal control problems where the\ncosts are linear functions of the state and inputs over a finite or infinite\nhorizon. We provide in both cases an explicit characterization of the optimal\ncontrol policies. We also show that these do not involve state feedback, but\nthey depend on the network topology and system parameters. The results are also\nillustrated with various examples.\n","authors":["Giovanni Pugliese Carratelli","Ioannis Lestas"],"pdf_url":"https://arxiv.org/pdf/2509.08572v1.pdf","comment":"Submission to the Conference on Decision and Control 2025"},{"id":"http://arxiv.org/abs/2509.08568v1","updated":"2025-09-10T13:10:52Z","published":"2025-09-10T13:10:52Z","title":"How can a geothermal storage system be optimally integrated into a local\n  district? A case study","summary":"  Achieving net-zero targets requires the phase-out of fossil-based heating. A\nmajor challenge is the seasonal mismatch between renewable heat supply and\ndemand. District heating networks often dispose of excess heat in summer and\nrely on fossil backups in winter. Large-scale thermal energy storage offers a\nsolution by storing surplus summer heat for use during winter, thus reducing\nthe need for fossil fuels. This study investigates the feasibility of a\nlarge-scale thermal storage system at a power production site that supplies a\nlarge district heating network in the city of Bern, Switzerland. Specifically,\nthe study examines the potential of a geothermal storage system to offset\nfossil fuel heat generation in winter by utilising heat stored during the\nsummer months. Using a Python-based multi-energy system model, we simulate the\noptimal operation of the geothermal storage system with respect to cost and\nemissions, considering both supply and demand on an hourly basis over one year.\nMulti-objective optimisation is applied to generate a Pareto-optimal front. The\nresults show that the geothermal storage system eliminates the requirement of 8\nGWh of gas-powered heat supply and increases the waste heat utilisation by 20%,\ntherefore lowering emissions. This effect is further increased when combined\nwith an expansion of the district heating network, as individual,\nemission-heavy heaters are replaced by low-emission heat from the district\nheating network. The findings presented in this study can prove useful when\nevaluating similar systems across Switzerland.\n","authors":["Ueli Schilt","Somesh Vijayananda","Sarah Schneeberger","Manuel Meyer","Santhosh Iyyakkunnel","Pascal Marc Vecsei","Philipp Schuetz"],"pdf_url":"https://arxiv.org/pdf/2509.08568v1.pdf","comment":"7 pages, 5 figures, 1 table. 2025 CISBAT conference"},{"id":"http://arxiv.org/abs/2502.19977v2","updated":"2025-09-10T12:30:24Z","published":"2025-02-27T11:01:43Z","title":"Convergence Guarantees of Model-free Policy Gradient Methods for LQR\n  with Stochastic Data","summary":"  Policy gradient (PG) methods are the backbone of many reinforcement learning\nalgorithms due to their good performance in policy optimization problems. As a\ngradient-based approach, PG methods typically rely on knowledge of the system\ndynamics. If this is not available, trajectory data can be utilized to\napproximate first-order information. When the data are noisy, gradient\nestimates become inaccurate and a study that investigates uncertainty\nestimation and the analysis of its propagation through the algorithm is\ncurrently missing. To address this, our work focuses on the Linear Quadratic\nRegulator (LQR) problem for systems subject to additive stochastic noise. After\nbriefly summarizing the state of the art for cases with a known model, we focus\non scenarios where the system dynamics are unknown, and approximate gradient\ninformation is obtained using zeroth-order optimization techniques. We analyze\nthe theoretical properties by computing the error in the estimated gradient and\nexamining how this error affects the convergence of PG algorithms.\nAdditionally, we provide global convergence guarantees for various versions of\nPG methods, including those employing adaptive step sizes and variance\nreduction techniques, which help increase the convergence rate and reduce\nsample complexity. This study contributed to characterizing robustness of the\nstudy of the robustness of model-free PG methods, aiming to identify their\nlimitations in the presence of stochastic noise and proposing improvements to\nenhance their applicability.\n","authors":["Bowen Song","Andrea Iannelli"],"pdf_url":"https://arxiv.org/pdf/2502.19977v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08534v1","updated":"2025-09-10T12:24:17Z","published":"2025-09-10T12:24:17Z","title":"Phase-Coordinated Multi-Agent Circular Formation Control with\n  Non-Concentric Boundary Constraints","summary":"  This paper addresses the problem of collective circular motion control for\nunicycle agents, with the objective of achieving phase coordination of their\nvelocity vectors while ensuring that their trajectories remain confined within\na prescribed non-concentric circular boundary. To accommodate such nonuniform\nmotion constraints, we build upon our earlier work and extend the use of Mobius\ntransformation to a multi-agent framework. The Mobius transformation maps two\nnonconcentric circles to concentric ones, thereby converting spatially\nnonuniform constraints into uniform ones in the transformed plane. Leveraging\nthis property, we introduce the notion of a phase-shifted order parameter,\nalong with the associated concepts of Mobius phase-shift coupled\nsynchronization and balancing, which characterize the phase-coordinated\npatterns studied in this paper. We establish an equivalence between the\nunicycle dynamics in the original and transformed planes under the Mobius\ntransformation and its inverse, and show that synchronization is preserved\nacross both planes, whereas balancing is generally not. Distributed control\nlaws are then designed in the transformed plane using barrier Lyapunov\nfunctions, under the assumption of an undirected and connected communication\ntopology among agents. These controllers are subsequently mapped back to the\noriginal plane to obtain the linear acceleration and turn-rate control inputs\napplied to the actual agents. Both simulations and experimental results are\nprovided to illustrate the proposed framework.\n","authors":["Shubham Singh","Anoop Jain"],"pdf_url":"https://arxiv.org/pdf/2509.08534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08521v1","updated":"2025-09-10T11:57:56Z","published":"2025-09-10T11:57:56Z","title":"FMT$^{x}$: An Efficient and Asymptotically Optimal Extension of the Fast\n  Marching Tree for Dynamic Replanning","summary":"  Path planning in dynamic environments remains a core challenge in robotics,\nespecially as autonomous systems are deployed in unpredictable spaces such as\nwarehouses and public roads. While algorithms like Fast Marching Tree\n(FMT$^{*}$) offer asymptotically optimal solutions in static settings, their\nsingle-pass design prevents path revisions which are essential for real-time\nadaptation. On the other hand, full replanning is often too computationally\nexpensive. This paper introduces FMT$^{x}$, an extension of the Fast Marching\nTree algorithm that enables efficient and consistent replanning in dynamic\nenvironments. We revisit the neighbor selection rule of FMT$^{*}$ and\ndemonstrate that a minimal change overcomes its single-pass limitation,\nenabling the algorithm to update cost-to-come values upon discovering better\nconnections without sacrificing asymptotic optimality or computational\nefficiency. By maintaining a cost-ordered priority queue and applying a\nselective update condition that uses an expanding neighbor to identify and\ntrigger the re-evaluation of any node with a potentially suboptimal path,\nFMT$^{x}$ ensures that suboptimal routes are efficiently repaired as the\nenvironment evolves. This targeted strategy preserves the inherent efficiency\nof FMT$^{*}$ while enabling robust adaptation to changes in obstacle\nconfiguration. FMT$^{x}$ is proven to recover an asymptotically optimal\nsolution after environmental changes. Experimental results demonstrate that\nFMT$^{x}$ outperforms the influential replanner RRT$^{x}$, reacting more\nswiftly to dynamic events with lower computational overhead and thus offering a\nmore effective solution for real-time robotic navigation in unpredictable\nworlds.\n","authors":["Soheil Espahbodini Nia"],"pdf_url":"https://arxiv.org/pdf/2509.08521v1.pdf","comment":"35 pages, 8 figures, 2 tables, submitted to the International Journal\n  of Robotics Research (IJRR)"},{"id":"http://arxiv.org/abs/2509.08481v1","updated":"2025-09-10T10:46:51Z","published":"2025-09-10T10:46:51Z","title":"Robustness of quantum algorithms: Worst-case fidelity bounds and\n  implications for design","summary":"  Errors occurring on noisy hardware pose a key challenge to reliable quantum\ncomputing. Existing techniques such as error correction, mitigation, or\nsuppression typically separate the error handling from the algorithm analysis\nand design. In this paper, we develop an alternative, algorithm-centered\nframework for understanding and improving the robustness against errors. For a\ngiven quantum algorithm and error model, we derive worst-case fidelity bounds\nwhich can be explicitly computed to certify the robustness. We consider general\nerror models including coherent and (Markovian) incoherent errors and allowing\nfor set-based error descriptions to address uncertainty or time-dependence in\nthe errors. Our results give rise to guidelines for robust algorithm design and\ncompilation by optimizing our theoretical robustness measure. Numerical results\non algorithm analysis and robust optimization demonstrate the practicality of\nthe framework.\n","authors":["Julian Berberich","Tobias Fellner","Robert L. Kosut","Christian Holm"],"pdf_url":"https://arxiv.org/pdf/2509.08481v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08455v1","updated":"2025-09-10T09:58:01Z","published":"2025-09-10T09:58:01Z","title":"SKYLINK: Scalable and Resilient Link Management in LEO Satellite Network","summary":"  The rapid growth of space-based services has established LEO satellite\nnetworks as a promising option for global broadband connectivity.\nNext-generation LEO networks leverage inter-satellite links (ISLs) to provide\nfaster and more reliable communications compared to traditional bent-pipe\narchitectures, even in remote regions. However, the high mobility of\nsatellites, dynamic traffic patterns, and potential link failures pose\nsignificant challenges for efficient and resilient routing. To address these\nchallenges, we model the LEO satellite network as a time-varying graph\ncomprising a constellation of satellites and ground stations. Our objective is\nto minimize a weighted sum of average delay and packet drop rate. Each\nsatellite independently decides how to distribute its incoming traffic to\nneighboring nodes in real time. Given the infeasibility of finding optimal\nsolutions at scale, due to the exponential growth of routing options and\nuncertainties in link capacities, we propose SKYLINK, a novel fully distributed\nlearning strategy for link management in LEO satellite networks. SKYLINK\nenables each satellite to adapt to the time-varying network conditions,\nensuring real-time responsiveness, scalability to millions of users, and\nresilience to network failures, while maintaining low communication overhead\nand computational complexity. To support the evaluation of SKYLINK at global\nscale, we develop a new simulator for large-scale LEO satellite networks. For\n25.4 million users, SKYLINK reduces the weighted sum of average delay and drop\nrate by 29% compared to the bent-pipe approach, and by 92% compared to\nDijkstra. It lowers drop rates by 95% relative to k-shortest paths, 99%\nrelative to Dijkstra, and 74% compared to the bent-pipe baseline, while\nachieving up to 46% higher throughput. At the same time, SKYLINK maintains\nconstant computational complexity with respect to constellation size.\n","authors":["Wanja de Sombre","Arash Asadi","Debopam Bhattacherjee","Deepak Vasisht","Andrea Ortiz"],"pdf_url":"https://arxiv.org/pdf/2509.08455v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2509.08378v1","updated":"2025-09-10T08:15:44Z","published":"2025-09-10T08:15:44Z","title":"A Planning Strategy for Building a Heterogeneous Smart EM Environment","summary":"  This paper presents a planning strategy for the deployment of smart\nelectromagnetic entities (SEEs) to enhance the wireless coverage and the\nQuality-of-Service (QoS) in large urban areas. The integration of different\ntechnological solutions such as integrated access-and-backhaul nodes (IABs),\nsmart repeaters (SRs), and electromagnetic skins (EMSs) is here addressed to\nenable an effective and efficient implementation of the concept of Smart\nElectromagnetic Environment (SEME). By combining the features of such\nheterogeneous SEEs and optimizing their number, positions, orientations, and\nconfiguration, the electromagnetic (EM) coverage in a set of\nRegions-of-Interest (RoIs) of outdoor scenarios is recovered and/or enhanced\nsubject to installation costs and energy consumption requirements. Numerical\nvalidations from real-world scenarios are reported to assess the effectiveness\nof the proposed planning scheme as well as to show the potentialities of an\nheterogeneous deployment of SEMEs.\n","authors":["Arianna Benoni","Marco Salucci","Baozhu Li","Andrea Massa"],"pdf_url":"https://arxiv.org/pdf/2509.08378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.23509v3","updated":"2025-09-10T07:47:37Z","published":"2025-06-30T04:20:40Z","title":"Power-Gas Infrastructure Planning under Weather-induced Supply and\n  Demand Uncertainties","summary":"  Implementing economy-wide decarbonization strategies based on decarbonizing\nthe power grid via variable renewable energy (VRE) expansion and\nelectrification of end-uses requires new approaches for energy infrastructure\nplanning that consider, among other factors, weather-induced uncertainty in\ndemand and VRE supply. An energy planning model that fails to account for these\nuncertainties can hinder the intended transition efforts to a low-carbon grid\nand increase the risk of supply shortage especially during extreme weather\nconditions. Here, we consider the generation and transmission expansion problem\nof joint power-gas infrastructure and operations planning under the uncertainty\nof both demand and renewable supply. We propose two distributionally robust\noptimization approaches based on moment (MDRO) and Wasserstein distance (WDRO)\nambiguity sets to endogenize these uncertainties and account for the change in\nthe underlying distribution of these parameters that is caused by the climate\nchange, among other factors. Furthermore, our model considers the risk-aversion\nof the energy planners in the modeling framework via the conditional\nvalue-at-risk (CVaR) metric. An equivalent mixed-integer linear programming\n(MILP) reformulation of both modeling frameworks is presented, and a\ncomputationally efficient approximation scheme to obtain near-optimal solutions\nis proposed. We demonstrate the resulting DRO planning models and solution\nstrategy via a New England case study under different levels of end-use\nelectrification and decarbonization targets. Our experiments systematically\nexplore different modeling aspects and compare the DRO models with stochastic\nprogramming (SP) results.\n","authors":["Rahman Khorramfar","Dharik Mallapragada","Saurabh Amin"],"pdf_url":"https://arxiv.org/pdf/2506.23509v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.07009v2","updated":"2025-09-10T07:42:47Z","published":"2025-09-06T10:22:27Z","title":"Computational Concept of the Psyche (in Russian)","summary":"  The article provides an overview of approaches to modeling the human psyche\nin the perspective of building an artificial one. Based on the review, a\nconcept of cognitive architecture is proposed, where the psyche is considered\nas an operating system of a living or artificial subject, including a space of\nneeds that determines its life meanings in connection with stimuli from the\nexternal world, and intelligence as a decision-making system for actions in\nrelation to this world in order to satisfy these needs. Based on the concept, a\ncomputational formalization is proposed for creating artificial intelligence\nsystems through learning from experience in the space of a space of needs,\ntaking into account their biological or existential significance for an\nintelligent agent. Thus, the problem of building general artificial\nintelligence as a system for making optimal decisions in the space of\nagent-specific needs under conditions of uncertainty is formalized, with\nmaximization of success in achieving goals, minimization of existential risks\nand maximization of energy efficiency. A minimal experimental implementation of\nthe model is also provided.\n","authors":["Anton Kolonin","Vladimir Kryukov"],"pdf_url":"https://arxiv.org/pdf/2509.07009v2.pdf","comment":"14 pages, in Russian, 2 figures, submitted to Neuroinformatics-2025\n  conference"},{"id":"http://arxiv.org/abs/2509.08343v1","updated":"2025-09-10T07:30:56Z","published":"2025-09-10T07:30:56Z","title":"AP-observation Automata for Abstraction-based Verification of\n  Continuous-time Systems (Extended Version)","summary":"  A key challenge in abstraction-based verification and control under complex\nspecifications such as Linear Temporal Logic (LTL) is that abstract models\nretain significantly less information than their original systems. This issue\nis especially true for continuous-time systems, where the system state\ntrajectories are split into intervals of discrete actions, and satisfaction of\natomic propositions is abstracted to a whole time interval. To tackle this\nchallenge, this work introduces a novel translation from LTL specifications to\nAP-observation automata, a particular type of B\\\"uchi automata specifically\ndesigned for abstraction-based verification. Based on this automaton, we\npresent a game-based verification algorithm played between the system and the\nenvironment, and an illustrative example for abstraction-based system\nverification under several LTL specifications.\n","authors":["Sasinee Pruekprasert","Clovis Eberhart"],"pdf_url":"https://arxiv.org/pdf/2509.08343v1.pdf","comment":"This is an extended version of the paper under the same title\n  accepted for presentation at the 22nd International Colloquium on Theoretical\n  Aspects of Computing (ICTAC 2025)"},{"id":"http://arxiv.org/abs/2509.08324v1","updated":"2025-09-10T06:59:22Z","published":"2025-09-10T06:59:22Z","title":"Resilient Global Practical Fixed-Time Cooperative Output Regulation of\n  Uncertain Nonlinear Multi-Agent Systems Subject to Denial-of-Service Attacks","summary":"  This paper investigates the problem of resilient global practical fixed-time\ncooperative output regulation of uncertain nonlinear multi-agent systems\nsubject to denial-of-service attacks. A novel distributed resilient adaptive\nfixed-time control strategy is proposed, which consists of a novel distributed\nresilient fixed-time observer with a chain of nonlinear filters and a novel\ndistributed resilient adaptive fixed-time controller. It is shown that the\nproblem of resilient global practical fixed-time cooperative output regulation\ncan be solved by the proposed control strategy. More specifically, the proposed\n{distributed} control strategy ensures the global boundedness of all the\nsignals in the resulting closed-loop system and the global convergence of the\nregulated outputs to a {tunable} residual set in a fixed time. A simulation\nexample is finally provided to illustrate the efficacy of the proposed control\nstrategy.\n","authors":["Wenji Cao","Lu Liu","Zehua Ye","Dan Zhang","Gang Feng"],"pdf_url":"https://arxiv.org/pdf/2509.08324v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08310v1","updated":"2025-09-10T06:07:34Z","published":"2025-09-10T06:07:34Z","title":"Game-Theoretic Resilience Framework for Cyber-Physical Microgrids using\n  Multi-Agent Reinforcement Learning","summary":"  The increasing reliance on cyber physical infrastructure in modern power\nsystems has amplified the risk of targeted cyber attacks, necessitating robust\nand adaptive resilience strategies. This paper presents a mathematically\nrigorous game theoretic framework to evaluate and enhance microgrid resilience\nusing a combination of quantitative resilience metrics Load Served Ratio LSR,\nCritical Load Resilience CLR, Topological Survivability Score TSS, and DER\nResilience Score DRS. These are integrated into a unified payoff matrix using\nthe Analytic Hierarchy Process AHP to assess attack defense interactions. The\nframework is formalized as a finite horizon Markov Decision Process MDP with\nformal convergence guarantees and computational complexity bounds. Three case\nstudies are developed 1. static attacks analyzed via Nash equilibrium, 2.\nsevere attacks incorporating high impact strategies, and 3. adaptive attacks\nusing Stackelberg games, regret matching, softmax heuristics, and Multi Agent Q\nLearning. Rigorous theoretical analysis provides convergence proofs with\nexplicit rates , PAC learning sample complexity bounds, and computational\ncomplexity analysis. The framework is tested on an enhanced IEEE 33bus\ndistribution system with DERs and control switches, demonstrating the\neffectiveness of adaptive and strategic defenses in improving cyber physical\nresilience with statistically significant improvements of 18.7% 2.1% over\nstatic approaches.\n","authors":["S Krishna Niketh","Sagar Babu Mitikiri","V Vignesh","Vedantham Lakshmi Srinivas","Mayukha Pal"],"pdf_url":"https://arxiv.org/pdf/2509.08310v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.03120v3","updated":"2025-09-10T04:02:49Z","published":"2025-04-04T02:22:21Z","title":"Distributed Resilience-Aware Control in Multi-Robot Networks","summary":"  Ensuring resilient consensus in multi-robot systems with misbehaving agents\nremains a challenge, as many existing network resilience properties are\ninherently combinatorial and globally defined. While previous works have\nproposed control laws to enhance or preserve resilience in multi-robot\nnetworks, they often assume a fixed topology with known resilience properties,\nor require global state knowledge. These assumptions may be impractical in\nphysically-constrained environments, where safety and resilience requirements\nare conflicting, or when misbehaving agents share inaccurate state information.\nIn this work, we propose a distributed control law that enables each robot to\nguarantee resilient consensus and safety during its navigation without fixed\ntopologies using only locally available information. To this end, we establish\na sufficient condition for resilient consensus in time-varying networks based\non the degree of non-misbehaving or normal agents. Using this condition, we\ndesign a Control Barrier Function (CBF)-based controller that guarantees\nresilient consensus and collision avoidance without requiring estimates of\nglobal state and/or control actions of all other robots. Finally, we validate\nour method through simulations.\n","authors":["Haejoon Lee","Dimitra Panagou"],"pdf_url":"https://arxiv.org/pdf/2504.03120v3.pdf","comment":"Accepted and will appear at 2025 IEEE Conference on Decision and\n  Control (CDC)"},{"id":"http://arxiv.org/abs/2509.08242v1","updated":"2025-09-10T02:52:45Z","published":"2025-09-10T02:52:45Z","title":"Behaviorally Heterogeneous Multi-Agent Exploration Using Distributed\n  Task Allocation","summary":"  We study a problem of multi-agent exploration with behaviorally heterogeneous\nrobots. Each robot maps its surroundings using SLAM and identifies a set of\nareas of interest (AoIs) or frontiers that are the most informative to explore\nnext. The robots assess the utility of going to a frontier using Behavioral\nEntropy (BE) and then determine which frontier to go to via a distributed task\nassignment scheme. We convert the task assignment problem into a\nnon-cooperative game and use a distributed algorithm (d-PBRAG) to converge to\nthe Nash equilibrium (which we show is the optimal task allocation solution).\nFor unknown utility cases, we provide robust bounds using approximate rewards.\nWe test our algorithm (which has less communication cost and fast convergence)\nin simulation, where we explore the effect of sensing radii, sensing accuracy,\nand heterogeneity among robotic teams with respect to the time taken to\ncomplete exploration and path traveled. We observe that having a team of agents\nwith heterogeneous behaviors is beneficial.\n","authors":["Nirabhra Mandal","Aamodh Suresh","Carlos Nieto-Granda","Sonia Martínez"],"pdf_url":"https://arxiv.org/pdf/2509.08242v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2509.08241v1","updated":"2025-09-10T02:47:42Z","published":"2025-09-10T02:47:42Z","title":"Sample-Efficient Online Control Policy Learning with Real-Time Recursive\n  Model Updates","summary":"  Data-driven control methods need to be sample-efficient and lightweight,\nespecially when data acquisition and computational resources are limited --\nsuch as during learning on hardware. Most modern data-driven methods require\nlarge datasets and struggle with real-time updates of models, limiting their\nperformance in dynamic environments. Koopman theory formally represents\nnonlinear systems as linear models over observables, and Koopman\nrepresentations can be determined from data in an optimization-friendly setting\nwith potentially rapid model updates. In this paper, we present a highly\nsample-efficient, Koopman-based learning pipeline: Recursive Koopman Learning\n(RKL). We identify sufficient conditions for model convergence and provide\nformal algorithmic analysis supporting our claim that RKL is lightweight and\nfast, with complexity independent of dataset size. We validate our method on a\nsimulated planar two-link arm and a hybrid nonlinear hardware system with soft\nactuators, showing that real-time recursive Koopman model updates improve the\nsample efficiency and stability of data-driven controller synthesis --\nrequiring only <10% of the data compared to benchmarks. The high-performance\nC++ codebase is open-sourced. Website:\nhttps://www.zixinatom990.com/home/robotics/corl-2025-recursive-koopman-learning.\n","authors":["Zixin Zhang","James Avtges","Todd D. Murphey"],"pdf_url":"https://arxiv.org/pdf/2509.08241v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08238v1","updated":"2025-09-10T02:42:08Z","published":"2025-09-10T02:42:08Z","title":"Joint Optimization of Computation Offloading and Resource Allocation in\n  ISAC-assisted SAGIN-based IoT","summary":"  In this letters, an energy-efficient integrated sensing and communication\n(ISAC) for space-air-ground integrated network (SAGIN)-based Internet of Things\n(IoT) systems is proposed to facilitate wide coverage and real-time 6G\nservices. For processing a sizable data collected at a IoT device, a hybrid\nedge computing scheme is applied with the cloudlets mounted at autonomous\naerial vehicle (AAV) and low earth orbit (LEO) satellite, where the AAV with\nmultiple antennas performs uplink sensing of the nearby target. With the aim of\nminimizing the total AAV's energy consumption, we optimize the duration of\ntraining and data phase and the bit allocation coupled with the offloading\nratio under the constraints for offloading and sensing. Via simulations, the\nsuperiority of the proposed algorithm is verified to be pronounced with the\nsufficient mission time and the high sensing performance constraint.\n","authors":["Sooyeob Jung","Seongah Jeong","Jinkyu Kang"],"pdf_url":"https://arxiv.org/pdf/2509.08238v1.pdf","comment":"5 pages, 4 figures,"},{"id":"http://arxiv.org/abs/2509.08201v1","updated":"2025-09-10T00:14:32Z","published":"2025-09-10T00:14:32Z","title":"Multivariable Current Controller for Enhancing Dynamic Response and Grid\n  Synchronization Stability of IBRs","summary":"  This paper develops a multivariable current control strategy for\ninverter-based resources (IBRs) based on optimal control theory to enhance\ntheir dynamic performance and grid synchronization stability. The structure of\nthe implemented multiple-input, multiple-output (MIMO) controller closely\nresembles that of the commonly used conventional single-input, single-output\n(SISO) PI controllers for IBRs. As a result, it requires only minor adjustments\nto conventional vector current control schemes, thereby facilitating its\nstraightforward adoption. Time-domain simulations and analytical analysis\ndemonstrate the superior performance of the developed method under various\nconditions and use case scenarios, such as weak power systems and uncertain\nparameters.\n","authors":["Hassan Yazdani","Ali Maleki","Saeed Lotfifard","Ali Saberi"],"pdf_url":"https://arxiv.org/pdf/2509.08201v1.pdf","comment":"8 pages, 12 figures"},{"id":"http://arxiv.org/abs/2509.09048v1","updated":"2025-09-10T22:55:07Z","published":"2025-09-10T22:55:07Z","title":"Decentralized Local Voltage Control for Active Distribution Networks","summary":"  Distribution networks face challenges from the increasing deployment of\nDistributed Energy Resources (DERs) and the emergence of bidirectional power\nflows. We propose a decentralized Volt/VAr control method based on a\nsaddle-point reformulation and consensus+innovation (C+I) updates. Each agent\nat a controllable bus computes and enforces its own set-points using only\nneighbor communication. Our method embeds passive buses directly, preserves\nnetwork physics through a linearized Jacobian model, and avoids any supervisory\nnodes. Simulation results on a modified CIGRE low-voltage network show voltage\nstability improvement within operational limits, indicating the viability of a\nfully decentralized (edge-based) Volt/VAr control solution.\n","authors":["Diana Vieira Fernandes","Soummya Kar","Carlos Santos Silva"],"pdf_url":"https://arxiv.org/pdf/2509.09048v1.pdf","comment":"To appear in IEEE SmartGridComm'25 - 2025 IEEE International\n  Conference on Communications, Control, and Computing Technologies for Smart\n  Grids (SmartGridComm)"},{"id":"http://arxiv.org/abs/2509.09044v1","updated":"2025-09-10T22:41:18Z","published":"2025-09-10T22:41:18Z","title":"Design of Reliable and Resilient Electric Power Systems for Wide-Body\n  All-Electric Aircraft","summary":"  To achieve net-zero emissions by 2050, all-electric transportation is a\npromising option. In the U.S., the transportation sector contributes the\nlargest share (29 percent) of greenhouse gas emissions. While electric vehicles\nare approaching maturity, aviation is only beginning to develop electrified\naircraft for commercial flights. More than 75 percent of aviation emissions\ncome from large aircraft, and this impact will worsen with 4-5 percent annual\nair travel growth. Aircraft electrification has led to two types: more electric\naircraft (MEA) and all-electric aircraft (AEA). A MEA replaces subsystems such\nas hydraulics with electric alternatives, whereas an AEA uses electrically\ndriven subsystems and provides thrust fully from electrochemical energy units\n(EEUs). For wide-body AEA, thrust demand is about 25 MW plus 1 MW for\nnon-thrust loads, creating major challenges for electric power system (EPS)\ndesign. Achieving maximum power density requires minimizing mass and volume.\nIncreasing voltage into the kilovolt range using medium-voltage direct current\n(MVDC) is a feasible option to enhance power transfer. Consequently, designing\nan MVDC EPS for wide-body AEA is critical. Because EPS failures could\njeopardize passenger safety, reliability and resilience are essential. This\nchapter presents a load-flow model for DC systems to determine power flows in\nboth normal and single-contingency conditions, followed by analysis of optimal\nMVDC EPS architectures. A complete EPS for wide-body AEA is introduced, with\nEEUs and non-propulsion loads located, distances estimated, and flow studies\nperformed. Multiple architectures are evaluated for reliability, power density,\npower loss, and cost to identify optimal solutions.\n","authors":["Mona Ghassemi"],"pdf_url":"https://arxiv.org/pdf/2509.09044v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.10647v3","updated":"2025-09-10T22:19:29Z","published":"2023-12-17T08:19:59Z","title":"Single-Stage Optimization of Open-loop Stable Limit Cycles with Smooth,\n  Symbolic Derivatives","summary":"  Open-loop stable limit cycles are foundational to legged robotics, providing\ninherent self-stabilization that minimizes the need for computationally\nintensive feedback-based gait correction. While previous methods have primarily\ntargeted specific robotic models, this paper introduces a general framework for\nrapidly generating limit cycles across various dynamical systems, with the\nflexibility to impose arbitrarily tight stability bounds. We formulate the\nproblem as a single-stage constrained optimization problem and use Direct\nCollocation to transcribe it into a nonlinear program with closed-form\nexpressions for constraints, objectives, and their gradients.\n  Our method supports multiple stability formulations. In particular, we tested\ntwo popular formulations for limit cycle stability in robotics: (1) based on\nthe spectral radius of a discrete return map, and (2) based on the spectral\nradius of the monodromy matrix, and tested five different\nconstraint-satisfaction formulations of the eigenvalue problem to bound the\nspectral radius. We compare the performance and solution quality of the various\nformulations on a robotic swing-leg model, highlighting the Schur decomposition\nof the monodromy matrix as a method with broader applicability due to weaker\nassumptions and stronger numerical convergence properties.\n  As a case study, we apply our method on a hopping robot model, generating\nopen-loop stable gaits in under 2 seconds on an Intel Core i7-6700K, while\nsimultaneously minimizing energy consumption even under tight stability\nconstraints.\n","authors":["Muhammad Saud Ul Hassan","Christian Hubicki"],"pdf_url":"https://arxiv.org/pdf/2312.10647v3.pdf","comment":"Accepted at IEEE International Conference on Robotics and Automation\n  (ICRA) 2025"},{"id":"http://arxiv.org/abs/2509.09027v1","updated":"2025-09-10T21:54:13Z","published":"2025-09-10T21:54:13Z","title":"Regularization in Data-driven Predictive Control: A Convex Relaxation\n  Perspective","summary":"  This paper explores the role of regularization in data-driven predictive\ncontrol (DDPC) through the lens of convex relaxation. Using a bi-level\noptimization framework, we model system identification as an inner problem and\npredictive control as an outer problem. Within this framework, we show that\nseveral regularized DDPC formulations, including l1-norm penalties,\nprojection-based regularizers, and a newly introduced causality-based\nregularizer, can be viewed as convex relaxations of their respective bi-level\nproblems. This perspective clarifies the conceptual links between direct and\nindirect data-driven control and highlights how regularization implicitly\nenforces system identification. We further propose an optimality-based variant,\nO-DDPC, which approximately solves the inner problem with all identification\nconstraints via an iterative algorithm. Numerical experiments demonstrate that\nO-DDPC outperforms existing regularized DDPC by reducing both bias and variance\nerrors. These results indicate that further benefits may be obtained by\napplying system identification techniques to pre-process the trajectory library\nin nonlinear settings. Overall, our analysis contributes to a unified convex\nrelaxation view of regularization in DDPC and sheds light on its strong\nempirical performance beyond linear time-invariant systems.\n","authors":["Xu Shang","Yang Zheng"],"pdf_url":"https://arxiv.org/pdf/2509.09027v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08976v1","updated":"2025-09-10T20:20:12Z","published":"2025-09-10T20:20:12Z","title":"Toward a Multi-Echelon Cyber Warfare Theory: A Meta-Game-Theoretic\n  Paradigm for Defense and Dominance","summary":"  Cyber warfare has become a central element of modern conflict, especially\nwithin multi-domain operations. As both a distinct and critical domain, cyber\nwarfare requires integrating defensive and offensive technologies into coherent\nstrategies. While prior research has emphasized isolated tactics or fragmented\ntechnologies, a holistic understanding is essential for effective resource\ndeployment and risk mitigation. Game theory offers a unifying framework for\nthis purpose. It not only models attacker-defender interactions but also\nprovides quantitative tools for equilibrium analysis, risk assessment, and\nstrategic reasoning. Integrated with modern AI techniques, game-theoretic\nmodels enable the design and optimization of strategies across multiple levels\nof cyber warfare, from policy and strategy to operations, tactics, and\ntechnical implementations. These models capture the paradoxical logic of\nconflict, where more resources do not always translate into greater advantage,\nand where nonlinear dynamics govern outcomes. To illustrate the approach, this\nchapter examines RedCyber, a synthetic cyber conflict, demonstrating how\ngame-theoretic methods capture the interdependencies of cyber operations. The\nchapter concludes with directions for future research on resilience,\ncros-echelon planning, and the evolving role of AI in cyber warfare.\n","authors":["Ya-Ting Yang","Quanyan Zhu"],"pdf_url":"https://arxiv.org/pdf/2509.08976v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08968v1","updated":"2025-09-10T19:57:45Z","published":"2025-09-10T19:57:45Z","title":"Efficient High-Order Participation Factor Computation via\n  Batch-Structured Tensor Contraction","summary":"  Participation factors (PFs) quantify the interaction between system modes and\nstate variables, and they play a crucial role in various applications such as\nmodal analysis, model reduction, and control design. With increasing system\ncomplexity, especially due to power electronic devices and renewable\nintegration, the need for scalable and high-order nonlinear PF (NPF)\ncomputation has become more critical. This paper presents an efficient\ntensor-based method for calculating NPFs up to an arbitrary order. Traditional\ncomputation of PFs directly from normal form theory is computationally\nexpensive -- even for second-order PFs -- and becomes infeasible for higher\norders due to memory constraints. To address this, a tensor contraction-based\napproach is introduced that enables the calculation of high-order PFs using a\nbatching strategy. The batch sizes are dynamically determined based on the\navailable computational resources, allowing scalable and memory-efficient\ncomputation.\n","authors":["Mahsa Sajjadi","Kaiyang Huang","Kai Sun"],"pdf_url":"https://arxiv.org/pdf/2509.08968v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08956v1","updated":"2025-09-10T19:30:04Z","published":"2025-09-10T19:30:04Z","title":"Multi-Agent Inverse Reinforcement Learning for Identifying\n  Pareto-Efficient Coordination -- A Distributionally Robust Approach","summary":"  Multi-agent inverse reinforcement learning (IRL) aims to identify\nPareto-efficient behavior in a multi-agent system, and reconstruct utility\nfunctions of the individual agents. Motivated by the problem of detecting UAV\ncoordination, how can we construct a statistical detector for Pareto-efficient\nbehavior given noisy measurements of the decisions of a multi-agent system?\nThis paper approaches this IRL problem by deriving necessary and sufficient\nconditions for a dataset of multi-agent system dynamics to be consistent with\nPareto-efficient coordination, and providing algorithms for recovering utility\nfunctions which are consistent with the system dynamics. We derive an optimal\nstatistical detector for determining Pareto-efficient coordination from noisy\nsystem measurements, which minimizes Type-I statistical detection error. Then,\nwe provide a utility estimation algorithm which minimizes the worst-case\nestimation error over a statistical ambiguity set centered at empirical\nobservations; this min-max solution achieves distributionally robust IRL, which\nis crucial in adversarial strategic interactions. We illustrate these results\nin a detailed example for detecting Pareto-efficient coordination among\nmultiple UAVs given noisy measurement recorded at a radar. We then reconstruct\nthe utility functions of the UAVs in a distributionally robust sense.\n","authors":["Luke Snow","Vikram Krishnamurthy"],"pdf_url":"https://arxiv.org/pdf/2509.08956v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.01878v2","updated":"2025-09-10T19:02:54Z","published":"2025-04-02T16:33:21Z","title":"Tunable Thresholds and Frequency Encoding in a Spiking NOD Controller","summary":"  Spiking Nonlinear Opinion Dynamics (S-NOD) is an excitable decision-making\nmodel inspired by the spiking dynamics of neurons. S-NOD enables the design of\nagile decision-making that can rapidly switch between decision options in\nresponse to a changing environment. In S-NOD, decisions are represented by\ndiscrete opinion spikes that evolve in continuous time. Here, we extend\nprevious analysis of S-NOD and explore its potential as a nonlinear controller\nwith a tunable balance between robustness and responsiveness to input. We\nidentify and provide necessary conditions for the bifurcation that determines\nthe onset of periodic opinion spiking. We leverage this analysis to\ncharacterize the tunability of the input-output threshold for opinion spiking\nas a function of the model basal sensitivity and the tunable dependence of\nopinion spiking frequency on input magnitude above the threshold. We conclude\nwith a discussion of S-NOD as a new neuromorphic control block and its\nextension to distributed spiking controllers.\n","authors":["Ian Xul Belaustegui","Alessio Franci","Naomi Ehrich Leonard"],"pdf_url":"https://arxiv.org/pdf/2504.01878v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08933v1","updated":"2025-09-10T18:56:39Z","published":"2025-09-10T18:56:39Z","title":"Corruption-Tolerant Asynchronous Q-Learning with Near-Optimal Rates","summary":"  We consider the problem of learning the optimal policy in a discounted,\ninfinite-horizon reinforcement learning (RL) setting where the reward signal is\nsubject to adversarial corruption. Such corruption, which may arise from\nextreme noise, sensor faults, or malicious attacks, can severely degrade the\nperformance of classical algorithms such as Q-learning. To address this\nchallenge, we propose a new provably robust variant of the Q-learning algorithm\nthat operates effectively even when a fraction of the observed rewards are\narbitrarily perturbed by an adversary. Under the asynchronous sampling model\nwith time-correlated data, we establish that despite adversarial corruption,\nthe finite-time convergence rate of our algorithm matches that of existing\nresults for the non-adversarial case, up to an additive term proportional to\nthe fraction of corrupted samples. Moreover, we derive an information-theoretic\nlower bound revealing that the additive corruption term in our upper bounds is\nunavoidable.\n  Next, we propose a variant of our algorithm that requires no prior knowledge\nof the statistics of the true reward distributions. The analysis of this\nsetting is particularly challenging and is enabled by carefully exploiting a\nrefined Azuma-Hoeffding inequality for almost-martingales, a technical tool\nthat might be of independent interest. Collectively, our contributions provide\nthe first finite-time robustness guarantees for asynchronous Q-learning,\nbridging a significant gap in robust RL.\n","authors":["Sreejeet Maity","Aritra Mitra"],"pdf_url":"https://arxiv.org/pdf/2509.08933v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08914v1","updated":"2025-09-10T18:19:19Z","published":"2025-09-10T18:19:19Z","title":"Bridging Centralized and Distributed Frameworks in Unknown Input\n  Observer Design","summary":"  State estimation for linear time-invariant systems with unknown inputs is a\nfundamental problem in various research domains. In this article, we establish\nconditions for the design of unknown input observers (UIOs) from a geometric\napproach perspective. Specifically, we derive a necessary and sufficient\ngeometric condition for the existence of a centralized UIO. Compared to\nexisting results, our condition offers a more general design framework,\nallowing designers the flexibility to estimate partial information of the\nsystem state. Furthermore, we extend the centralized UIO design to distributed\nsettings. In contrast to existing distributed UIO approaches, which require\neach local node to satisfy the rank condition regarding the unknown input and\noutput matrices, our method accommodates cases where a subset of nodes does not\nmeet this requirement. This relaxation significantly broadens the range of\npractical applications. Simulation results are provided to demonstrate the\neffectiveness of the proposed design.\n","authors":["Ruixuan Zhao","Guitao Yang","Peng Li","Boli Chen"],"pdf_url":"https://arxiv.org/pdf/2509.08914v1.pdf","comment":null}],"Hardware Architecture":[{"id":"http://arxiv.org/abs/2509.08727v1","updated":"2025-09-10T16:17:31Z","published":"2025-09-10T16:17:31Z","title":"Securing Cryptographic Software via Typed Assembly Language (Extended\n  Version)","summary":"  Authors of cryptographic software are well aware that their code should not\nleak secrets through its timing behavior, and, until 2018, they believed that\nfollowing industry-standard constant-time coding guidelines was sufficient.\nHowever, the revelation of the Spectre family of speculative execution attacks\ninjected new complexities.\n  To block speculative attacks, prior work has proposed annotating the\nprogram's source code to mark secret data, with hardware using this information\nto decide when to speculate (i.e., when only public values are involved) or not\n(when secrets are in play). While these solutions are able to track secret\ninformation stored on the heap, they suffer from limitations that prevent them\nfrom correctly tracking secrets on the stack, at a cost in performance.\n  This paper introduces SecSep, a transformation framework that rewrites\nassembly programs so that they partition secret and public data on the stack.\nBy moving from the source-code level to assembly rewriting, SecSep is able to\naddress limitations of prior work. The key challenge in performing this\nassembly rewriting stems from the loss of semantic information through the\nlengthy compilation process. The key innovation of our methodology is a new\nvariant of typed assembly language (TAL), Octal, which allows us to address\nthis challenge. Assembly rewriting is driven by compile-time inference within\nOctal. We apply our technique to cryptographic programs and demonstrate that it\nenables secure speculation efficiently, incurring a low average overhead of\n$1.2\\%$.\n","authors":["Shixin Song","Tingzhen Dong","Kosi Nwabueze","Julian Zanders","Andres Erbsen","Adam Chlipala","Mengjia Yan"],"pdf_url":"https://arxiv.org/pdf/2509.08727v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08542v1","updated":"2025-09-10T12:46:29Z","published":"2025-09-10T12:46:29Z","title":"BitROM: Weight Reload-Free CiROM Architecture Towards Billion-Parameter\n  1.58-bit LLM Inference","summary":"  Compute-in-Read-Only-Memory (CiROM) accelerators offer outstanding energy\nefficiency for CNNs by eliminating runtime weight updates. However, their\nscalability to Large Language Models (LLMs) is fundamentally constrained by\ntheir vast parameter sizes. Notably, LLaMA-7B - the smallest model in LLaMA\nseries - demands more than 1,000 cm2 of silicon area even in advanced CMOS\nnodes. This paper presents BitROM, the first CiROM-based accelerator that\novercomes this limitation through co-design with BitNet's 1.58-bit quantization\nmodel, enabling practical and efficient LLM inference at the edge. BitROM\nintroduces three key innovations: 1) a novel Bidirectional ROM Array that\nstores two ternary weights per transistor; 2) a Tri-Mode Local Accumulator\noptimized for ternary-weight computations; and 3) an integrated Decode-Refresh\n(DR) eDRAM that supports on-die KV-cache management, significantly reducing\nexternal memory access during decoding. In addition, BitROM integrates\nLoRA-based adapters to enable efficient transfer learning across various\ndownstream tasks. Evaluated in 65nm CMOS, BitROM achieves 20.8 TOPS/W and a bit\ndensity of 4,967 kB/mm2 - offering a 10x improvement in area efficiency over\nprior digital CiROM designs. Moreover, the DR eDRAM contributes to a 43.6%\nreduction in external DRAM access, further enhancing deployment efficiency for\nLLMs in edge applications.\n","authors":["Wenlun Zhang","Xinyu Li","Shimpei Ando","Kentaro Yoshioka"],"pdf_url":"https://arxiv.org/pdf/2509.08542v1.pdf","comment":"Accepted to ASP-DAC 2026"},{"id":"http://arxiv.org/abs/2509.08416v1","updated":"2025-09-10T09:00:32Z","published":"2025-09-10T09:00:32Z","title":"AutoVeriFix: Automatically Correcting Errors and Enhancing Functional\n  Correctness in LLM-Generated Verilog Code","summary":"  Large language models (LLMs) have demonstrated impressive capabilities in\ngenerating software code for high-level programming languages such as Python\nand C++. However, their application to hardware description languages, such as\nVerilog, is challenging due to the scarcity of high-quality training data.\nCurrent approaches to Verilog code generation using LLMs often focus on\nsyntactic correctness, resulting in code with functional errors. To address\nthese challenges, we present AutoVeriFix, a novel Python-assisted two-stage\nframework designed to enhance the functional correctness of LLM-generated\nVerilog code. In the first stage, LLMs are employed to generate high-level\nPython reference models that define the intended circuit behavior. In the\nsecond stage, these Python models facilitate the creation of automated tests\nthat guide the generation of Verilog RTL implementations. Simulation\ndiscrepancies between the reference model and the Verilog code are iteratively\nused to identify and correct errors, thereby improving the functional accuracy\nand reliability of the LLM-generated Verilog code. Experimental results\ndemonstrate that our approach significantly outperforms existing\nstate-of-the-art methods in improving the functional correctness of generated\nVerilog code.\n","authors":["Yan Tan","Xiangchen Meng","Zijun Jiang","Yangdi Lyu"],"pdf_url":"https://arxiv.org/pdf/2509.08416v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08405v1","updated":"2025-09-10T08:54:04Z","published":"2025-09-10T08:54:04Z","title":"FASE: FPGA-Assisted Syscall Emulation for Rapid End-to-End Processor\n  Performance Validation","summary":"  The rapid advancement of AI workloads and domain-specific architectures has\nled to increasingly diverse processor microarchitectures, whose design\nexploration requires fast and accurate performance validation. However,\ntraditional workflows defer validation process until RTL design and SoC\nintegration are complete, significantly prolonging development and iteration\ncycle.\n  In this work, we present FASE framework, FPGA-Assisted Syscall Emulation, the\nfirst work for adapt syscall emulation on FPGA platforms, enabling complex\nmulti-thread benchmarks to directly run on the processor design without\nintegrating SoC or target OS for early-stage performance validation. FASE\nintroduces three key innovations to address three critical challenges for\nadapting FPGA-based syscall emulation: (1) only a minimal CPU interface is\nexposed, with other hardware components untouched, addressing the lack of a\nunified hardware interface in FPGA systems; (2) a Host-Target Protocol (HTP) is\nproposed to minimize cross-device data traffic, mitigating the low-bandwidth\nand high-latency communication between FPGA and host; and (3) a host-side\nruntime is proposed to remotely handle Linux-style system calls, addressing the\nchallenge of cross-device syscall delegation.\n  Experiments ware conducted on Xilinx FPGA with open-sourced RISC-V SMP\nprocessor Rocket. With single-thread CoreMark, FASE introduces less than 1%\nperformance error and achieves over 2000x higher efficiency compared to Proxy\nKernel due to FPGA acceleration. With complex OpenMP benchmarks, FASE\ndemonstrates over 96% performance validation accuracy for most single-thread\nworkloads and over 91.5% for most multi-thread workloads compared to full SoC\nvalidation, significantly reducing development complexity and time-to-feedback.\nAll components of FASE framework are released as open-source.\n","authors":["Chengzhen Meng","Xiuzhuang Chen","Hongjun Dai"],"pdf_url":"https://arxiv.org/pdf/2509.08405v1.pdf","comment":"14 pages, 19 figures, to be submitted to IEEE TCAD"},{"id":"http://arxiv.org/abs/2509.08207v1","updated":"2025-09-10T00:30:05Z","published":"2025-09-10T00:30:05Z","title":"Aurora: Architecting Argonne's First Exascale Supercomputer for\n  Accelerated Scientific Discovery","summary":"  Aurora is Argonne National Laboratory's pioneering Exascale supercomputer,\ndesigned to accelerate scientific discovery with cutting-edge architectural\ninnovations. Key new technologies include the Intel(TM) Xeon(TM) Data Center\nGPU Max Series (code-named Sapphire Rapids) with support for High Bandwidth\nMemory (HBM), alongside the Intel(TM) Data Center GPU Max Series (code-named\nPonte Vecchio) on each compute node. Aurora also integrates the Distributed\nAsynchronous Object Storage (DAOS), a novel exascale storage solution, and\nleverages Intel's oneAPI programming environment. This paper presents an\nin-depth exploration of Aurora's node architecture, the HPE Slingshot\ninterconnect, the supporting software ecosystem, and DAOS. We provide insights\ninto standard benchmark performance and applications readiness efforts via\nAurora's Early Science Program and the Exascale Computing Project.\n","authors":["Benjamin S. Allen","James Anchell","Victor Anisimov","Thomas Applencourt","Abhishek Bagusetty","Ramesh Balakrishnan","Riccardo Balin","Solomon Bekele","Colleen Bertoni","Cyrus Blackworth","Renzo Bustamante","Kevin Canada","John Carrier","Christopher Chan-nui","Lance C. Cheney","Taylor Childers","Paul Coffman","Susan Coghlan","Michael D'Mello","Murali Emani","Kyle G. Felker","Sam Foreman","Olivier Franza","Longfei Gao","Marta García","María Garzarán","Balazs Gerofi","Yasaman Ghadar","Neha Gupta","Kevin Harms","Väinö Hatanpää","Brian Holland","Carissa Holohan","Brian Homerding","Khalid Hossain","Louise Huot","Huda Ibeid","Joseph A. Insley","Sai Jayanthi","Hong Jiang","Wei Jiang","Xiao-Yong Jin","Jeongnim Kim","Christopher Knight","Kalyan Kumaran","JaeHyuk Kwack","Ti Leggett","Ben Lenard","Chris Lewis","Nevin Liber","Johann Lombardi","Raymond M. Loy","Ye Luo","Bethany Lusch","Nilakantan Mahadevan","Victor A. Mateevitsi","Gordon McPheeters","Ryan Milner","Vitali A. Morozov","Servesh Muralidharan","Tom Musta","Mrigendra Nagar","Vikram Narayana","Marieme Ngom","Anthony-Trung Nguyen","Nathan Nichols","Aditya Nishtala","James C. Osborn","Michael E. Papka","Scott Parker","Saumil S. Patel","Adrian C. Pope","Sucheta Raghunanda","Esteban Rangel","Paul M. Rich","Silvio Rizzi","Kris Rowe","Varuni Sastry","Adam Scovel","Filippo Simini","Haritha Siddabathuni Som","Patrick Steinbrecher","Rick Stevens","Xinmin Tian","Peter Upton","Thomas Uram","Archit K. Vasan","Álvaro Vázquez-Mayagoitia","Kaushik Velusamy","Brice Videau","Venkatram Vishwanath","Brian Whitney","Timothy J. Williams","Michael Woodacre","Sam Zeltner","Gengbin Zheng","Huihuo Zheng"],"pdf_url":"https://arxiv.org/pdf/2509.08207v1.pdf","comment":"40 pages, 10 figures. Submitted to J. Supercomputing"}],"Programming Languages":[{"id":"http://arxiv.org/abs/2509.08804v1","updated":"2025-09-10T17:37:56Z","published":"2025-09-10T17:37:56Z","title":"Approximate Algorithms for Verifying Differential Privacy with Gaussian\n  Distributions","summary":"  The verification of differential privacy algorithms that employ Gaussian\ndistributions is little understood. This paper tackles the challenge of\nverifying such programs by introducing a novel approach to approximating\nprobability distributions of loop-free programs that sample from both discrete\nand continuous distributions with computable probability density functions,\nincluding Gaussian and Laplace. We establish that verifying\n$(\\epsilon,\\delta)$-differential privacy for these programs is \\emph{almost\ndecidable}, meaning the problem is decidable for all values of $\\delta$ except\nthose in a finite set. Our verification algorithm is based on computing\nprobabilities to any desired precision by combining integral approximations,\nand tail probability bounds. The proposed methods are implemented in the tool,\nDipApprox, using the FLINT library for high-precision integral computations,\nand incorporate optimizations to enhance scalability. We validate {\\ourtool} on\nfundamental privacy-preserving algorithms, such as Gaussian variants of the\nSparse Vector Technique and Noisy Max, demonstrating its effectiveness in both\nconfirming privacy guarantees and detecting violations.\n","authors":["Bishnu Bhusal","Rohit Chadha","A. Prasad Sistla","Mahesh Viswanathan"],"pdf_url":"https://arxiv.org/pdf/2509.08804v1.pdf","comment":"An extended abstract appears in CCS 2025"},{"id":"http://arxiv.org/abs/2509.08727v1","updated":"2025-09-10T16:17:31Z","published":"2025-09-10T16:17:31Z","title":"Securing Cryptographic Software via Typed Assembly Language (Extended\n  Version)","summary":"  Authors of cryptographic software are well aware that their code should not\nleak secrets through its timing behavior, and, until 2018, they believed that\nfollowing industry-standard constant-time coding guidelines was sufficient.\nHowever, the revelation of the Spectre family of speculative execution attacks\ninjected new complexities.\n  To block speculative attacks, prior work has proposed annotating the\nprogram's source code to mark secret data, with hardware using this information\nto decide when to speculate (i.e., when only public values are involved) or not\n(when secrets are in play). While these solutions are able to track secret\ninformation stored on the heap, they suffer from limitations that prevent them\nfrom correctly tracking secrets on the stack, at a cost in performance.\n  This paper introduces SecSep, a transformation framework that rewrites\nassembly programs so that they partition secret and public data on the stack.\nBy moving from the source-code level to assembly rewriting, SecSep is able to\naddress limitations of prior work. The key challenge in performing this\nassembly rewriting stems from the loss of semantic information through the\nlengthy compilation process. The key innovation of our methodology is a new\nvariant of typed assembly language (TAL), Octal, which allows us to address\nthis challenge. Assembly rewriting is driven by compile-time inference within\nOctal. We apply our technique to cryptographic programs and demonstrate that it\nenables secure speculation efficiently, incurring a low average overhead of\n$1.2\\%$.\n","authors":["Shixin Song","Tingzhen Dong","Kosi Nwabueze","Julian Zanders","Andres Erbsen","Adam Chlipala","Mengjia Yan"],"pdf_url":"https://arxiv.org/pdf/2509.08727v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.17233v2","updated":"2025-09-10T15:58:41Z","published":"2025-07-23T05:57:15Z","title":"Hiord#: An Approach to the Specification and Verification of\n  Higher-Order (C)LP Programs","summary":"  Higher-order constructs enable more expressive and concise code by allowing\nprocedures to be parameterized by other procedures. Assertions allow expressing\npartial program specifications, which can be verified either at compile time\n(statically) or run time (dynamically). In higher-order programs, assertions\ncan also describe higher-order arguments. While in the context of (constraint)\nlogic programming ((C)LP), run-time verification of higher-order assertions has\nreceived some attention, compile-time verification remains relatively\nunexplored. We propose a novel approach for statically verifying higher-order\n(C)LP programs with higher-order assertions. Although we use the Ciao assertion\nlanguage for illustration, our approach is quite general and we believe is\napplicable to similar contexts. Higher-order arguments are described using\npredicate properties -- a special kind of property which exploits the (Ciao)\nassertion language. We refine the syntax and semantics of these properties and\nintroduce an abstract criterion to determine conformance to a predicate\nproperty at compile time, based on a semantic order relation comparing the\npredicate property with the predicate assertions. We then show how to handle\nthese properties using an abstract interpretation-based static analyzer for\nprograms with first-order assertions by reducing predicate properties to\nfirst-order properties. Finally, we report on a prototype implementation and\nevaluate it through various examples within the Ciao system.\n","authors":["Marco Ciccalè","Daniel Jurjo-Rivas","Jose F. Morales","Pedro López-García","Manuel V. Hermenegildo"],"pdf_url":"https://arxiv.org/pdf/2507.17233v2.pdf","comment":"Accepted for publication in Theory and Practice of Logic Programming\n  (TPLP)"},{"id":"http://arxiv.org/abs/2509.09059v1","updated":"2025-09-10T23:45:19Z","published":"2025-09-10T23:45:19Z","title":"Dependent-Type-Preserving Memory Allocation","summary":"  Dependently typed programming languages such as Coq, Agda, Idris, and F*,\nallow programmers to write detailed specifications of their programs and prove\ntheir programs meet these specifications. However, these specifications can be\nviolated during compilation since they are erased after type checking. External\nprograms linked with the compiled program can violate the specifications of the\noriginal program and change the behavior of the compiled program -- even when\ncompiled with a verified compiler. For example, since Coq does not allow\nexplicitly allocating memory, a programmer might link their Coq program with a\nC program that can allocate memory. Even if the Coq program is compiled with a\nverified compiler, the external C program can still violate the memory-safe\nspecification of the Coq program by providing an uninitialized pointer to\nmemory. This error could be ruled out by type checking in a language expressive\nenough to indicate whether memory is initialized versus uninitialized. Linking\nwith a program with an uninitialized pointer could be considered ill-typed, and\nour linking process could prevent linking with ill-typed programs. To\nfacilitate type checking during linking, we can use type-preserving\ncompilation, which preserves the types through the compilation process. In this\nongoing work, we develop a typed intermediate language that supports dependent\nmemory allocation, as well as a dependent-type-preserving compiler pass for\nmemory allocation.\n","authors":["Paulette Koronkevich","William J. Bowman"],"pdf_url":"https://arxiv.org/pdf/2509.09059v1.pdf","comment":"Submitted and received second place at the Student Research\n  Competition at Principles of Programming Languages 2022"},{"id":"http://arxiv.org/abs/2509.09019v1","updated":"2025-09-10T21:27:35Z","published":"2025-09-10T21:27:35Z","title":"Towards Verified Compilation of Floating-point Optimization in\n  Scientific Computing Programs","summary":"  Scientific computing programs often undergo aggressive compiler optimization\nto achieve high performance and efficient resource utilization. While\nperformance is critical, we also need to ensure that these optimizations are\ncorrect. In this paper, we focus on a specific class of optimizations,\nfloating-point optimizations, notably due to fast math, at the LLVM IR level.\nWe present a preliminary work, which leverages the Verified LLVM framework in\nthe Rocq theorem prover, to prove the correctness of Fused-Multiply-Add (FMA)\noptimization for a basic block implementing the arithmetic expression $a * b +\nc$ . We then propose ways to extend this preliminary results by adding more\nprogram features and fast math floating-point optimizations.\n","authors":["Mohit Tekriwal","John Sarracino"],"pdf_url":"https://arxiv.org/pdf/2509.09019v1.pdf","comment":null}],"Data Structures and Algorithms":[{"id":"http://arxiv.org/abs/2506.12718v2","updated":"2025-09-10T16:55:18Z","published":"2025-06-15T04:50:02Z","title":"Permutation-Avoiding FFT-Based Convolution","summary":"  Fast Fourier Transform (FFT) libraries are widely used for evaluating\ndiscrete convolutions. Most FFT implementations follow some variant of the\nCooley-Tukey framework, in which the transform is decomposed into butterfly\noperations and index-reversal permutations. While butterfly operations dominate\nthe floating-point operation count, the memory access patterns induced by\nindex-reversal permutations significantly degrade the FFT's arithmetic\nintensity. When performing discrete convolution, the three sets of\nindex-reversal permutations which occur in FFT-based implementations using\nCooley-Tukey frameworks cancel out, thus paving the way to implementations free\nof any permutation. To the best of our knowledge, such permutation-free\nvariants of FFT-based discrete convolution are not commonly used in practice,\nmaking such kernels worth investigating. Here, we look into such\npermutation-avoiding convolution procedures for multi-dimensional cases within\na general radix Cooley-Tukey framework. We perform numerical experiments to\nbenchmark the algorithms presented against state-of-the-art FFT-based\nconvolution implementations. Our results suggest that developers of FFT\nlibraries should consider supporting permutation-avoiding convolution kernels.\n","authors":["Nicolas Venkovic","Hartwig Anzt"],"pdf_url":"https://arxiv.org/pdf/2506.12718v2.pdf","comment":"42 pages, 22 tables, 2 figures, 22 algorithms"},{"id":"http://arxiv.org/abs/2509.08684v1","updated":"2025-09-10T15:22:47Z","published":"2025-09-10T15:22:47Z","title":"Dorst-Smeulders Coding for Arbitrary Binary Words","summary":"  A binary word is Sturmian if the occurrences of each letter are balanced, in\nthe sense that in any two factors of the same length, the difference between\nthe number of occurrences of the same letter is at most 1. In digital geometry,\nSturmian words correspond to discrete approximations of straight line segments\nin the Euclidean plane. The Dorst-Smeulders coding, introduced in 1984, is a\n4-tuple of integers that uniquely represents a Sturmian word $w$, enabling its\nreconstruction using $|w|$ modular operations, making it highly efficient in\npractice. In this paper, we present a linear-time algorithm that, given a\nbinary input word $w$, computes the Dorst-Smeulders coding of its longest\nSturmian prefix. This forms the basis for computing the Dorst-Smeulders coding\nof an arbitrary binary word $w$, which is a minimal decomposition (in terms of\nthe number of factors) of $w$ into Sturmian words, each represented by its\nDorst-Smeulders coding. This coding could be leveraged in compression schemes\nwhere the input is transformed into a binary word composed of long Sturmian\nsegments. Although the algorithm is conceptually simple and can be implemented\nin just a few lines of code, it is grounded in a deep analysis of the\nstructural properties of Sturmian words.\n","authors":["Alessandro De Luca","Gabriele Fici"],"pdf_url":"https://arxiv.org/pdf/2509.08684v1.pdf","comment":"9 pages, presented at SPIRE 2025 (proceedings upcoming)"},{"id":"http://arxiv.org/abs/2509.07827v2","updated":"2025-09-10T13:45:56Z","published":"2025-09-09T15:04:42Z","title":"Compressibility Measures and Succinct Data Structures for Piecewise\n  Linear Approximations","summary":"  We study the problem of deriving compressibility measures for Piecewise\nLinear Approximations (PLAs), i.e., error-bounded approximations of a set of\ntwo-dimensional increasing data points using a sequence of segments. Such\napproximations are widely used tools in implementing many learned data\nstructures, which mix learning models with traditional algorithmic design\nblocks to exploit regularities in the underlying data distribution, providing\nnovel and effective space-time trade-offs. We introduce the first lower bounds\nto the cost of storing PLAs in two settings, namely compression and indexing.\nWe then compare these compressibility measures to known data structures, and\nshow that they are asymptotically optimal up to a constant factor from the\nspace lower bounds. Finally, we design the first data structures for the\naforementioned settings that achieve the space lower bounds plus small additive\nterms, which turn out to be succinct in most practical cases. Our data\nstructures support the efficient retrieval and evaluation of a segment in the\n(compressed) PLA for a given $x$-value, which is a core operation in any\nlearned data structure relying on PLAs. As a result, our paper offers the first\ntheoretical analysis of the maximum compressibility achievable by PLA-based\nlearned data structures, and provides novel storage schemes for PLAs offering\nstrong theoretical guarantees while also suggesting simple and efficient\npractical implementations.\n","authors":["Paolo Ferragina","Filippo Lari"],"pdf_url":"https://arxiv.org/pdf/2509.07827v2.pdf","comment":"Accepted for publication at the 36th International Symposium on\n  Algorithms and Computation (ISAAC)"},{"id":"http://arxiv.org/abs/2508.04726v2","updated":"2025-09-10T13:20:38Z","published":"2025-08-05T18:04:36Z","title":"Subset Sum in Near-Linear Pseudopolynomial Time and Polynomial Space","summary":"  Given a multiset $A = \\{a_1, \\dots, a_n\\}$ of positive integers and a target\ninteger $t$, the Subset Sum problem asks if there is a subset of $A$ that sums\nto $t$. Bellman's [1957] classical dynamic programming algorithm runs in\n$O(nt)$ time and $O(t)$ space. Since then, much work has been done to reduce\nboth the time and space usage.\n  Notably, Bringmann [SODA 2017] uses a two-step color-coding technique to\nobtain a randomized algorithm that runs in $\\tilde{O}(n+t)$ time and\n$\\tilde{O}(t)$ space. Jin, Vyas and Williams [SODA 2021] build upon the\nalgorithm given by Bringmann, using a clever algebraic trick first seen in\nKane's Logspace algorithm, to obtain an $\\tilde{O}(nt)$ time and\n$\\tilde{O}(\\log(nt))$ space randomized algorithm. A SETH-based lower-bound\nestablished by Abboud et al. [SODA 2019] shows that Bringmann's algorithm is\nlikely to have near-optimal time complexity.\n  We build on the techniques used by Jin et al. to obtain a randomized\nalgorithm running in $\\tilde{O}(n+t)$ time and $\\tilde{O}(n^2 + n \\log^2 t)$\nspace, resulting in an algorithm with near-optimal runtime that also runs in\npolynomial space. We use a multipoint evaluation-based approach to speed up a\nbottleneck step in their algorithm.\n  We also provide a simple polynomial space deterministic algorithm that runs\nin $\\tilde{O}(n^2t)$ time and $\\tilde{O}(n \\log^2 t)$ space.\n","authors":["Thejas Radhika Sajith"],"pdf_url":"https://arxiv.org/pdf/2508.04726v2.pdf","comment":"11 pages; v2: correction in the deterministic algorithm, main\n  randomized algorithm unchanged"},{"id":"http://arxiv.org/abs/2504.02342v2","updated":"2025-09-10T12:59:05Z","published":"2025-04-03T07:20:41Z","title":"On the twin-width of near-regular graphs","summary":"  Twin-width is a recently introduced graph parameter based on the repeated\ncontraction of near-twins. It has shown remarkable utility in algorithmic and\nstructural graph theory, as well as in finite model theory -- particularly\nsince first-order model checking is fixed-parameter tractable when a witness\ncertifying small twin-width is provided. However, the behavior of twin-width in\nspecific graph classes, particularly cubic graphs, remains poorly understood.\nWhile cubic graphs are known to have unbounded twin-width, no explicit cubic\ngraph of twin-width greater than 4 is known.\n  This paper explores this phenomenon in regular and near-regular graph\nclasses. We show that extremal graphs of bounded degree and high twin-width are\nasymmetric, partly explaining their elusiveness. Additionally, we establish\nbounds for circulant and d-degenerate graphs, and examine strongly regular\ngraphs, which exhibit similar behavior to cubic graphs. Our results include\ndetermining the twin-width of Johnson graphs over 2-sets, and cyclic Latin\nsquare graphs.\n","authors":["Irene Heinrich","Ferdinand Ihringer","Simon Raßmann","Lena Volk"],"pdf_url":"https://arxiv.org/pdf/2504.02342v2.pdf","comment":"26 pages, 2 figures"},{"id":"http://arxiv.org/abs/2509.08503v1","updated":"2025-09-10T11:24:53Z","published":"2025-09-10T11:24:53Z","title":"Checking and producing word attractors","summary":"  The article focuses on word (or string) attractors, which are sets of\npositions related to the text compression efficiency of the underlying word.\nThe article presents two combinatorial algorithms based on Suffix automata or\nDirected Acyclic Word Graphs. The first algorithm decides in linear time\nwhether a set of positions on the word is an attractor of the word. The second\nalgorithm generates an attractor for a given word in a greedy manner. Although\nthis problem is NP-hard, the algorithm is efficient and produces very small\nattractors for several well-known families of words.\n","authors":["Marie-Pierre Béal","Maxime Crochemore","Giuseppe Romana"],"pdf_url":"https://arxiv.org/pdf/2509.08503v1.pdf","comment":"17 pages, 6 figures, 3 tables, 2 algorithms"},{"id":"http://arxiv.org/abs/2509.08475v1","updated":"2025-09-10T10:27:21Z","published":"2025-09-10T10:27:21Z","title":"Enumeration kernels for Vertex Cover and Feedback Vertex Set","summary":"  Enumerative kernelization is a recent and promising area sitting at the\nintersection of parameterized complexity and enumeration algorithms. Its study\nbegan with the paper of Creignou et al. [Theory Comput. Syst., 2017], and\ndevelopment in the area has started to accelerate with the work of Golovach et\nal. [J. Comput. Syst. Sci., 2022]. The latter introduced polynomial-delay\nenumeration kernels and applied them in the study of structural\nparameterizations of the \\textsc{Matching Cut} problem and some variants. Few\nother results, mostly on \\textsc{Longest Path} and some generalizations of\n\\textsc{Matching Cut}, have also been developed. However, little success has\nbeen seen in enumeration versions of \\textsc{Vertex Cover} and \\textsc{Feedback\nVertex Set}, some of the most studied problems in kernelization. In this paper,\nwe address this shortcoming. Our first result is a polynomial-delay enumeration\nkernel with $2k$ vertices for \\textsc{Enum Vertex Cover}, where we wish to list\nall solutions with at most $k$ vertices. This is obtained by developing a\nnon-trivial lifting algorithm for the classical crown decomposition reduction\nrule, and directly improves upon the kernel with $\\mathcal{O}(k^2)$ vertices\nderived from the work of Creignou et al. Our other result is a polynomial-delay\nenumeration kernel with $\\mathcal{O}(k^3)$ vertices and edges for \\textsc{Enum\nFeedback Vertex Set}; the proof is inspired by some ideas of Thomass\\'e [TALG,\n2010], but with a weaker bound on the kernel size due to difficulties in\napplying the $q$-expansion technique.\n","authors":["Marin Bougeret","Guilherme C. M. Gomes","Vinicius F. dos Santos","Ignasi Sau"],"pdf_url":"https://arxiv.org/pdf/2509.08475v1.pdf","comment":"23 pages. Accepted at IPEC2025"},{"id":"http://arxiv.org/abs/2402.08332v3","updated":"2025-09-10T09:08:52Z","published":"2024-02-13T09:57:04Z","title":"Induced Minor Models. I. Structural Properties and Algorithmic\n  Consequences","summary":"  A graph $H$ is said to be an induced minor of a graph $G$ if $H$ can be\nobtained from $G$ by a sequence of vertex deletions and edge contractions.\nEquivalently, $H$ is an induced minor of $G$ if there exists an induced minor\nmodel of $H$ in $G$, that is, a collection of pairwise disjoint subsets of\nvertices of $G$ labeled by the vertices of $H$, each inducing a connected\nsubgraph in $G$, such that two vertices of $H$ are adjacent if and only if\nthere is an edge in $G$ between the corresponding subsets.\n  In this paper, we investigate structural properties of induced minor models,\nincluding bounds on treewidth and chromatic number of the subgraphs induced by\nminimal induced minor models. It is known that for some graphs $H$, testing\nwhether a given graph $G$ contains $H$ as an induced minor is an NP-complete\nproblem. Nevertheless, as algorithmic applications of our structural results,\nwe make use of recent developments regarding tree-independence number to show\nthat if $H$ is the $4$-wheel, the $5$-vertex complete graph minus an edge, or a\ncomplete bipartite graph $K_{2,q}$, then there is a polynomial-time algorithm\nto find in a given graph $G$ an induced minor model of $H$ in $G$, if there is\none. We also develop an alternative polynomial-time algorithm for recognizing\ngraphs that do not contain $K_{2,3}$ as an induced minor, which revolves around\nthe idea of detecting the induced subgraphs whose presence is forced when the\ninput graph contains $K_{2,3}$ as an induced minor, using the so-called\nshortest path detector. It turns out that all these induced subgraphs are\nTruemper configurations.\n","authors":["Nicolas Bousquet","Clément Dallard","Maël Dumas","Claire Hilaire","Martin Milanič","Anthony Perez","Nicolas Trotignon"],"pdf_url":"https://arxiv.org/pdf/2402.08332v3.pdf","comment":"Section 6 contains the main results of the first version of this\n  preprint (arXiv:2402.08332v1), which has been superseded by the current\n  version"},{"id":"http://arxiv.org/abs/2411.04394v3","updated":"2025-09-10T08:53:51Z","published":"2024-11-07T03:11:53Z","title":"Statistical-Computational Trade-offs for Recursive Adaptive Partitioning\n  Estimators","summary":"  Models based on recursive adaptive partitioning such as decision trees and\ntheir ensembles are popular for high-dimensional regression as they can\npotentially avoid the curse of dimensionality. Because empirical risk\nminimization (ERM) is computationally infeasible, these models are typically\ntrained using greedy algorithms. Although effective in many cases, these\nalgorithms have been empirically observed to get stuck at local optima. We\nexplore this phenomenon in the context of learning sparse regression functions\nover $d$ binary features, showing that when the true regression function $f^*$\ndoes not satisfy Abbe et al. (2022)'s Merged Staircase Property (MSP), greedy\ntraining requires $\\exp(\\Omega(d))$ to achieve low estimation error.\nConversely, when $f^*$ does satisfy MSP, greedy training can attain small\nestimation error with only $O(\\log d)$ samples. This dichotomy mirrors that of\ntwo-layer neural networks trained with stochastic gradient descent (SGD) in the\nmean-field regime, thereby establishing a head-to-head comparison between\nSGD-trained neural networks and greedy recursive partitioning estimators.\nFurthermore, ERM-trained recursive partitioning estimators achieve low\nestimation error with $O(\\log d)$ samples irrespective of whether $f^*$\nsatisfies MSP, thereby demonstrating a statistical-computational trade-off for\ngreedy training. Our proofs are based on a novel interpretation of greedy\nrecursive partitioning using stochastic process theory and a coupling technique\nthat may be of independent interest.\n","authors":["Yan Shuo Tan","Jason M. Klusowski","Krishnakumar Balasubramanian"],"pdf_url":"https://arxiv.org/pdf/2411.04394v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.09993v4","updated":"2025-09-10T08:23:06Z","published":"2022-07-20T15:53:53Z","title":"Computing Tree Decompositions with Small Independence Number","summary":"  The independence number of a tree decomposition is the maximum of the\nindependence numbers of the subgraphs induced by its bags. The\ntree-independence number of a graph is the minimum independence number of a\ntree decomposition of it. Several NP-hard graph problems, like maximum weight\nindependent set, can be solved in time n^{O(k)} if the input n-vertex graph is\ngiven together with a tree decomposition of independence number k. Yolov, in\n[SODA 2018], gave an algorithm that, given an n-vertex graph G and an integer\nk, in time n^{O(k^3)} either constructs a tree decomposition of G whose\nindependence number is O(k^3) or correctly reports that the tree-independence\nnumber of G is larger than k.\n  In this paper, we first give an algorithm for computing the tree-independence\nnumber with a better approximation ratio and running time and then prove that\nour algorithm is, in some sense, the best one can hope for. More precisely, our\nalgorithm runs in time 2^{O(k^2)} n^{O(k)} and either outputs a tree\ndecomposition of G with independence number at most $8k$, or determines that\nthe tree-independence number of G is larger than k. This implies 2^{O(k^2)}\nn^{O(k)}-time algorithms for various problems, like maximum weight independent\nset, parameterized by the tree-independence number k without needing the\ndecomposition as an input. Assuming Gap-ETH, an n^{\\Omega(k)} factor in the\nrunning time is unavoidable for any approximation algorithm for the\ntree-independence number.\n  Our second result is that the exact computation of the tree-independence\nnumber is para-NP-hard: We show that for every constant k \\ge 4 it is NP-hard\nto decide if a given graph has the tree-independence number at most k.\n","authors":["Clément Dallard","Fedor V. Fomin","Petr A. Golovach","Tuukka Korhonen","Martin Milanič"],"pdf_url":"https://arxiv.org/pdf/2207.09993v4.pdf","comment":"Small corrections were made"},{"id":"http://arxiv.org/abs/2311.12732v2","updated":"2025-09-10T06:20:17Z","published":"2023-11-21T17:15:21Z","title":"Tight Lieb-Robinson Bound for approximation ratio in Quantum Annealing","summary":"  Quantum annealing (QA) holds promise for optimization problems in quantum\ncomputing, especially for combinatorial optimization. This analog framework\nattracts attention for its potential to address complex problems. Its\ngate-based homologous, QAOA with proven performance, has brought lots of\nattention to the NISQ era. Several numerical benchmarks try to classify these\ntwo metaheuristics however, classical computational power highly limits the\nperformance insights. In this work, we introduce a new parametrized version of\nQA enabling a precise 1-local analysis of the algorithm. We develop a tight\nLieb-Robinson bound for regular graphs, achieving the best-known numerical\nvalue to analyze QA locally. Studying MaxCut over cubic graph as a benchmark\noptimization problem, we show that a linear-schedule QA with a 1-local analysis\nachieves an approximation ratio over 0.7020, outperforming any known 1-local\nalgorithms.\n","authors":["Arthur Braida","Simon Martiel","Ioan Todinca"],"pdf_url":"https://arxiv.org/pdf/2311.12732v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08276v1","updated":"2025-09-10T04:29:09Z","published":"2025-09-10T04:29:09Z","title":"FeynmanDD: Quantum Circuit Analysis with Classical Decision Diagrams","summary":"  Applications of decision diagrams in quantum circuit analysis have been an\nactive research area. Our work introduces FeynmanDD, a new method utilizing\nstandard and multi-terminal decision diagrams for quantum circuit simulation\nand equivalence checking. Unlike previous approaches that exploit patterns in\nquantum states and operators, our method explores useful structures in the path\nintegral formulation, essentially transforming the analysis into a counting\nproblem. The method then employs efficient counting algorithms using decision\ndiagrams as its underlying computational engine. Through comprehensive\ntheoretical analysis and numerical experiments, we demonstrate FeynmanDD's\ncapabilities and limitations in quantum circuit analysis, highlighting the\nvalue of this new BDD-based approach.\n","authors":["Ziyuan Wang","Bin Cheng","Longxiang Yuan","Zhengfeng Ji"],"pdf_url":"https://arxiv.org/pdf/2509.08276v1.pdf","comment":"26 pages, 2 figures, 7 tables. Published in the Proceedings of CAV\n  2025. Code available at https://github.com/cqs-thu/feynman-decision-diagram"},{"id":"http://arxiv.org/abs/1911.07945v2","updated":"2025-09-10T22:58:37Z","published":"2019-11-18T20:48:12Z","title":"Optimal Single-Choice Prophet Inequalities from Samples","summary":"  We study the single-choice Prophet Inequality problem when the gambler is\ngiven access to samples. We show that the optimal competitive ratio of $1/2$\ncan be achieved with a single sample from each distribution. When the\ndistributions are identical, we show that for any constant $\\varepsilon > 0$,\n$O(n)$ samples from the distribution suffice to achieve the optimal competitive\nratio ($\\approx 0.745$) within $(1+\\varepsilon)$, resolving an open problem of\nCorrea, D\\\"utting, Fischer, and Schewior.\n","authors":["Aviad Rubinstein","Jack Z. Wang","S. Matthew Weinberg"],"pdf_url":"https://arxiv.org/pdf/1911.07945v2.pdf","comment":"Appears in Innovations in Theoretical Computer Science (ITCS) 2020"},{"id":"http://arxiv.org/abs/2508.20785v2","updated":"2025-09-10T22:33:22Z","published":"2025-08-28T13:47:54Z","title":"Sharp Online Hardness for Large Balanced Independent Sets","summary":"  We study the algorithmic problem of finding large $\\gamma$-balanced\nindependent sets in dense random bipartite graphs; an independent set is\n$\\gamma$-balanced if a $\\gamma$ proportion of its vertices lie on one side of\nthe bipartition. In the sparse regime, Perkins and Wang established tight\nbounds within the low-degree polynomial (LDP) framework, showing a\nfactor-$1/(1-\\gamma)$ statistical-computational gap via the Overlap Gap\nProperty (OGP) framework tailored for stable algorithms. However, these\ntechniques do not appear to extend to the dense setting. For the related large\nindependent set problem in dense random graph, the best known algorithm is an\nonline greedy procedure that is inherently unstable, and LDP algorithms are\nconjectured to fail even in the \"easy\" regime where greedy succeeds. We show\nthat the largest $\\gamma$-balanced independent set in dense random bipartite\ngraphs has size $\\alpha:=\\frac{\\log_b n}{\\gamma(1-\\gamma)}$ whp, where $n$ is\nthe size of each bipartition, $p$ is the edge probability, and $b=1/(1-p)$. We\ndesign an online algorithm that achieves $(1-\\epsilon)(1-\\gamma)\\alpha$ whp for\nany $\\epsilon>0$. We complement this with a sharp lower bound, showing that no\nonline algorithm can achieve $(1+\\epsilon)(1-\\gamma)\\alpha$ with nonnegligible\nprobability. Our results suggest that the same factor-$1/(1-\\gamma)$ gap is\nalso present in the dense setting, supporting its conjectured universality.\nWhile the classical greedy procedure on $G(n,p)$ is straightforward, our\nalgorithm is more intricate: it proceeds in two stages, incorporating a\nstopping time and suitable truncation to ensure that $\\gamma$-balancedness-a\nglobal constraint-is met despite operating with limited information. Our lower\nbound utilizes the OGP framework; we build on a recent refinement of this\nframework for online models and extend it to the bipartite setting.\n","authors":["Abhishek Dhawan","Eren C. Kızıldağ","Neeladri Maitra"],"pdf_url":"https://arxiv.org/pdf/2508.20785v2.pdf","comment":"36 pages; abstract shortened due to arxiv restrictions; this version\n  includes a new result involving online algorithms which allow future queries"},{"id":"http://arxiv.org/abs/2509.08911v1","updated":"2025-09-10T18:15:41Z","published":"2025-09-10T18:15:41Z","title":"Instance-Optimal Matrix Multiplicative Weight Update and Its Quantum\n  Applications","summary":"  The Matrix Multiplicative Weight Update (MMWU) is a seminal online learning\nalgorithm with numerous applications. Applied to the matrix version of the\nLearning from Expert Advice (LEA) problem on the $d$-dimensional spectraplex,\nit is well known that MMWU achieves the minimax-optimal regret bound of\n$O(\\sqrt{T\\log d})$, where $T$ is the time horizon. In this paper, we present\nan improved algorithm achieving the instance-optimal regret bound of\n$O(\\sqrt{T\\cdot S(X||d^{-1}I_d)})$, where $X$ is the comparator in the regret,\n$I_d$ is the identity matrix, and $S(\\cdot||\\cdot)$ denotes the quantum\nrelative entropy. Furthermore, our algorithm has the same computational\ncomplexity as MMWU, indicating that the improvement in the regret bound is\n``free''.\n  Technically, we first develop a general potential-based framework for matrix\nLEA, with MMWU being its special case induced by the standard exponential\npotential. Then, the crux of our analysis is a new ``one-sided'' Jensen's trace\ninequality built on a Laplace transform technique, which allows the application\nof general potential functions beyond exponential to matrix LEA. Our algorithm\nis finally induced by an optimal potential function from the vector LEA\nproblem, based on the imaginary error function.\n  Complementing the above, we provide a memory lower bound for matrix LEA, and\nexplore the applications of our algorithm in quantum learning theory. We show\nthat it outperforms the state of the art for learning quantum states corrupted\nby depolarization noise, random quantum states, and Gibbs states. In addition,\napplying our algorithm to linearized convex losses enables predicting nonlinear\nquantum properties, such as purity, quantum virtual cooling, and R\\'{e}nyi-$2$\ncorrelation.\n","authors":["Weiyuan Gong","Tongyang Li","Xinzhao Wang","Zhiyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2509.08911v1.pdf","comment":"47 pages"}],"Graphics":[{"id":"http://arxiv.org/abs/2509.08643v1","updated":"2025-09-10T14:37:02Z","published":"2025-09-10T14:37:02Z","title":"X-Part: high fidelity and structure coherent shape decomposition","summary":"  Generating 3D shapes at part level is pivotal for downstream applications\nsuch as mesh retopology, UV mapping, and 3D printing. However, existing\npart-based generation methods often lack sufficient controllability and suffer\nfrom poor semantically meaningful decomposition. To this end, we introduce\nX-Part, a controllable generative model designed to decompose a holistic 3D\nobject into semantically meaningful and structurally coherent parts with high\ngeometric fidelity. X-Part exploits the bounding box as prompts for the part\ngeneration and injects point-wise semantic features for meaningful\ndecomposition. Furthermore, we design an editable pipeline for interactive part\ngeneration. Extensive experimental results show that X-Part achieves\nstate-of-the-art performance in part-level shape generation. This work\nestablishes a new paradigm for creating production-ready, editable, and\nstructurally sound 3D assets. Codes will be released for public research.\n","authors":["Xinhao Yan","Jiachen Xu","Yang Li","Changfeng Ma","Yunhan Yang","Chunshi Wang","Zibo Zhao","Zeqiang Lai","Yunfei Zhao","Zhuo Chen","Chunchao Guo"],"pdf_url":"https://arxiv.org/pdf/2509.08643v1.pdf","comment":"Tech Report"},{"id":"http://arxiv.org/abs/2509.08947v1","updated":"2025-09-10T19:13:14Z","published":"2025-09-10T19:13:14Z","title":"CameraVDP: Perceptual Display Assessment with Uncertainty Estimation via\n  Camera and Visual Difference Prediction","summary":"  Accurate measurement of images produced by electronic displays is critical\nfor the evaluation of both traditional and computational displays. Traditional\ndisplay measurement methods based on sparse radiometric sampling and fitting a\nmodel are inadequate for capturing spatially varying display artifacts, as they\nfail to capture high-frequency and pixel-level distortions. While cameras offer\nsufficient spatial resolution, they introduce optical, sampling, and\nphotometric distortions. Furthermore, the physical measurement must be combined\nwith a model of a visual system to assess whether the distortions are going to\nbe visible. To enable perceptual assessment of displays, we propose a\ncombination of a camera-based reconstruction pipeline with a visual difference\npredictor, which account for both the inaccuracy of camera measurements and\nvisual difference prediction. The reconstruction pipeline combines HDR image\nstacking, MTF inversion, vignetting correction, geometric undistortion,\nhomography transformation, and color correction, enabling cameras to function\nas precise display measurement instruments. By incorporating a Visual\nDifference Predictor (VDP), our system models the visibility of various stimuli\nunder different viewing conditions for the human visual system. We validate the\nproposed CameraVDP framework through three applications: defective pixel\ndetection, color fringing awareness, and display non-uniformity evaluation. Our\nuncertainty analysis framework enables the estimation of the theoretical upper\nbound for defect pixel detection performance and provides confidence intervals\nfor VDP quality scores.\n","authors":["Yancheng Cai","Robert Wanat","Rafal Mantiuk"],"pdf_url":"https://arxiv.org/pdf/2509.08947v1.pdf","comment":"Accepted by SIGGRAPH Asia 2025"}]},"2025-09-11T00:00:00Z":{"Operating Systems":[{"id":"http://arxiv.org/abs/2509.09525v1","updated":"2025-09-11T15:06:03Z","published":"2025-09-11T15:06:03Z","title":"TrEnv: Transparently Share Serverless Execution Environments Across\n  Different Functions and Nodes","summary":"  Serverless computing provides dynamic scalability, but its infrastructure\noverhead becomes a bottleneck for emerging workloads such as LLM agents, which\nexhibit unpredictable invocation patterns and variable resource demands. Our\nanalysis shows that for these agents, the cost of running on serverless\nplatforms can reach up to 70% of the cost of LLM API calls. This finding\nmotivates the need for a more efficient, high-density serverless platform. We\npresent TrEnv, a co-designed serverless platform that supports both container-\nand VM-based environments, optimized for the unique demands of LLM agents.\nTrEnv reduces startup latency and memory usage through repurposable sandboxes\nand memory templates, which enable fast reuse and restoration of execution\nenvironments. To further reduce overhead in VM-based agent workloads, TrEnv\nleverages browser sharing and a page cache bypassing mechanism. Evaluations\nshow that TrEnv reduces P99 latency by up to 7X and memory usage by 48% in\ncontainer-based settings, and achieves up to 58% lower P99 latency and 61%\nmemory savings for VM-based agents compared to state-of-the-art systems like\nE2B.\n","authors":["Jialiang Huang","Teng Ma","Zheng Liu","Sixing Lin","Kang Chen","Jinlei Jiang","Xia Liao","Yingdi Shan","Yongwei Wu","Ning Zhang","Mengting Lu","Tao Ma","Haifeng Gong","Mingxing Zhang"],"pdf_url":"https://arxiv.org/pdf/2509.09525v1.pdf","comment":"38 pages"},{"id":"http://arxiv.org/abs/2509.09439v1","updated":"2025-09-11T13:26:33Z","published":"2025-09-11T13:26:33Z","title":"μFork: Supporting POSIX fork Within a Single-Address-Space OS","summary":"  Single-address-space operating systems have well-known lightweightness\nbenefits that result from their central design idea: the kernel and\napplications share a unique address space. This model makes these operating\nsystems (OSes) incompatible by design with a large class of software:\nmultiprocess POSIX applications. Indeed, the semantics of the primitive used to\ncreate POSIX processes, fork, are inextricably tied to the existence of\nmultiple address spaces.\n  Prior approaches addressing this issue trade off lightweightness,\ncompatibility and/or isolation. We propose {\\mu}Fork, a single-address-space\noperating system design supporting POSIX fork on modern hardware without\ncompromising on any of these key objectives. {\\mu}Fork emulates POSIX processes\n({\\mu}processes) and achieves fork by creating for the child a copy of the\nparent {\\mu}process' memory at a different location within a single address\nspace. This approach presents two challenges: relocating the child's absolute\nmemory references (pointers), as well as providing user/kernel and\n{\\mu}processes isolation without impacting lightweightness. We address them\nusing CHERI. We implement {\\mu}Fork and evaluate it upon three real-world\nuse-cases: Redis snapshots, Nginx multi-worker deployments, and Zygote FaaS\nworker warm-up. {\\mu}Fork outperforms previous work and traditional monolithic\nOSes on key lightweightness metrics by an order of magnitude, e.g. it can offer\na fork-bound FaaS function throughput 24% higher than that of a monolithic OS,\nand can fork a {\\mu}process in 54{\\mu}s, 3.7x faster than a traditional fork.\n","authors":["John Alistair Kressel","Hugo Lefeuvre","Pierre Olivier"],"pdf_url":"https://arxiv.org/pdf/2509.09439v1.pdf","comment":"Accepted to appear at SOSP 2025"},{"id":"http://arxiv.org/abs/2509.03855v4","updated":"2025-09-11T02:26:06Z","published":"2025-09-04T03:31:31Z","title":"Towards Deterministic Sub-0.5 us Response on Linux through Interrupt\n  Isolation","summary":"  Real-time responsiveness in Linux is often constrained by interrupt\ncontention and timer handling overhead, making it challenging to achieve\nsub-microsecond latency. This work introduces an interrupt isolation approach\nthat centralizes and minimizes timer interrupt interference across CPU cores.\nBy enabling a dedicated API to selectively invoke timer handling routines and\nsuppress non-critical inter-processor interrupts, our design significantly\nreduces jitter and response latency. Experiments conducted on an ARM-based\nmulticore platform demonstrate that the proposed mechanism consistently\nachieves sub-0.5 us response times, outperforming conventional Linux PREEMPT-RT\nconfigurations. These results highlight the potential of interrupt isolation as\na lightweight and effective strategy for deterministic real-time workloads in\ngeneral-purpose operating systems.\n","authors":["Zhouyi Zhou","Zhili Liu","Shancong Zhang","Jiemin Li","Dengke Du","Mengke Sun","Zhiqiang Wang","Hongyan Liu","Guokai Xu"],"pdf_url":"https://arxiv.org/pdf/2509.03855v4.pdf","comment":"9 pages, 11 figures"}],"Systems and Control":[{"id":"http://arxiv.org/abs/2509.09637v1","updated":"2025-09-11T17:23:47Z","published":"2025-09-11T17:23:47Z","title":"A neural drift-plus-penalty algorithm for network power allocation and\n  routing","summary":"  The drift-plus-penalty method is a Lyapunov optimisation technique commonly\napplied to network routing problems. It reduces the original stochastic\nplanning task to a sequence of greedy optimizations, enabling the design of\ndistributed routing algorithms which stabilize data queues while simultaneously\noptimizing a specified penalty function. While drift-plus-penalty methods have\ndesirable asymptotic properties, they tend to incur higher network delay than\nalternative control methods, especially under light network load. In this work,\nwe propose a learned variant of the drift-plus-penalty method that can preserve\nits theoretical guarantees, while being flexible enough to learn routing\nstrategies directly from a model of the problem. Our approach introduces a\nnovel mechanism for learning routing decisions and employs an optimal\ntransport-based method for link scheduling. Applied to the joint task of\ntransmit-power allocation and data routing, the method achieves consistent\nimprovements over common baselines under a broad set of scenarios.\n","authors":["Ahmed Rashwan","Keith Briggs","Chris Budd"],"pdf_url":"https://arxiv.org/pdf/2509.09637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.09594v1","updated":"2025-09-11T16:34:17Z","published":"2025-09-11T16:34:17Z","title":"ObjectReact: Learning Object-Relative Control for Visual Navigation","summary":"  Visual navigation using only a single camera and a topological map has\nrecently become an appealing alternative to methods that require additional\nsensors and 3D maps. This is typically achieved through an \"image-relative\"\napproach to estimating control from a given pair of current observation and\nsubgoal image. However, image-level representations of the world have\nlimitations because images are strictly tied to the agent's pose and\nembodiment. In contrast, objects, being a property of the map, offer an\nembodiment- and trajectory-invariant world representation. In this work, we\npresent a new paradigm of learning \"object-relative\" control that exhibits\nseveral desirable characteristics: a) new routes can be traversed without\nstrictly requiring to imitate prior experience, b) the control prediction\nproblem can be decoupled from solving the image matching problem, and c) high\ninvariance can be achieved in cross-embodiment deployment for variations across\nboth training-testing and mapping-execution settings. We propose a topometric\nmap representation in the form of a \"relative\" 3D scene graph, which is used to\nobtain more informative object-level global path planning costs. We train a\nlocal controller, dubbed \"ObjectReact\", conditioned directly on a high-level\n\"WayObject Costmap\" representation that eliminates the need for an explicit RGB\ninput. We demonstrate the advantages of learning object-relative control over\nits image-relative counterpart across sensor height variations and multiple\nnavigation tasks that challenge the underlying spatial understanding\ncapability, e.g., navigating a map trajectory in the reverse direction. We\nfurther show that our sim-only policy is able to generalize well to real-world\nindoor environments. Code and supplementary material are accessible via project\npage: https://object-react.github.io/\n","authors":["Sourav Garg","Dustin Craggs","Vineeth Bhat","Lachlan Mares","Stefan Podgorski","Madhava Krishna","Feras Dayoub","Ian Reid"],"pdf_url":"https://arxiv.org/pdf/2509.09594v1.pdf","comment":"CoRL 2025; 23 pages including appendix"},{"id":"http://arxiv.org/abs/2509.09563v1","updated":"2025-09-11T15:52:55Z","published":"2025-09-11T15:52:55Z","title":"Learning-Based Data-Assisted Port-Hamiltonian Control for Free-Floating\n  Space Manipulators","summary":"  A generic data-assisted control architecture within the port-Hamiltonian\nframework is proposed, introducing a physically meaningful observable that\nlinks conservative dynamics to all actuation, dissipation, and disturbance\nchannels. A robust, model-based controller combined with a high-gain\ndecentralized integrator establishes large robustness margins and strict\ntime-scale separation, ensuring that subsequent learning cannot destabilize the\nprimary dynamics. Learning, selected for its generalizability, is then applied\nto capture complex, unmodeled effects, despite inherent delay and transient\nerror during adaptation. Formal Lyapunov analysis with explicit stability\nbounds guarantees convergence under bounded learning errors. The structured\ndesign confines learning to the simplest part of the dynamics, enhancing data\nefficiency while preserving physical interpretability. The approach is generic,\nwith a free-floating space manipulator orientation control task, including\nintegrated null-space collision avoidance, serving as a case study to\ndemonstrate robust tracking performance and applicability to broader robotic\ndomains.\n","authors":["Mostafa Eslami","Maryam Babazadeh"],"pdf_url":"https://arxiv.org/pdf/2509.09563v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.09484v1","updated":"2025-09-11T14:15:20Z","published":"2025-09-11T14:15:20Z","title":"BagIt! An Adaptive Dual-Arm Manipulation of Fabric Bags for Object\n  Bagging","summary":"  Bagging tasks, commonly found in industrial scenarios, are challenging\nconsidering deformable bags' complicated and unpredictable nature. This paper\npresents an automated bagging system from the proposed adaptive\nStructure-of-Interest (SOI) manipulation strategy for dual robot arms. The\nsystem dynamically adjusts its actions based on real-time visual feedback,\nremoving the need for pre-existing knowledge of bag properties. Our framework\nincorporates Gaussian Mixture Models (GMM) for estimating SOI states,\noptimization techniques for SOI generation, motion planning via Constrained\nBidirectional Rapidly-exploring Random Tree (CBiRRT), and dual-arm coordination\nusing Model Predictive Control (MPC). Extensive experiments validate the\ncapability of our system to perform precise and robust bagging across various\nobjects, showcasing its adaptability. This work offers a new solution for\nrobotic deformable object manipulation (DOM), particularly in automated bagging\ntasks. Video of this work is available at https://youtu.be/6JWjCOeTGiQ.\n","authors":["Peng Zhou","Jiaming Qi","Hongmin Wu","Chen Wang","Yizhou Chen","Zeqing Zhang"],"pdf_url":"https://arxiv.org/pdf/2509.09484v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.09466v1","updated":"2025-09-11T13:49:30Z","published":"2025-09-11T13:49:30Z","title":"Taming Spontaneous Stop-and-Go Traffic Waves: A Bifurcation Perspective\n  of A Dynamical Map","summary":"  We consider a discrete-time dynamical system in a car-following context. The\nsystem was recently introduced to parsimoniously model human driving behavior\nbased on utility maximization. The parameters of the model were calibrated\nusing vehicle trajectory data from the Sugiyama experiment. It was shown that\nsuch a system can accurately reproduce the observed collective phenomena of a\nmore elaborate experiment by Tadaki et al. Once the heterogeneity and noise are\nswitched off, the model defines a map of the corresponding discrete-time\ndynamical system. We first perform a bifurcation analysis of the map by\nstudying the stability of its limit solutions: a free-flow fixed point and a\nstop-and-go quasi-periodic orbit. When the vehicle density is varied, our model\ndisplays a bifurcation diagram qualitatively similar to those found in a class\nof optimal velocity models based on an ordinary differential equation approach,\nincluding regimes where one or both of the limit solutions are stable. In a 2D\nbifurcation diagram we further demonstrate that imposing a vehicle\ndensity-dependent speed advisory can dissipate the stop-and-go quasi-periodic\norbit. This in turn lays the mathematical foundation for a simple, yet\neffective proposal [1] to tame stop-and-go waves, improving traffic flow and\nsmoothness simultaneously via variable speed advisory.\n","authors":["Suzhou Huang","Jian Hu"],"pdf_url":"https://arxiv.org/pdf/2509.09466v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.09441v1","updated":"2025-09-11T13:27:37Z","published":"2025-09-11T13:27:37Z","title":"Taming Spontaneous Stop-and-Go Traffic Waves: A Computational Mechanism\n  Design Perspective","summary":"  It is well known that stop-and-go waves can be generated spontaneously in\ntraffic even without bottlenecks. Can such undesirable traffic patterns,\ninduced by intrinsic human driving behaviors, be tamed effectively and\ninexpensively? Taking advantage of emerging connectivity and autonomy\ntechnologies, we envision a simple yet realistic traffic control system to\nachieve this goal. To prove the concept, we design such a system to suppress\nthese waves while maximizing traffic throughput in the Tadaki setting: a\ncircular road with varying number of vehicles. We first introduce our driver\nbehavior model and demonstrate how our calibrated human driving agents can\nclosely reproduce the observed human driving patterns in the original Tadaki\nexperiment. We then propose a simple control system mediated via connected\nautomated vehicles (CAV) whose ideal speed parameter is treated as a\nsystem-level control variable adapted to the local vehicle density of the\ntraffic. The objective of the control system is set up as a tradeoff:\nmaximizing throughput while minimizing traffic oscillation. Following\ncomputational mechanism design, we search for the optimal control policy as a\nfunction of vehicle density and the tradeoff attitude parameter. This can be\ndone by letting all vehicles play a simulated game of CAV-modulated traffic\nunder such a control system. Our simulation results show that the improvements\nin traffic efficiency and smoothness are substantial. Finally, we envision how\nsuch a traffic control system can be realized in an environment with smart\nvehicles connected to a smart infrastructure or via a scheme of variable speed\nadvisory.\n","authors":["Di Shen","Qi Dai","Suzhou Huang","Dimitar Filev"],"pdf_url":"https://arxiv.org/pdf/2509.09441v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02437v3","updated":"2025-09-11T13:03:43Z","published":"2025-08-04T13:56:22Z","title":"On the Equivalence of Koopman Eigenfunctions and Commuting Symmetries","summary":"  The Koopman operator framework offers a way to represent a nonlinear system\nas a linear one. The key to this simplification lies in the identification of\neigenfunctions. While various data-driven algorithms have been developed for\nthis problem, a theoretical characterization of Koopman eigenfunctions from\ngeometric properties of the flow is still missing. This paper provides such a\ncharacterization by establishing an equivalence between a set of Koopman\neigenfunctions and a set of commuting symmetries -- both assumed to span the\ntangent spaces at every point on a simply connected open set. Based on this\nequivalence, we build an explicit and convergent formula for the principal\nKoopman eigenfunctions defined on the region of attraction of a locally\nasymptotically stable equilibrium point, thereby offering a constructive\nformula to compute Koopman eigenfunctions.\n","authors":["Xinyuan Jiang","Yan Li"],"pdf_url":"https://arxiv.org/pdf/2508.02437v3.pdf","comment":"7 pages, 1 figure"},{"id":"http://arxiv.org/abs/2509.09422v1","updated":"2025-09-11T13:03:36Z","published":"2025-09-11T13:03:36Z","title":"A Comparative Analysis of Robust and Reliable Designs Using the\n  Compromised Design Support Problem: A Case Study in Hot Rod Rolling Processes","summary":"  Design under uncertainty is a challenging problem, as a systems performance\ncan be highly sensitive to variations in input parameters and model\nuncertainty. A conventional approach to addressing such problems is robust\noptimization, which seeks to enhance design performance by reducing sensitivity\nto uncertainty. Alternatively, reliability-based design focuses on optimizing\nperformance while ensuring that failure constraints are satisfied with a\nspecified probability. While both methods are well established, their\nintegration into multi-objective and multi-stakeholder decision-making\nframeworks remains a challenging problem. In this study, we extend the\nCompromise Decision Support Problem (cDSP) framework to incorporate\nreliability-based design considerations and evaluate its performance in\ncomparison to the conventional robust-based cDSP formulation. The developed\nframework has been validated on a multidisciplinary hot rod rolling process\nincluding parametric and model uncertainties. The results compare the predicted\nperformance under robust and reliable scenarios, validating the efficiency of\nthe approach in managing uncertainties for complex, multidisciplinary systems.\nSpecifically, we found that the two methods exhibit markedly different\nperformance when the predicted performance follows a non-normal distribution, a\nsituation that arises in non-linear systems with parametric uncertainty. Based\non this insight, we offer guidance to designers on the conditions under which\neach method is most appropriate.\n","authors":["Maryam Ghasemzadeh","H M Dilshad Alam Digonta","Anand Balu Nellippallil","Anton van Beek"],"pdf_url":"https://arxiv.org/pdf/2509.09422v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.06541v2","updated":"2025-09-11T10:42:16Z","published":"2025-04-09T02:46:03Z","title":"Data-Driven Reachability with Scenario Optimization and the Holdout\n  Method","summary":"  Reachability analysis is an important method in providing safety guarantees\nfor systems with unknown or uncertain dynamics. Due to the computational\nintractability of exact reachability analysis for general nonlinear,\nhigh-dimensional systems, recent work has focused on the use of probabilistic\nmethods for computing approximate reachable sets. In this work, we advocate for\nthe use of a general purpose, practical, and sharp method for data-driven\nreachability: the holdout method. Despite the simplicity of the holdout method,\nwe show -- on several numerical examples including scenario-based reach tubes\n-- that the resulting probabilistic bounds are substantially sharper and\nrequire fewer samples than existing methods for data-driven reachability.\nFurthermore, we complement our work with a discussion on the necessity of\nprobabilistic reachability bounds. We argue that any method that attempts to\nde-randomize the bounds, by converting the guarantees to hold\ndeterministically, requires (a) an exponential in state-dimension amount of\nsamples to achieve non-vacuous guarantees, and (b) extra assumptions on the\ndynamics.\n","authors":["Elizabeth Dietrich","Rosalyn Devonport","Stephen Tu","Murat Arcak"],"pdf_url":"https://arxiv.org/pdf/2504.06541v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.07362v2","updated":"2025-09-11T10:36:45Z","published":"2025-05-12T08:57:29Z","title":"High Performance Signal Design for Optical OFDM Systems using\n  Variational Autoencoder","summary":"  This letter proposes a design of low peak-to-average power ratio (PAPR), low\nsymbol error rate (SER), and high data rate signal for optical orthogonal\nfrequency division multiplexing (OFDM) systems. The proposed design leverages a\nvariational autoencoder (VAE) incorporating gradual loss learning to jointly\noptimize the geometry and probability of the constellation's symbols. This not\nonly enhances mutual information (MI) but also effectively reduces the PAPR\nwhile maintaining a low SER for reliable transmission. We evaluate the\nperformance of the proposed VAE-based design by comparing the MI, SER, and PAPR\nagainst existing techniques. Simulation results demonstrate that the proposed\nmethod achieves a considerably lower PAPR while maintaining superior SER and MI\nperformance for a wide range of SNRs.\n","authors":["Nam N. Luong","Chuyen T. Nguyen","Thanh V. Pham"],"pdf_url":"https://arxiv.org/pdf/2505.07362v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19882v2","updated":"2025-09-11T10:22:31Z","published":"2024-09-30T02:27:52Z","title":"Tannenbaum's gain-margin optimization meets Polyak's heavy-ball\n  algorithm","summary":"  This paper highlights an apparent, yet relatively unknown link, between\nalgorithm design in optimization theory and control synthesis in robust\ncontrol. Specifically, quadratic optimization can be recast as a regulation\nproblem within the frame of $H_\\infty$ control. From this vantage point, the\noptimality of Polyak's fastest heavy-ball algorithm can be ascertained as a\nsolution to a gain margin optimization problem. The approach is independent of\nPolyak's original and brilliant argument, and relies on foundational work by\nTannenbaum who introduced and solved gain margin optimization via\nNevanlinna-Pick interpolation theory. The link between first-order optimization\nmethods and robust control sheds new light into the limits of algorithmic\nperformance of such methods, and suggests a framework where similar\ncomputational tasks can be systematically studied and algorithms optimized. In\nparticular, it raises the question as to whether periodically scheduled\nalgorithms can achieve faster rates for quadratic optimization, in a manner\nanalogous to periodic control that extends gain margin beyond that of\ntime-invariant control. This turns out not to be the case, due to the analytic\nobstruction of a transmission zero that is inherent in causal schemes.\nInterestingly, this obstruction can be removed with implicit algorithms, cast\nas feedback regulation problems with causal, but not strictly causal dynamics,\nthereby devoid of the transmission zero at infinity and able to achieve\nsuperior convergence rates.\n","authors":["Wuwei Wu","Jie Chen","Mihailo R. Jovanović","Tryphon T. Georgiou"],"pdf_url":"https://arxiv.org/pdf/2409.19882v2.pdf","comment":"26 pages, 8 figures"},{"id":"http://arxiv.org/abs/2509.09299v1","updated":"2025-09-11T09:43:27Z","published":"2025-09-11T09:43:27Z","title":"Towards Efficient and Secure Cloud Control Systems: Advances,\n  Challenges, and Future Directions","summary":"  Networked Control Systems (NCSs) have been instrumental in realizing fully\nconnected and responsive intelligent environments within the context of\nreal-time virtual control and management. However, traditional NCSs face\nconsiderable challenges in handling the vast amounts of data generated by\nlarge-scale control applications, particularly in terms of data acquisition,\nstorage, and computational processing. To address these challenges, the\nemergence of cloud computing and advancements in control theory have empowered\nthe new paradigm known as Cloud Control Systems (CCSs). Recently, CCSs have\nreceived substantial attention from industries for their potential properties,\nsuch as large-scale data management, complex computations, and data-centric\noptimized decisions. This study presents an extensive review of recent progress\nin CCSs spanning over multiple studies published between 2012 and 2025.\nSpecifically, the focus is on providing a taxonomy of the current findings in\nCCS research, encompassing various perspectives, such as its efficient\nimplementations in industrial automation, security and privacy considerations,\nand cloud-based control techniques. Each category is examined in depth through\nselected state-of-the-art analyses of different approaches and contrasting\nmethodologies. Furthermore, we discuss future directions aimed at designing\nmore efficient and practical CCSs. The insights gained from this study can help\nresearchers, practitioners, and decision-makers in their domain for effective\nCCS design and deployment.\n","authors":["Yasir Ali","Tayyab Manzoor","Huan Yang","Asif Ali","Yuanqing Xia"],"pdf_url":"https://arxiv.org/pdf/2509.09299v1.pdf","comment":"42 pages, 8 Figures"},{"id":"http://arxiv.org/abs/2509.09277v1","updated":"2025-09-11T09:08:09Z","published":"2025-09-11T09:08:09Z","title":"Voltage Synchronization and Proportional Current Sharing of Grid-Forming\n  Inverters","summary":"  Most previously proposed controllers are analyzed in the\nsmall-signal/quasi-steady regime rather than large-signal or transient\nstability for grid-forming inverters (GFMI). Additionally, methods that presume\nsystem-wide data--global measurements and complete grid-model knowledge--are\nchallenging to realize in practice and unsuitable for large-scale operation.\nMoreover, proportional current sharing is rarely embedded into them. The whole\nsystem is a high-order, nonlinear differential system, making analysis\nintractable without principled simplifications. Hence, contraction stability\nanalysis in GFMI is proposed to guarantee the large-signal stability.\nFurthermore, a contraction-based controller is proposed to synchronize GFMI.\nAdditionally, this paper proposes integrating an auxiliary virtual-impedance\nlayer into the contraction-based controller to achieve proportional current\nsharing, while the GFMI retains global stability and voltage synchronization. A\ndispatchable virtual oscillator control (dVOC), also known as the\nAndronov--Hopf oscillator (AHO) is used to validate the proposed contraction\nstability analysis and contraction-based controller with virtual-impedance. It\nis proved that the complex multi-converter system can achieve output-feedback\ncontraction under large-signal operation. Therefore, without requiring\nsystem-wide data, the proposed method offers voltage synchronization,\ndecentralized stability conditions for the transient stability of AHO and\nproportional current sharing, beyond prior small-signal, quasi-steady analysis.\n","authors":["Qianxi Tang","Li Peng"],"pdf_url":"https://arxiv.org/pdf/2509.09277v1.pdf","comment":"7 pages, 5 figures, 1 table"},{"id":"http://arxiv.org/abs/2509.09269v1","updated":"2025-09-11T08:58:57Z","published":"2025-09-11T08:58:57Z","title":"The role of communication delays in the optimal control of spatially\n  invariant systems","summary":"  We study optimal proportional feedback controllers for spatially invariant\nsystems when the controller has access to delayed state measurements received\nfrom different spatial locations. We analyze how delays affect the spatial\nlocality of the optimal feedback gain leveraging the problem decoupling in the\nspatial frequency domain. For the cases of expensive control and small delay,\nwe provide exact expressions of the optimal controllers in the limit for\ninfinite control weight and vanishing delay, respectively. In the expensive\ncontrol regime, the optimal feedback control law decomposes into a delay-aware\nfiltering of the delayed state and the optimal controller in the delay-free\nsetting. Under small delays, the optimal controller is a perturbation of the\ndelay-free one which depends linearly on the delay. We illustrate our\nanalytical findings with a reaction-diffusion process over the real line and a\nmulti-agent system coupled through circulant matrices, showing that delays\nreduce the effectiveness of optimal feedback control and may require each\nsubsystem within a distributed implementation to communicate with farther-away\nlocations.\n","authors":["Luca Ballotta","Juncal Arbelaiz","Vijay Gupta","Luca Schenato","Mihailo R. Jovanović"],"pdf_url":"https://arxiv.org/pdf/2509.09269v1.pdf","comment":"{\\copyright} 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works"},{"id":"http://arxiv.org/abs/2509.09206v1","updated":"2025-09-11T07:29:19Z","published":"2025-09-11T07:29:19Z","title":"Occupancy-aware Trajectory Planning for Autonomous Valet Parking in\n  Uncertain Dynamic Environments","summary":"  Accurately reasoning about future parking spot availability and integrated\nplanning is critical for enabling safe and efficient autonomous valet parking\nin dynamic, uncertain environments. Unlike existing methods that rely solely on\ninstantaneous observations or static assumptions, we present an approach that\npredicts future parking spot occupancy by explicitly distinguishing between\ninitially vacant and occupied spots, and by leveraging the predicted motion of\ndynamic agents. We introduce a probabilistic spot occupancy estimator that\nincorporates partial and noisy observations within a limited Field-of-View\n(FoV) model and accounts for the evolving uncertainty of unobserved regions.\nCoupled with this, we design a strategy planner that adaptively balances\ngoal-directed parking maneuvers with exploratory navigation based on\ninformation gain, and intelligently incorporates wait-and-go behaviors at\npromising spots. Through randomized simulations emulating large parking lots,\nwe demonstrate that our framework significantly improves parking efficiency,\nsafety margins, and trajectory smoothness compared to existing approaches.\n","authors":["Farhad Nawaz","Faizan M. Tariq","Sangjae Bae","David Isele","Avinash Singh","Nadia Figueroa","Nikolai Matni","Jovin D'sa"],"pdf_url":"https://arxiv.org/pdf/2509.09206v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.09178v1","updated":"2025-09-11T06:31:14Z","published":"2025-09-11T06:31:14Z","title":"Implementation of a 8-bit Wallace Tree Multiplier","summary":"  Wallace tree multipliers are a parallel digital multiplier architecture\ndesigned to minimize the worst-case time complexity of the circuit depth\nrelative to the input size [1]. In particular, it seeks to perform long\nmultiplication in the binary sense, reducing as many partial products per stage\nas possible through full and half adders circuits, achieving O(log(n)) where n\n= bit length of input. This paper provides an overview of the design, progress\nand methodology in the final project of ECE 55900, consisting of the schematic\nand layout of a Wallace tree 8-bit input multiplier on the gpdk45 technology in\nCadence Virtuoso, as well as any design attempts prior to the final product.\nThis also includes our endeavors in designing the final MAC (Multiply\nAccumulate) unit with undefined targets, which we chose to implement as a 16\nbit combinational multiply-add.\n","authors":["Ayan Biswas","Jimmy Jin"],"pdf_url":"https://arxiv.org/pdf/2509.09178v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.09145v1","updated":"2025-09-11T04:43:09Z","published":"2025-09-11T04:43:09Z","title":"KAN-Therm: A Lightweight Battery Thermal Model Using Kolmogorov-Arnold\n  Network","summary":"  Battery management systems (BMSs) rely on real-time estimation of battery\ntemperature distribution in battery cells to ensure safe and optimal operation\nof Lithium-ion batteries (LIBs). However, physical BMS often suffers from\nmemory and computational resource limitations required by highfidelity models.\nTemperature prediction using physics-based models becomes challenging due to\ntheir higher computational time. In contrast, machine learning based approaches\noffer faster predictions but demand larger memory overhead. In this work, we\ndevelop a lightweight and efficient Kolmogorov-Arnold networks (KAN) based\nthermal model, KAN-Therm, to predict the core temperature of a cylindrical\nbattery. We have compared the memory overhead and computation costs of our\nmethod with Multi-layer perceptron (MLP), recurrent neural network (RNN), and\nlong shortterm memory (LSTM) network. Our results show that the proposed\nKAN-Therm model exhibit the best prediction accuracy with the least memory\noverhead and computation time.\n","authors":["Soumyoraj Mallick","Sanchita Ghosh","Tanushree Roy"],"pdf_url":"https://arxiv.org/pdf/2509.09145v1.pdf","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2508.21335v2","updated":"2025-09-11T04:00:32Z","published":"2025-08-29T05:38:06Z","title":"A Fundamental Convergence Rate Bound for Gradient Based Online\n  Optimization Algorithms with Exact Tracking","summary":"  In this paper, we consider algorithms with integral action for solving online\noptimization problems characterized by quadratic cost functions with a\ntime-varying optimal point described by an $(n-1)$th order polynomial. Using a\nversion of the internal model principle, the optimization algorithms under\nconsideration are required to incorporate a discrete time $n$-th order\nintegrator in order to achieve exact tracking. By using results on an optimal\ngain margin problem, we obtain a fundamental convergence rate bound for the\nclass of linear gradient based algorithms exactly tracking a time-varying\noptimal point. This convergence rate bound is given by $\n\\left(\\frac{\\sqrt{\\kappa} - 1 }{\\sqrt{\\kappa} + 1}\\right)^{\\frac{1}{n}}$, where\n$\\kappa$ is the condition number for the set of cost functions under\nconsideration. Using our approach, we also construct algorithms which achieve\nthe optimal convergence rate as well as zero steady-state error when tracking a\ntime-varying optimal point.\n","authors":["Alex Xinting Wu","Ian R. Petersen","Iman Shames"],"pdf_url":"https://arxiv.org/pdf/2508.21335v2.pdf","comment":"Submitted to IEEE Transactions on Automatic Control"},{"id":"http://arxiv.org/abs/2509.09075v1","updated":"2025-09-11T00:42:15Z","published":"2025-09-11T00:42:15Z","title":"Optimal Control of an SIR Model with Noncompliance as a Social Contagion","summary":"  We propose and study a compartmental model for epidemiology with human\nbehavioral effects. Specifically, our model incorporates governmental\nprevention measures aimed at lowering the disease infection rate, but we split\nthe population into those who comply with the measures and those who do not\ncomply and therefore do not receive the reduction in infectivity. We then allow\nthe attitude of noncompliance to spread as a social contagion parallel to the\ndisease. We derive the reproductive ratio for our model and provide stability\nanalysis for the disease-free equilibria. We then propose a control scenario\nwherein a policy-maker with access to control variables representing disease\nprevention mandates, treatment efforts, and educational campaigns aimed at\nencouraging compliance minimizes a cost functional incorporating several cost\nconcerns. We characterize optimal controls via the Pontryagin optimality\nprinciple and present simulations which demonstrate the behavior of the control\nmaps in several different parameter regimes.\n","authors":["Chloe Ngo","Christian Parkinson","Weinan Wang"],"pdf_url":"https://arxiv.org/pdf/2509.09075v1.pdf","comment":"24 pages, 7 figures"}],"Hardware Architecture":[{"id":"http://arxiv.org/abs/2509.09505v1","updated":"2025-09-11T14:49:50Z","published":"2025-09-11T14:49:50Z","title":"Combating the Memory Walls: Optimization Pathways for Long-Context\n  Agentic LLM Inference","summary":"  LLMs now form the backbone of AI agents for a diverse array of applications,\nincluding tool use, command-line agents, and web or computer use agents. These\nagentic LLM inference tasks are fundamentally different from chatbot-focused\ninference -- they often have much larger context lengths to capture complex,\nprolonged inputs, such as entire webpage DOMs or complicated tool call\ntrajectories. This, in turn, generates significant off-chip memory traffic for\nthe underlying hardware at the inference stage and causes the workload to be\nconstrained by two memory walls, namely the bandwidth and capacity memory\nwalls, preventing the on-chip compute units from achieving high utilization.\n  In this paper, we introduce PLENA, a hardware-software co-designed system\nthat applies three core optimization pathways to tackle these challenges. PLENA\nincludes an efficient hardware implementation of compute and memory units\nsupporting an asymmetric quantization scheme. PLENA also features a novel\nflattened systolic array architecture that has native support for\nFlashAttention to tackle these memory walls in the scenario of inference\nserving for long-context LLMs. Additionally, PLENA is developed with a complete\nstack, including a custom ISA, a compiler, a cycle-emulated simulator, and an\nautomated design space exploration flow. The simulated results show that PLENA\nachieves up to 8.5x higher utilization than existing accelerators, and delivers\n2.24x higher throughput than the A100 GPU and 3.85x higher throughput than the\nTPU v6e, under the same multiplier count and memory settings. The full PLENA\nsystem will also be open-sourced.\n","authors":["Haoran Wu","Can Xiao","Jiayi Nie","Xuan Guo","Binglei Lou","Jeffrey T. H. Wong","Zhiwen Mo","Cheng Zhang","Przemyslaw Forys","Wayne Luk","Hongxiang Fan","Jianyi Cheng","Timothy M. Jones","Rika Antonova","Robert Mullins","Aaron Zhao"],"pdf_url":"https://arxiv.org/pdf/2509.09505v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.09178v1","updated":"2025-09-11T06:31:14Z","published":"2025-09-11T06:31:14Z","title":"Implementation of a 8-bit Wallace Tree Multiplier","summary":"  Wallace tree multipliers are a parallel digital multiplier architecture\ndesigned to minimize the worst-case time complexity of the circuit depth\nrelative to the input size [1]. In particular, it seeks to perform long\nmultiplication in the binary sense, reducing as many partial products per stage\nas possible through full and half adders circuits, achieving O(log(n)) where n\n= bit length of input. This paper provides an overview of the design, progress\nand methodology in the final project of ECE 55900, consisting of the schematic\nand layout of a Wallace tree 8-bit input multiplier on the gpdk45 technology in\nCadence Virtuoso, as well as any design attempts prior to the final product.\nThis also includes our endeavors in designing the final MAC (Multiply\nAccumulate) unit with undefined targets, which we chose to implement as a 16\nbit combinational multiply-add.\n","authors":["Ayan Biswas","Jimmy Jin"],"pdf_url":"https://arxiv.org/pdf/2509.09178v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.20250v2","updated":"2025-09-11T04:19:00Z","published":"2025-05-26T17:23:47Z","title":"Efficient Optimization Accelerator Framework for Multistate Ising\n  Problems","summary":"  Ising Machines are emerging hardware architectures that efficiently solve\nNP-Hard combinatorial optimization problems. Generally, combinatorial problems\nare transformed into quadratic unconstrained binary optimization (QUBO) form,\nbut this transformation often complicates the solution landscape, degrading\nperformance, especially for multi-state problems. To address this challenge, we\nmodel spin interactions as generalized boolean logic function to significantly\nreduce the exploration space. We demonstrate the effectiveness of our approach\non graph coloring problem using probabilistic Ising solvers, achieving similar\naccuracy compared to state-of-the-art heuristics and machine learning\nalgorithms. It also shows significant improvement over state-of-the-art\nQUBO-based Ising solvers, including probabilistic Ising and simulated\nbifurcation machines. We also design 1024-neuron all-to-all connected\nprobabilistic Ising accelerator on FPGA with the proposed approach that shows\n~10000x performance acceleration compared to GPU-based Tabucol heuristics and\nreducing physical neurons by 1.5-4x over baseline Ising frameworks. Thus, this\nwork establishes superior efficiency, scalability and solution quality for\nmulti-state optimization problems.\n","authors":["Chirag Garg","Sayeef Salahuddin"],"pdf_url":"https://arxiv.org/pdf/2505.20250v2.pdf","comment":"9 page main text, 4 main figures, 2 main table, 3 page supplementary,\n  10 supplementary figures,"},{"id":"http://arxiv.org/abs/2503.20507v3","updated":"2025-09-11T04:12:45Z","published":"2025-03-26T12:47:52Z","title":"Harmonia: A Multi-Agent Reinforcement Learning Approach to Data\n  Placement and Migration in Hybrid Storage Systems","summary":"  Hybrid storage systems (HSS) integrate multiple storage devices with diverse\ncharacteristics to deliver high performance and capacity at low cost. The\nperformance of an HSS highly depends on the effectiveness of two key policies:\n(1) the data-placement policy, which determines the best-fit storage device for\nincoming data, and (2) the data-migration policy, which dynamically rearranges\nstored data (i.e., prefetches hot data and evicts cold data) across the devices\nto sustain high HSS performance. Prior works optimize either data placement or\ndata migration in isolation, which leads to suboptimal HSS performance.\nUnfortunately, no prior work tries to optimize both policies together.\n  Our goal is to design a holistic data-management technique that optimizes\nboth data-placement and data-migration policies to fully exploit the potential\nof an HSS, and thus significantly improve system performance. We propose\nHarmonia, a multi-agent reinforcement learning (RL)-based data-management\ntechnique that employs two lightweight autonomous RL agents, a data-placement\nagent and a data-migration agent, that adapt their policies for the current\nworkload and HSS configuration while coordinating with each other to improve\noverall HSS performance.\n  We evaluate Harmonia on real HSS configurations with up to four heterogeneous\nstorage devices and seventeen data-intensive workloads. On\nperformance-optimized (cost-optimized) HSS with two storage devices, Harmonia\noutperforms the best-performing prior approach by 49.5% (31.7%) on average. On\nan HSS with three (four) devices, Harmonia outperforms the best-performing\nprior work by 37.0% (42.0%) on average. Harmonia's performance benefits come\nwith low latency (240ns for inference) and storage overheads (206 KiB in DRAM\nfor both RL agents combined). We will open-source Harmonia's implementation to\naid future research on HSS.\n","authors":["Rakesh Nadig","Vamanan Arulchelvan","Rahul Bera","Taha Shahroodi","Gagandeep Singh","Andreas Kakolyris","Mohammad Sadrosadati","Jisung Park","Onur Mutlu"],"pdf_url":"https://arxiv.org/pdf/2503.20507v3.pdf","comment":null}],"Programming Languages":[{"id":"http://arxiv.org/abs/2508.15264v2","updated":"2025-09-11T02:55:06Z","published":"2025-08-21T05:55:07Z","title":"Exploring the Theory and Practice of Concurrency in the\n  Entity-Component-System Pattern","summary":"  The Entity-Component-System (ECS) software design pattern, long used in game\ndevelopment, encourages a clean separation of identity (entities), data\nproperties (components), and computational behaviors (systems). Programs\nwritten using the ECS pattern are naturally concurrent, and the pattern offers\nmodularity, flexibility, and performance benefits that have led to a\nproliferation of ECS frameworks. Nevertheless, the ECS pattern is little-known\nand not well understood outside of a few domains. Existing explanations of the\nECS pattern tend to be mired in the concrete details of particular ECS\nframeworks, or they explain the pattern in terms of imperfect metaphors or in\nterms of what it is not. We seek a rigorous understanding of the ECS pattern\nvia the design of a formal model, Core ECS, that abstracts away the details of\nspecific implementations to reveal the essence of software using the ECS\npattern. We identify a class of Core ECS programs that behave deterministically\nregardless of scheduling, enabling use of the ECS pattern as a\ndeterministic-by-construction concurrent programming model. With Core ECS as a\npoint of comparison, we then survey several real-world ECS frameworks and find\nthat they all leave opportunities for deterministic concurrency unexploited.\nOur findings point out a space for new ECS implementation techniques that\nbetter leverage such opportunities.\n","authors":["Patrick Redmond","Jonathan Castello","José Manuel Calderón Trilla","Lindsey Kuper"],"pdf_url":"https://arxiv.org/pdf/2508.15264v2.pdf","comment":"This is an extended version (with appendices) of the OOPSLA 2025\n  paper"}],"Data Structures and Algorithms":[{"id":"http://arxiv.org/abs/2509.09652v1","updated":"2025-09-11T17:45:21Z","published":"2025-09-11T17:45:21Z","title":"Additive Approximation Schemes for Low-Dimensional Embeddings","summary":"  We consider the task of fitting low-dimensional embeddings to\nhigh-dimensional data. In particular, we study the $k$-Euclidean Metric\nViolation problem ($\\textsf{$k$-EMV}$), where the input is $D \\in\n\\mathbb{R}^{\\binom{n}{2}}_{\\geq 0}$ and the goal is to find the closest vector\n$X \\in \\mathbb{M}_{k}$, where $\\mathbb{M}_k \\subset\n\\mathbb{R}^{\\binom{n}{2}}_{\\geq 0}$ is the set of all $k$-dimensional Euclidean\nmetrics on $n$ points, and closeness is formulated as the following\noptimization problem, where $\\| \\cdot \\|$ is the entry-wise $\\ell_2$ norm: \\[\n  \\textsf{OPT}_{\\textrm{EMV}} = \\min_{X \\in \\mathbb{M}_{k} } \\Vert D - X\n\\Vert_2^2\\,.\\] Cayton and Dasgupta [CD'06] showed that this problem is NP-Hard,\neven when $k=1$. Dhamdhere [Dha'04] obtained a $O(\\log(n))$-approximation for\n$\\textsf{$1$-EMV}$ and leaves finding a PTAS for it as an open question\n(reiterated recently by Lee [Lee'25]). Although $\\textsf{$k$-EMV}$ has been\nstudied in the statistics community for over 70 years, under the name\n\"multi-dimensional scaling\", there are no known efficient approximation\nalgorithms for $k > 1$, to the best of our knowledge.\n  We provide the first polynomial-time additive approximation scheme for\n$\\textsf{$k$-EMV}$. In particular, we obtain an embedding with objective value\n$\\textsf{OPT}_{\\textrm{EMV}} + \\varepsilon \\Vert D\\Vert_2^2$ in $(n\\cdot\nB)^{\\mathsf{poly}(k, \\varepsilon^{-1})}$ time, where each entry in $D$ can be\nrepresented by $B$ bits. We believe our algorithm is a crucial first step\ntowards obtaining a PTAS for $\\textsf{$k$-EMV}$. Our key technical contribution\nis a new analysis of correlation rounding for Sherali-Adams / Sum-of-Squares\nrelaxations, tailored to low-dimensional embeddings. We also show that our\ntechniques allow us to obtain additive approximation schemes for two related\nproblems: a weighted variant of $\\textsf{$k$-EMV}$ and $\\ell_p$ low-rank\napproximation for $p>2$.\n","authors":["Prashanti Anderson","Ainesh Bakshi","Samuel B. Hopkins"],"pdf_url":"https://arxiv.org/pdf/2509.09652v1.pdf","comment":"57 pages"},{"id":"http://arxiv.org/abs/2509.09641v1","updated":"2025-09-11T17:28:01Z","published":"2025-09-11T17:28:01Z","title":"Maximizing social welfare among EF1 allocations at the presence of two\n  types of agents","summary":"  We study the fair allocation of indivisible items to $n$ agents to maximize\nthe utilitarian social welfare, where the fairness criterion is envy-free up to\none item and there are only two different utility functions shared by the\nagents. We present a $2$-approximation algorithm when the two utility functions\nare normalized, improving the previous best ratio of $16 \\sqrt{n}$ shown for\ngeneral normalized utility functions; thus this constant ratio approximation\nalgorithm confirms the APX-completeness in this special case previously shown\nAPX-hard. When there are only three agents, i.e., $n = 3$, the previous best\nratio is $3$ shown for general utility functions, and we present an improved\nand tight $\\frac 53$-approximation algorithm when the two utility functions are\nnormalized, and a best possible and tight $2$-approximation algorithm when the\ntwo utility functions are unnormalized.\n","authors":["Jiaxuan Ma","Yong Chen","Guangting Chen","Mingyang Gong","Guohui Lin","An Zhang"],"pdf_url":"https://arxiv.org/pdf/2509.09641v1.pdf","comment":"A shorter version appears in ISAAC 2025; 20 pages in this full\n  version"},{"id":"http://arxiv.org/abs/2504.01206v2","updated":"2025-09-11T11:39:42Z","published":"2025-04-01T21:39:50Z","title":"SplineSketch: Even More Accurate Quantiles with Error Guarantees","summary":"  Space-efficient streaming estimation of quantiles in massive datasets is a\nfundamental problem with numerous applications in data monitoring and analysis.\nWhile theoretical research led to optimal algorithms, such as the\nGreenwald-Khanna algorithm or the KLL sketch, practitioners often use other\nsketches that perform significantly better in practice but lack theoretical\nguarantees. Most notably, the widely used $t$-digest has unbounded worst-case\nerror.\n  In this paper, we seek to get the best of both worlds. We present a new\nquantile summary, SplineSketch, for numeric data, offering near-optimal\ntheoretical guarantees, namely uniformly bounded rank error, and outperforming\n$t$-digest by a factor of 2-20 on a range of synthetic and real-world datasets.\nTo achieve such performance, we develop a novel approach that maintains a\ndynamic subdivision of the input range into buckets while fitting the input\ndistribution using monotone cubic spline interpolation. The core challenge is\nimplementing this method in a space-efficient manner while ensuring strong\nworst-case guarantees.\n","authors":["Aleksander Łukasiewicz","Jakub Tětek","Pavel Veselý"],"pdf_url":"https://arxiv.org/pdf/2504.01206v2.pdf","comment":"Accepted to SIGMOD'26"},{"id":"http://arxiv.org/abs/2509.07827v3","updated":"2025-09-11T10:11:55Z","published":"2025-09-09T15:04:42Z","title":"Compressibility Measures and Succinct Data Structures for Piecewise\n  Linear Approximations","summary":"  We study the problem of deriving compressibility measures for Piecewise\nLinear Approximations (PLAs), i.e., error-bounded approximations of a set of\ntwo-dimensional increasing data points using a sequence of segments. Such\napproximations are widely used tools in implementing many learned data\nstructures, which mix learning models with traditional algorithmic design\nblocks to exploit regularities in the underlying data distribution, providing\nnovel and effective space-time trade-offs. We introduce the first lower bounds\nto the cost of storing PLAs in two settings, namely compression and indexing.\nWe then compare these compressibility measures to known data structures, and\nshow that they are asymptotically optimal up to a constant factor from the\nspace lower bounds. Finally, we design the first data structures for the\naforementioned settings that achieve the space lower bounds plus small additive\nterms, which turn out to be succinct in most practical cases. Our data\nstructures support the efficient retrieval and evaluation of a segment in the\n(compressed) PLA for a given $x$-value, which is a core operation in any\nlearned data structure relying on PLAs. As a result, our paper offers the first\ntheoretical analysis of the maximum compressibility achievable by PLA-based\nlearned data structures, and provides novel storage schemes for PLAs offering\nstrong theoretical guarantees while also suggesting simple and efficient\npractical implementations.\n","authors":["Paolo Ferragina","Filippo Lari"],"pdf_url":"https://arxiv.org/pdf/2509.07827v3.pdf","comment":"Accepted for publication at the 36th International Symposium on\n  Algorithms and Computation (ISAAC)"},{"id":"http://arxiv.org/abs/2507.23659v2","updated":"2025-09-11T10:03:22Z","published":"2025-07-31T15:37:36Z","title":"Nyldon Factorization of Thue-Morse Words and Fibonacci Words","summary":"  The Nyldon factorization is a string factorization that is a non-decreasing\nproduct of Nyldon words. Nyldon words and Nyldon factorizations are recently\ndefined combinatorial objects inspired by the well-known Lyndon words and\nLyndon factorizations. In this paper, we investigate the Nyldon factorization\nof several words. First, we fully characterize the Nyldon factorizations of the\n(finite) Fibonacci and the (finite) Thue-Morse words. Moreover, we show that\nthere exists a non-decreasing product of Nyldon words that is a factorization\nof the infinite Thue-Morse word.\n","authors":["Kaisei Kishi","Kazuki Kai","Yuto Nakashima","Shunsuke Inenaga","Hideo Bannai"],"pdf_url":"https://arxiv.org/pdf/2507.23659v2.pdf","comment":"A full version of our conference paper accepted for SPIRE 2025"},{"id":"http://arxiv.org/abs/2101.03712v6","updated":"2025-09-11T07:46:34Z","published":"2021-01-11T05:49:49Z","title":"Enumeration Algorithms for Conjunctive Queries with Projection","summary":"  We investigate the enumeration of query results for an important subset of\nCQs with projections, namely star and path queries. The task is to design data\nstructures and algorithms that allow for efficient enumeration with delay\nguarantees after a preprocessing phase. Our main contribution is a series of\nresults based on the idea of interleaving precomputed output with further join\nprocessing to maintain delay guarantees, which maybe of independent interest.\nIn particular, for star queries, we design combinatorial algorithms that\nprovide instance-specific delay guarantees in linear preprocessing time. These\nalgorithms improve upon the currently best known results. Further, we show how\nexisting results can be improved upon by using fast matrix multiplication. We\nalso present new results involving tradeoff between preprocessing time and\ndelay guarantees for enumeration of path queries that contain projections.\nBoolean matrix multiplication is an important query that can be expressed as a\nCQ with projection where the join attribute is projected away. Our results can\ntherefore also be interpreted as sparse, output-sensitive matrix multiplication\nwith delay guarantees.\n","authors":["Shaleen Deep","Xiao Hu","Paraschos Koutris"],"pdf_url":"https://arxiv.org/pdf/2101.03712v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.09180v1","updated":"2025-09-11T06:32:29Z","published":"2025-09-11T06:32:29Z","title":"Improved Approximation Guarantees and Hardness Results for MNL-Driven\n  Product Ranking","summary":"  In this paper, we address open computational questions regarding the market\nshare ranking problem, recently introduced by Derakhshan et al. (2022). Their\nmodelling framework incorporates the extremely popular Multinomial Logit (MNL)\nchoice model, along with a novel search-based consider-then-choose paradigm. In\na nutshell, the authors devised a Pandora's-Box-type search model, where\ndifferent customer segments sequentially screen through a ranked list of\nproducts, one position after the other, forming their consideration set by\nincluding all products viewed up until terminating their inspection procedure.\nSubsequently, a purchasing decision out of this set is made based on a joint\nMNL choice model.\n  Our main contribution consists in devising a polynomial-time approximation\nscheme for the market share ranking problem, utilizing fresh technical\ndevelopments and analytical ideas, in conjunction with revising the original\ninsights of Derakhshan et al. (2022). Along the way, we introduce a black-box\nreduction, mapping general instances of the market share ranking problem into\n``bounded ratio'' instances, showing that this result directly leads to an\nelegant and easily-implementable quasi-PTAS. Finally, to provide a complete\ncomputational characterization, we prove that the market share ranking problem\nis strongly $\\mathrm{NP}$-hard.\n","authors":["Danny Segev","Gidi Steinberg"],"pdf_url":"https://arxiv.org/pdf/2509.09180v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2509.08148v2","updated":"2025-09-11T00:40:02Z","published":"2025-09-09T21:10:15Z","title":"A Dynamic, Self-balancing k-d Tree","summary":"  The original description of the k-d tree recognized that rebalancing\ntechniques, used for building an AVL tree or a red-black tree, are not\napplicable to a k-d tree, because these techniques involve cyclic exchange of\ntree nodes, which destroys the sorted order of the k-d tree. For this reason, a\nstatic, balanced k-d tree is often built from all of the k-dimensional data en\nmasse. However, it is possible to build a dynamic k-d tree that self-balances\nwhen necessary after insertion or deletion of each k-dimensional datum. This\narticle describes insertion, deletion, and rebalacing algorithms for a dynamic,\nself-balancing k-d tree, and measures their performance.\n","authors":["Russell A. Brown"],"pdf_url":"https://arxiv.org/pdf/2509.08148v2.pdf","comment":"16 pages, 4 figures, 6 tables"}],"Graphics":[{"id":"http://arxiv.org/abs/2509.09143v1","updated":"2025-09-11T04:33:27Z","published":"2025-09-11T04:33:27Z","title":"Objectness Similarity: Capturing Object-Level Fidelity in 3D Scene\n  Evaluation","summary":"  This paper presents Objectness SIMilarity (OSIM), a novel evaluation metric\nfor 3D scenes that explicitly focuses on \"objects,\" which are fundamental units\nof human visual perception. Existing metrics assess overall image quality,\nleading to discrepancies with human perception. Inspired by neuropsychological\ninsights, we hypothesize that human recognition of 3D scenes fundamentally\ninvolves attention to individual objects. OSIM enables object-centric\nevaluations by leveraging an object detection model and its feature\nrepresentations to quantify the \"objectness\" of each object in the scene. Our\nuser study demonstrates that OSIM aligns more closely with human perception\ncompared to existing metrics. We also analyze the characteristics of OSIM using\nvarious approaches. Moreover, we re-evaluate recent 3D reconstruction and\ngeneration models under a standardized experimental setup to clarify\nadvancements in this field. The code is available at\nhttps://github.com/Objectness-Similarity/OSIM.\n","authors":["Yuiko Uchida","Ren Togo","Keisuke Maeda","Takahiro Ogawa","Miki Haseyama"],"pdf_url":"https://arxiv.org/pdf/2509.09143v1.pdf","comment":"Accepted by the ICCV 2025 UniLight Workshop"},{"id":"http://arxiv.org/abs/2502.00626v2","updated":"2025-09-11T03:25:24Z","published":"2025-02-02T01:51:56Z","title":"Lifting the Winding Number: Precise Discontinuities in Neural Fields for\n  Physics Simulation","summary":"  Cutting thin-walled deformable structures is common in daily life, but poses\nsignificant challenges for simulation due to the introduced spatial\ndiscontinuities. Traditional methods rely on mesh-based domain representations,\nwhich require frequent remeshing and refinement to accurately capture evolving\ndiscontinuities. These challenges are further compounded in reduced-space\nsimulations, where the basis functions are inherently geometry- and\nmesh-dependent, making it difficult or even impossible for the basis to\nrepresent the diverse family of discontinuities introduced by cuts.\n  Recent advances in representing basis functions with neural fields offer a\npromising alternative, leveraging their discretization-agnostic nature to\nrepresent deformations across varying geometries. However, the inherent\ncontinuity of neural fields is an obstruction to generalization, particularly\nif discontinuities are encoded in neural network weights.\n  We present Wind Lifter, a novel neural representation designed to accurately\nmodel complex cuts in thin-walled deformable structures. Our approach\nconstructs neural fields that reproduce discontinuities precisely at specified\nlocations, without baking in the position of the cut line. Crucially, our\napproach does not embed the discontinuity in the neural network's weights,\nopening avenues to generalization of cut placement.\n  Our method achieves real-time simulation speeds and supports dynamic updates\nto cut line geometry during the simulation. Moreover, the explicit\nrepresentation of discontinuities makes our neural field intuitive to control\nand edit, offering a significant advantage over traditional neural fields,\nwhere discontinuities are embedded within the network's weights, and enabling\nnew applications that rely on general cut placement.\n","authors":["Yue Chang","Mengfei Liu","Zhecheng Wang","Peter Yichen Chen","Eitan Grinspun"],"pdf_url":"https://arxiv.org/pdf/2502.00626v2.pdf","comment":null}]}}